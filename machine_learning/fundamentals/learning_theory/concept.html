
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Concept &#8212; Machine Learning Chronicles</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
    <script src="../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"defeq": "\\overset{\\text{def}}{=}", "defa": "\\overset{\\text{(a)}}{=}", "defb": "\\overset{\\text{(b)}}{=}", "defc": "\\overset{\\text{(c)}}{=}", "defd": "\\overset{\\text{(d)}}{=}", "st": "\\mid", "mod": "\\mid", "S": "\\Omega", "s": "\\omega", "e": "\\exp", "P": "\\mathbb{P}", "R": "\\mathbb{R}", "expectation": "\\mathbb{E}", "v": "\\mathbf{v}", "a": "\\mathbf{a}", "b": "\\mathbf{b}", "c": "\\mathbf{c}", "u": "\\mathbf{u}", "w": "\\mathbf{w}", "x": "\\mathbf{x}", "y": "\\mathbf{y}", "z": "\\mathbf{z}", "0": "\\mathbf{0}", "1": "\\mathbf{1}", "A": "\\mathbf{A}", "B": "\\mathbf{B}", "C": "\\mathbf{C}", "E": "\\mathcal{F}", "eventA": "\\mathcal{A}", "lset": "\\left\\{", "rset": "\\right\\}", "lsq": "\\left[", "rsq": "\\right]", "lpar": "\\left(", "rpar": "\\right)", "lcurl": "\\left\\{", "rcurl": "\\right\\}", "pmf": "p_X", "pdf": "f_X", "pdftwo": "f_{X,Y}", "pdfjoint": "f_{\\mathbf{X}}", "pmfjointxy": "p_{X, Y}", "pdfjointxy": "f_{X, Y}", "cdf": "F_X", "pspace": "(\\Omega, \\mathcal{F}, \\mathbb{P})", "var": "\\operatorname{Var}", "std": "\\operatorname{Std}", "bern": "\\operatorname{Bernoulli}", "binomial": "\\operatorname{Binomial}", "geometric": "\\operatorname{Geometric}", "poisson": "\\operatorname{Poisson}", "uniform": "\\operatorname{Uniform}", "normal": "\\operatorname{Normal}", "gaussian": "\\operatorname{Gaussian}", "gaussiansymbol": "\\mathcal{N}", "exponential": "\\operatorname{Exponential}", "iid": "\\textbf{i.i.d.}", "and": "\\text{and}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'machine_learning/fundamentals/learning_theory/concept';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Bias and Variance Tradeoff" href="../bias_and_variance/intro.html" />
    <link rel="prev" title="Is the Learning Problem Solvable?" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../../intro.html">

  
  
  
  
  
  
  

  
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../../../_static/logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../optimization/gradient_descent/intro.html">
                        Gradient Descent
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../intro.html">
                        Fundamentals
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mixtures/intro.html">
                        Mixture Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../clustering/intro.html">
                        Clustering
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../references_resources_roadmap/bibliography.html">
                        Bibliography
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../references_resources_roadmap/resources.html">
                        Resources
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../optimization/gradient_descent/intro.html">
                        Gradient Descent
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../intro.html">
                        Fundamentals
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mixtures/intro.html">
                        Mixture Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../clustering/intro.html">
                        Clustering
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../references_resources_roadmap/bibliography.html">
                        Bibliography
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../references_resources_roadmap/resources.html">
                        Resources
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
  


<a class="navbar-brand logo" href="../../../intro.html">

  
  
  
  
  
  
  

  
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../../../_static/logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    </div>
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Optimization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../optimization/gradient_descent/intro.html">Gradient Descent</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../optimization/gradient_descent/concept.html">Gradient Descent Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../optimization/gradient_descent/implementation.html">Gradient Descent Construction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../optimization/gradient_descent/application.html">Application: Gradient Descent</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../intro.html">Fundamentals</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../criterions/intro.html">Loss</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../criterions/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../criterions/cross_entropy_loss.html">Cross Entropy Loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../criterions/focal_loss.html">Focal Loss</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../empirical_risk_minimization/intro.html">Empirical Risk Minimization</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../empirical_risk_minimization/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../empirical_risk_minimization/bayes_optimal_classifier.html">Bayes Optimal Classifier</a></li>
</ul>
</li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="intro.html">Is the Learning Problem Solvable?</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3 current active"><a class="current reference internal" href="#">Concept</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../bias_and_variance/intro.html">Bias and Variance Tradeoff</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../bias_and_variance/concept.html">Bias-Variance Tradeoff Concept</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../decision_boundary/intro.html">Decision Boundary</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../decision_boundary/concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../voronoi_region/intro.html">Voronoi Region</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../voronoi_region/concept.html">Concept</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mixtures/intro.html">Mixture Models</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mixtures/gmm/intro.html">Gaussian Mixture Models</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mixtures/gmm/concept.html">Concept</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../clustering/intro.html">Clustering</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../clustering/kmeans/intro.html">K-Means</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../clustering/kmeans/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../clustering/kmeans/implementation.html">Implementation: K-Means (Lloyd)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../clustering/kmeans/image_segmentation.html">Application: Image Compression and Segmentation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References, Resources and Roadmap</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../references_resources_roadmap/bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../references_resources_roadmap/resources.html">Resources</a></li>
</ul>

    </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        <label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" data-toggle="tooltip" data-placement="right" title="Toggle primary sidebar">
            <span class="fa-solid fa-bars"></span>
        </label>
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="btn btn-sm"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<div class="dropdown dropdown-repository-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://github.com/gao-hongnan/gaohn-galaxy" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">repository</span>
</a>
</a>
      
      <li><a href="https://github.com/gao-hongnan/gaohn-galaxy/issues/new?title=Issue%20on%20page%20%2Fmachine_learning/fundamentals/learning_theory/concept.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">open issue</span>
</a>
</a>
      
  </ul>
</div>



<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="../../../_sources/machine_learning/fundamentals/learning_theory/concept.md" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</a>
      
      <li>
<button onclick="printPdf(this)"
  class="btn btn-sm dropdown-item"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</a>
      
  </ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary" data-toggle="tooltip" data-placement="left" title="Toggle secondary sidebar">
            <span class="fa-solid fa-list"></span>
        </label>
    </div>
</div>
            </div>
            
            

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Concept</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#some-abuse-of-notations">
   Some Abuse of Notations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problem-statement">
   Problem Statement
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notations">
   Notations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#is-learning-feasible">
   Is Learning Feasible?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learing-outside-the-training-set-mathcal-s-deterministic-case">
     Learing Outside the Training Set
     <span class="math notranslate nohighlight">
      \(\mathcal{S}\)
     </span>
     (Deterministic Case)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#identically-and-independently-distributed-random-variables">
     Identically and Independently Distributed Random Variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learing-outside-the-training-set-mathcal-s-probabilistic-case">
     Learing Outside the Training Set
     <span class="math notranslate nohighlight">
      \(\mathcal{S}\)
     </span>
     (Probabilistic Case)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-generalization-gap">
     The Generalization Gap
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-law-of-large-numbers">
   The Law of Large Numbers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hoeffding-s-inequality">
   Hoeffding’s Inequality
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comparing-hoeffding-s-inequality-with-the-chebyshev-s-inequality">
     Comparing Hoeffding’s Inequality with the Chebyshev’s Inequality
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-hoeffding-s-inequality-in-classification">
     Example: Hoeffding’s Inequality in Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pac-framework">
   PAC Framework
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hoeffding-inequality-is-invalid-for-h-s-learnt-from-mathcal-s">
   Hoeffding Inequality is Invalid for
   <span class="math notranslate nohighlight">
    \(h_S\)
   </span>
   learnt from
   <span class="math notranslate nohighlight">
    \(\mathcal{S}\)
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#union-bound">
   Union Bound
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#framing-learning-theory-with-hoeffding-s-inequality">
   Framing Learning Theory with Hoeffding’s Inequality
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feasibility-from-the-two-view-points">
   Feasibility from the Two View Points
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complex-hypothesis-set-and-complex-target-function">
     Complex Hypothesis Set and Complex Target Function
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vc-analysis">
   VC-Analysis
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generalization-bound">
     Generalization Bound
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-growth-function">
     The Growth Function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-vc-dimension">
     The VC Dimension
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sauers-lemma-and-bounding-the-growth-function">
     Sauer’s Lemma and Bounding the Growth Function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpretating-the-generalization-bound">
     Interpretating the Generalization Bound
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sample-complexity">
     Sample Complexity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-complexity">
     Model Complexity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#testing-data">
     Testing Data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-must-h-be-fixed-and-defined-before-generating-the-dataset-mathcal-s">
   Why must
   <span class="math notranslate nohighlight">
    \(h\)
   </span>
   be fixed and defined before generating the dataset
   <span class="math notranslate nohighlight">
    \(\mathcal{S}\)
   </span>
   ?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-intuition-on-the-difference-between-a-priori-and-a-posteriori">
     Some intuition on the difference between
     <em>
      a-priori
     </em>
     and
     <em>
      a-posteriori
     </em>
     :
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-priori">
       A-priori:
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-posteriori">
       A-posteriori:
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-specific-setup">
   Your specific setup
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#your-specific-questions">
     Your specific questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-readings">
   Further Readings
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>

            <article class="bd-article" role="main">
              
  <section class="tex2jax_ignore mathjax_ignore" id="concept">
<h1>Concept<a class="headerlink" href="#concept" title="Permalink to this heading">#</a></h1>
<p>This topic is quite theoretical and heavy. I do not have the ability to explain
them in an intuitive way. Therefore, most of the content here is adapted
from the following sources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://engineering.purdue.edu/ChanGroup/ECE595/files/chapter4.pdf">ECE595: Learning Theory</a></p></li>
<li><p><a class="reference external" href="https://mostafa-samir.github.io/ml-theory-pt2/">Mostafa Samir: Machine Learning Theory</a></p></li>
<li><p><a class="reference external" href="https://wei2624.github.io/MachineLearning/sv_learning_theory/">Zhang Wei: Learning Theory</a></p></li>
</ul>
<p>Therefore, this section serves as a document/reference and all credits go to the authors of the above sources.</p>
<section id="some-abuse-of-notations">
<h2>Some Abuse of Notations<a class="headerlink" href="#some-abuse-of-notations" title="Permalink to this heading">#</a></h2>
<div class="proof remark admonition" id="remark-learning-problem-notations-learning-theory">
<p class="admonition-title"><span class="caption-number">Remark 7 </span> (Notations)</p>
<section class="remark-content" id="proof-content">
<p>We will abbrieviate:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} := \mathcal{R}_{\mathcal{D}}\left\{h\right\}
\]</div>
<div class="math notranslate nohighlight">
\[
\mathbb{P}_{\mathcal{D}} := \mathcal{D}
\]</div>
<p>when the context is clear.</p>
<p>The author used <span class="math notranslate nohighlight">\(g\)</span> as the final hypothesis learnt by the algorithm, we will however use <span class="math notranslate nohighlight">\(h_S\)</span> to denote
<span class="math notranslate nohighlight">\(g\)</span>. Therefore, some images from the author will have <span class="math notranslate nohighlight">\(g\)</span> instead of <span class="math notranslate nohighlight">\(h_S\)</span>.</p>
</section>
</div></section>
<section id="problem-statement">
<h2>Problem Statement<a class="headerlink" href="#problem-statement" title="Permalink to this heading">#</a></h2>
<p>When we have built a classifier, one question people always ask is how good the classifier is. They want to evaluate the classifier. They want to see whether the classifier is able to predict what it is supposed to predict. Often times, the “gold standard” is to report the classification accuracy: Give me a testing dataset, and I will tell you how many times the classifier has done correctly. This is one way of evaluating the classifier. However, does this evaluation method really tells us how good the classifier is? Not clear. All it says is that for this classifier trained on a particular training dataset and tested on a particular testing dataset, the classifier performs such and such. Will it perform well if we train the classifier using another training set, maybe containing more data points? Will it perform well if we test it on a different testing dataset? It seems that we lack a way to quantify the generalization ability of our classifier.</p>
<p>There is another difficulty. When we train the classifier, we can only access the training data but not the testing data. This is like taking an exam. We can never see the exam questions when we study, for otherwise we will defeat the purpose of the exam! Since we only have the training set when we design our classifier, how do we tell whether we have trained a good classifier? Should we choose a more complex model? How many samples do we need? Remember, we cannot use any testing data and so all the evaluation has to be done internally using the training data. How to do that? Again, we are missing a way to quantify the performance of the classifier.</p>
<p>The objective of this chapter is to answer a few theoretical (and also practical) questions in learning:</p>
<ol class="arabic simple">
<li><p>Is learning feasible?</p></li>
<li><p>How much can a classifier generalize?</p></li>
<li><p>What is the relationship between number of training samples and the complexity of the classifier?</p></li>
<li><p>How do we tell whether we have obtained a good classifier during the training?</p></li>
</ol>
</section>
<section id="notations">
<h2>Notations<a class="headerlink" href="#notations" title="Permalink to this heading">#</a></h2>
<p>Let’s refresh ourselves with some notations.</p>
<p>We have a training dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> sampled <span class="math notranslate nohighlight">\(\iid\)</span> from the underlying and unknown distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\mathcal{S} = \left\{(\mathbf{x}^{(1)}, y^{(1)}), (\mathbf{x}^{(2)}, y^{(2)}), \ldots, (\mathbf{x}^{(N)}, y^{(N)})\right\} \overset{\text{iid}}{\sim} \mathcal{D}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)} \in \mathbb{R}^{D}\)</span> is the input vector and <span class="math notranslate nohighlight">\(y^{(n)} \in \mathcal{Y}\)</span> is the corresponding label. We call <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> the <span class="math notranslate nohighlight">\(n\)</span>-th input vector and <span class="math notranslate nohighlight">\(y^{(n)}\)</span> the <span class="math notranslate nohighlight">\(n\)</span>-th label. We call <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> the training dataset. We call <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> (<span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}\)</span>) the underlying distribution.</p>
<p>Now there is an unknown target function <span class="math notranslate nohighlight">\(f: \mathcal{X} \rightarrow \mathcal{Y}\)</span><a class="footnote-reference brackets" href="#f-and-c" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> which maps <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to a label <span class="math notranslate nohighlight">\(y=f(\mathbf{x})\)</span>. The set <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> contains all the input vectors, and we call <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> the input space. The set <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> contains the corresponding labels, and we call <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> the output space.</p>
<p>In any supervised learning scenario, there is always a training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> sampled from <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}\)</span>. The training set contains <span class="math notranslate nohighlight">\(N\)</span> input-output pairs <span class="math notranslate nohighlight">\(\left(\mathbf{x}^{(1)}, y^{(1)}\right), \ldots,\left(\mathbf{x}^{(N)}, y^{(N)}\right)\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> and <span class="math notranslate nohighlight">\(y^{(n)}\)</span> are related via <span class="math notranslate nohighlight">\(y^{(n)}=\)</span> <span class="math notranslate nohighlight">\(f\left(\mathbf{x}^{(n)}\right)\)</span>, for <span class="math notranslate nohighlight">\(n=1, \ldots, N\)</span>. These input-output pairs are called the data points or samples. Since <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is a finite collection of data points, there are many <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}\)</span> that do not live in the training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. A data point <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> that is inside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is called an <strong>in-sample</strong>, and a data point <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> that is outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is called an <strong>out-sample</strong>.</p>
<p>When we say that we use a machine learning algorithm to learn a classifier, we mean that we have an algorithmic procedure <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> (i.e. Logistic Regression, KNN etc) which uses the training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> to select a hypothesis function <span class="math notranslate nohighlight">\(h_S: \mathcal{X} \rightarrow \mathcal{Y}\)</span>. The hypothesis function is again a mapping from <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> to <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, because it tells what a sample <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is being classified. However, a hypothesis function <span class="math notranslate nohighlight">\(h_S\)</span> learned by the algorithm  is not the same as the target function <span class="math notranslate nohighlight">\(f\)</span>. We never know <span class="math notranslate nohighlight">\(f\)</span> because <span class="math notranslate nohighlight">\(f\)</span> is simply unknown. No matter how much we learn, the hypothesis function <span class="math notranslate nohighlight">\(h_S\)</span> is at best an approximation of <span class="math notranslate nohighlight">\(f\)</span>. The approximation error can be zero in some hand-craved toy examples, but in general <span class="math notranslate nohighlight">\(h_S \neq f\)</span>. All hypothesis functions are contained in the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. If the hypothesis set is finite, then <span class="math notranslate nohighlight">\(\mathcal{H}=\left\{h_{1}, \ldots, h_{M}\right\}\)</span>, and <span class="math notranslate nohighlight">\(h_S\)</span> will be one of these <span class="math notranslate nohighlight">\(h_{m}\)</span> ‘s. A hypothesis set can be infinite, for example we can perturb a perceptron decision boundary by an infinitesimal step to an infinite hypothesis set. An infinite hypothesis set is denoted by <span class="math notranslate nohighlight">\(\mathcal{H}=\left\{h_{\sigma}\right\}\)</span>, where <span class="math notranslate nohighlight">\(\sigma\)</span> denotes a continuous parameter.</p>
<p>The drawings in <a class="reference internal" href="#ece595-fig4-1"><span class="std std-numref">Fig. 4</span></a> illustrate a few key concepts we just mentioned. On the left hand side there is an input space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, which contains a small subset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. The subset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is the training set, which includes a finite number of training samples or in-samples. There is an unknown target function <span class="math notranslate nohighlight">\(f\)</span>. The target function <span class="math notranslate nohighlight">\(f\)</span> maps an <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> to produce an output <span class="math notranslate nohighlight">\(y^{(n)}=f\left(\mathbf{x}^{(n)}\right)\)</span>, hence giving a colored dots in the middle of the figure. The objective of learning is to learn a classifier which can classify the red from the blue. The space containing all the possible hypothesis is the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, which contains <span class="math notranslate nohighlight">\(h_{1}, \ldots, h_{M}\)</span>. The final hypothesis function returned by the learning algorithm is <span class="math notranslate nohighlight">\(h_S\)</span>.</p>
<figure class="align-default" id="ece595-fig4-1">
<img alt="../../../_images/ece595_fig4.1.jpeg" src="../../../_images/ece595_fig4.1.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 4 </span><span class="caption-text">[Left] Treat the cloud as the entire input space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and correspondingly the output space <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>. The dots are the in-samples <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>. The target function is a mapping <span class="math notranslate nohighlight">\(f\)</span> which takes <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> and send it to <span class="math notranslate nohighlight">\(y^{(n)}\)</span>. The red and blue colors indicate the class label. [Right] A learning algorithm picks a hypothesis function <span class="math notranslate nohighlight">\(h_S\)</span> from the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}=\left\{h_{1}, \ldots, h_{M}\right\}\)</span>. Note that some hypotheses are good, and some are bad. A good learning algorithm will pick a good hypothesis, and a bad learning algorithm can pick a bad hypothesis.</span><a class="headerlink" href="#ece595-fig4-1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#ece595-fig4-2"><span class="std std-numref">Fig. 5</span></a> illustrates what we called a probabilistic learning model. It is called a probabilistic learning model because there is an unknown distribution <span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span>. The training samples <span class="math notranslate nohighlight">\(\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right\}\)</span> are generated according to <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span>. The same <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span> also generates the testing samples <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. It is possible to lift the probabilistic assumption so that the training samples are drawn deterministically. In this case, the samples are simply fixed set of data points <span class="math notranslate nohighlight">\(\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right\}\)</span>. The deterministic assumption will make learning infeasible, as we will see shortly. Therefore, we shall mainly focus on the probabilistic assumption.</p>
<figure class="align-default" id="ece595-fig4-2">
<img alt="../../../_images/ece595_fig4.2.jpeg" src="../../../_images/ece595_fig4.2.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 5 </span><span class="caption-text">All essential components of a machine learning model.</span><a class="headerlink" href="#ece595-fig4-2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="is-learning-feasible">
<h2>Is Learning Feasible?<a class="headerlink" href="#is-learning-feasible" title="Permalink to this heading">#</a></h2>
<p>The first question we ask is: Suppose we have a training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, can we learn the target function <span class="math notranslate nohighlight">\(f\)</span> ? If the answer is YES, then we are all in business, because it means that we will be able to predict the data we have not seen. If the answer is NO, then machine learning is a lair and we should all go home, because it means that we can only memorize what we have seen but we will not be able to predict what we have not seen.</p>
<p>Interestingly, the answer to this question depends on how we define the training samples <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> ‘s. If <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> ‘s are deterministically defined, then the answer is NO because <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> can contain no information about the out-samples. Thus, there is no way to learn outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. If <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> ‘s are drawn from a probabilistic distribution, then the answer is YES because the distribution will tell us something about the out-samples. Let us look at these two situations one by one.</p>
<section id="learing-outside-the-training-set-mathcal-s-deterministic-case">
<h3>Learing Outside the Training Set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> (Deterministic Case)<a class="headerlink" href="#learing-outside-the-training-set-mathcal-s-deterministic-case" title="Permalink to this heading">#</a></h3>
<p>Let us look at the deterministic case. Consider a 3-dimensional input space <span class="math notranslate nohighlight">\(\mathcal{X}=\{0,1\}^{3}\)</span>. Each vector <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}\)</span> is a binary vector containing three elements, e.g., <span class="math notranslate nohighlight">\(\mathbf{x}=[0,0,1]^{T}\)</span> or <span class="math notranslate nohighlight">\(\mathbf{x}=[1,0,1]^{T}\)</span>. Since there are 3 elements and each element take a binary state, there are totally <span class="math notranslate nohighlight">\(2^{3}=8\)</span> input vectors in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>.</p>
<p>How about the number of possible target functions <span class="math notranslate nohighlight">\(f\)</span> can we have? Remember, a target function <span class="math notranslate nohighlight">\(f\)</span> is a mapping which converts an input vector <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to a label <span class="math notranslate nohighlight">\(y\)</span>. For simplicity let us assume that <span class="math notranslate nohighlight">\(f\)</span> maps <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to a binary output <span class="math notranslate nohighlight">\(y \in\{+1,-1\}\)</span>. Since there are 8 input vectors, we can think of <span class="math notranslate nohighlight">\(f\)</span> as a 8-bit vector, e.g., <span class="math notranslate nohighlight">\(f=[-1,+1,-1,-1,-1,+1,+1,+1]\)</span>, where each entry represents the output. If we do the calculation, we can show that there are totally <span class="math notranslate nohighlight">\(2^{8}=256\)</span> possible target functions.</p>
<p>Here is the learning problem. Can we learn <span class="math notranslate nohighlight">\(f\)</span> from <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> ? To ensure that <span class="math notranslate nohighlight">\(f\)</span> is unknown, we will not disclose what <span class="math notranslate nohighlight">\(f\)</span> is. Instead, we assume that there is a training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> containing 6 training samples <span class="math notranslate nohighlight">\(\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(6)}\right\}\)</span>. Corresponding to each <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> is the label <span class="math notranslate nohighlight">\(y^{(n)}\)</span>. The relationship between <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> and <span class="math notranslate nohighlight">\(y^{(n)}\)</span> is shown in the table below. So our task is to pick a target function from the 256 possible choices.</p>
<table class="table" id="truth-table-1">
<caption><span class="caption-number">Table 1 </span><span class="caption-text">Truth Table for 6 samples</span><a class="headerlink" href="#truth-table-1" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(y^{(n)}\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,1,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,1,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
</tbody>
</table>
<table class="table" id="boolean-function-truth-table">
<caption><span class="caption-number">Table 2 </span><span class="caption-text">Function Table</span><a class="headerlink" href="#boolean-function-truth-table" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(y^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(h_S\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_1\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_2\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_3\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_4\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,1,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,1,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,1,0]\)</span></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\circ / \bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,1,1]\)</span></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\circ / \bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
</tbody>
</table>
<p>Since we have seen 6 out of 8 input vectors in <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, there remains two input vectors we have not seen and need to predict. Thus, we can quickly reduce the number of possible target functions to <span class="math notranslate nohighlight">\(2^{2}=4\)</span>. Let us call these target functions <span class="math notranslate nohighlight">\(f_{1}, f_{2}, f_{3}\)</span> and <span class="math notranslate nohighlight">\(f_{4}\)</span>. The boolean structure of these target functions are shown on the right hand side of the table above. Note that the first 6 entries of each <span class="math notranslate nohighlight">\(f_{i}\)</span> is fixed because they are already observed in <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
<p>In the table above we write down the final hypothesis function <span class="math notranslate nohighlight">\(h_S\)</span>. The last two entries of <span class="math notranslate nohighlight">\(h_S\)</span> is to be determined by the learning algorithm. If the learning algorithm decides <span class="math notranslate nohighlight">\(\circ\)</span>, then we will have both <span class="math notranslate nohighlight">\(\circ\)</span>. If the learning algorithm decides a <span class="math notranslate nohighlight">\(\circ\)</span> followed by a <span class="math notranslate nohighlight">\(\bullet\)</span>, then
we will have a <span class="math notranslate nohighlight">\(\circ\)</span> followed by a <span class="math notranslate nohighlight">\(\bullet\)</span>. So the final hypothesis function <span class="math notranslate nohighlight">\(h_S\)</span> can be one of the 4 possible choices, same number of choices of the target functions.</p>
<p>Since we assert that <span class="math notranslate nohighlight">\(f\)</span> is unknown, by only observing the first 6 entries we will have 4 equally good hypothesis functions. They are equally good, because no matter which hypothesis function we choose, the last 2 entries will agree or disagree with the target depending on which one is the true target function. For example, on the left hand side of the table below, the true target function is <span class="math notranslate nohighlight">\(f_{1}\)</span> and so our <span class="math notranslate nohighlight">\(h_S\)</span> is correct. But if the true target function is <span class="math notranslate nohighlight">\(f_{3}\)</span>, e.g., the right hand side of the table, then our <span class="math notranslate nohighlight">\(h_S\)</span> is wrong. We can repeat the experiment by choosing another <span class="math notranslate nohighlight">\(h_S\)</span>, and we can prove that not matter which <span class="math notranslate nohighlight">\(h_S\)</span> we choose, we only have <span class="math notranslate nohighlight">\(25 \%\)</span> chance of picking the correct one. This is the same as drawing a lottery from 4 numbers. The information we learned from the training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> does not allow us to infer anything outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
<table class="table" id="boolean-function-truth-table-f1">
<caption><span class="caption-number">Table 3 </span><span class="caption-text">Function Table with <span class="math notranslate nohighlight">\(f_1\)</span> as True Function</span><a class="headerlink" href="#boolean-function-truth-table-f1" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(y^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(h_S\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\textcolor{red}{f_1}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_2\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_3\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_4\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,1,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,1,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,1,0]\)</span></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,1,1]\)</span></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
</tbody>
</table>
<table class="table" id="boolean-function-truth-table-f3">
<caption><span class="caption-number">Table 4 </span><span class="caption-text">Function Table with <span class="math notranslate nohighlight">\(f_3\)</span> as True Function</span><a class="headerlink" href="#boolean-function-truth-table-f3" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(y^{(n)}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(h_S\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_1\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_2\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\textcolor{red}{f_3}\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(f_4\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([0,1,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([0,1,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,0,0]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,0,1]\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\([1,1,0]\)</span></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\([1,1,1]\)</span></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\circ\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\bullet\)</span></p></td>
</tr>
</tbody>
</table>
<p>The above analysis shows that learning is infeasible if we have a deterministic generator generating the training samples. The argument holds regardless which learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> we use, and what hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> we choose. Whether <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> contains the correct hypothesis function, and whether <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> can pick the correct hypothesis, there is no difference in terms of predicting outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. We can also extend the analysis from binary function to general learning problem. As long as <span class="math notranslate nohighlight">\(f\)</span> remains unknown, it is impossible to predict outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
</section>
<section id="identically-and-independently-distributed-random-variables">
<h3>Identically and Independently Distributed Random Variables<a class="headerlink" href="#identically-and-independently-distributed-random-variables" title="Permalink to this heading">#</a></h3>
<p>For the following section, we will discuss the case from a probabilistic perspective.</p>
<p>However, we will need to assume that the random variables are identically and independently distributed (i.i.d.). This means that the random variables are drawn from the same distribution and are independent of each other.</p>
<p>For formal definition, see <span class="xref myst"></span>.</p>
<p>This assumption is ubiquitous in machine learning. Not only does it simplify the analysis,
it also solidifies many theories governing the framework underlying machine learning.</p>
<p>This assumption is a strong one and is not always true in practice. However, it is a reasonable one.</p>
<p>See extracted paragraph from <a class="reference external" href="https://mostafa-samir.github.io">Machine Learning Theory</a> below:</p>
<p>This assumption is essential for us. We need it to start using the tools form probability theory to investigate our generalization probability, and it’s a very reasonable assumption because:</p>
<ol class="arabic simple">
<li><p>It’s more likely for a dataset used for inferring about an underlying probability distribution to be all sampled for that same distribution. If this is not the case, then the statistics we get from the dataset will be noisy and won’t correctly reflect the target underlying distribution.</p></li>
<li><p>It’s more likely that each sample in the dataset is chosen without considering any other sample that has been chosen before or will be chosen after. If that’s not the case and the samples are dependent, then the dataset will suffer from a bias towards a specific direction in the distribution, and hence will fail to reflect the underlying distribution correctly.</p></li>
</ol>
</section>
<section id="learing-outside-the-training-set-mathcal-s-probabilistic-case">
<h3>Learing Outside the Training Set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> (Probabilistic Case)<a class="headerlink" href="#learing-outside-the-training-set-mathcal-s-probabilistic-case" title="Permalink to this heading">#</a></h3>
<p>The deterministic analysis gives us a pessimistic result. Now, let us look at a probabilistic analysis. On top of the training set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, we pose an assumption. We assume that all <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}\)</span> is drawn from a distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span>. This includes all the in-samples <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)} \in \mathcal{S}\)</span> and the out-samples <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}\)</span>. At a first glance, putting a distributional assumption <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span> does not seem any different from the deterministic case: We still have a training set <span class="math notranslate nohighlight">\(\mathcal{S}=\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right\}\)</span>, and <span class="math notranslate nohighlight">\(f\)</span> is still unknown. How can we learn the unknown <span class="math notranslate nohighlight">\(f\)</span> using just the training samples?</p>
<p>Suppose that we pick a hypothesis function <span class="math notranslate nohighlight">\(h\)</span> from the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. For every in-sample <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span>, we check whether the output returned by <span class="math notranslate nohighlight">\(h\)</span> is the same as the output returned by <span class="math notranslate nohighlight">\(f\)</span>, i.e., <span class="math notranslate nohighlight">\(\left\{h\left(\mathbf{x}^{(n)}\right)=f\left(\mathbf{x}^{(n)}\right)\right\}\)</span>, for <span class="math notranslate nohighlight">\(n=1, \ldots, N\)</span>. If <span class="math notranslate nohighlight">\(\left\{h\left(\mathbf{x}^{(n)}\right)=f\left(\mathbf{x}^{(n)}\right)\right\}\)</span>, then we say that the in-sample <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> is correctly classified in the training. If <span class="math notranslate nohighlight">\(\left\{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)\right\}\)</span>, then we say that <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> is incorrectly classified. Averaging over all the <span class="math notranslate nohighlight">\(N\)</span> samples, we obtain a quantity called the in-sample error, or the training error. In our
<span class="xref myst">machine learning notations</span>,
the in-sample error is our Empirical Risk Minimization (ERM) function <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{S}}\left(h\right)\)</span>.</p>
<div class="proof definition admonition" id="prf:definition:zero-one-loss">
<p class="admonition-title"><span class="caption-number">Definition 7 </span> (Zero-One Loss)</p>
<section class="definition-content" id="proof-content">
<p>The zero-one loss is defined as</p>
<div class="math notranslate nohighlight" id="equation-eq-zero-one-loss">
<span class="eqno">(15)<a class="headerlink" href="#equation-eq-zero-one-loss" title="Permalink to this equation">#</a></span>\[
\mathcal{L}\left(\left(\mathbf{x}, y\right), h\right) = \boldsymbol{1}\left\{h\left(\mathbf{x}\right) \neq y\right\}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{1}\left\{h\left(\mathbf{x}\right) \neq y\right\}\)</span> is the indicator function that returns 1 if the condition is true, and 0 otherwise.</p>
</section>
</div><p>With this,</p>
<div class="proof definition admonition" id="prf:definition:in-sample-error">
<p class="admonition-title"><span class="caption-number">Definition 8 </span> (In-Sample Error (Empirical Risk Minimization))</p>
<section class="definition-content" id="proof-content">
<p>Consider a training set <span class="math notranslate nohighlight">\(\mathcal{S} = \left\{(\mathbf{x}^{(1)}, y^{(1)}), (\mathbf{x}^{(2)}, y^{(2)}), \ldots, (\mathbf{x}^{(N)}, y^{(N)})\right\} \overset{\text{iid}}{\sim} \mathbb{P}_{\mathcal{D}}\)</span>, and a target function <span class="math notranslate nohighlight">\(f\)</span>. The in-sample error (or the training error) of a hypothesis function <span class="math notranslate nohighlight">\(h \in \mathcal{H}\)</span> is the empirical average of the zero-one loss <span class="math notranslate nohighlight">\(\mathcal{L}\left(\left(\mathbf{x}, y\right), h\right) : =\left\{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)\right\}\)</span> :</p>
<div class="math notranslate nohighlight" id="equation-eq-in-sample-error">
<span class="eqno">(16)<a class="headerlink" href="#equation-eq-in-sample-error" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{aligned}
\hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} :&amp;= \frac{1}{N} \sum_{n=1}^N \mathcal{L}\left(\left(\mathbf{x}^{(n)}, y^{(n)}\right), h\right) \\
&amp;= \frac{1}{N} \sum_{n=1}^N \boldsymbol{1}\left\{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)\right\} \\
&amp;= \mathbb{E}_{\mathcal{S}}\left[\mathcal{L}\left(\left(\mathbf{x}, y\right), h\right)\right]
\end{aligned}
\end{split}\]</div>
</section>
</div><p>Training error is the amount of error we have during the training process. A good learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> should pick a hypothesis <span class="math notranslate nohighlight">\(h\)</span> that gives low training error. Training error is sometimes called the cost (empirical risk) function (or the loss function) when we post the learning problem as an optimization. Thus, picking a good hypothesis is equivalent to minimizing the training error.</p>
<p>How about the out-samples? Since we assume that <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is drawn from a distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span>, we can define the out-sample error as the probability that <span class="math notranslate nohighlight">\(\{h(\mathbf{x}) \neq f(\mathbf{x})\}\)</span>, for all <span class="math notranslate nohighlight">\(\mathbf{x} \sim \mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span>.</p>
<div class="proof definition admonition" id="prf:definition:out-sample-error">
<p class="admonition-title"><span class="caption-number">Definition 9 </span> (Out-Sample Error (Generalization Error))</p>
<section class="definition-content" id="proof-content">
<p>Consider an input space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> containing elements <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> drawn from a distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}\)</span>, and a target function <span class="math notranslate nohighlight">\(f\)</span>. The out-sample error (or the true risk/testing error) of a hypothesis function <span class="math notranslate nohighlight">\(h \in \mathcal{H}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} :&amp;= \mathbb{P} \left[\left\{h\left(\mathbf{x}\right) \neq f\left(\mathbf{x}\right)\right\}\right] \\
&amp;= \mathbb{E}_{\mathcal{D}}\left[\mathcal{L}((\mathbf{x}, y), h)\right] \\
&amp;= \mathbb{E}_{\mathcal{D}}\left[\boldsymbol{1}\left\{h\left(\mathbf{x}\right) \neq f\left(\mathbf{x}\right)\right\}\right] \\
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{P}[\cdot]\)</span> measures the probability of the statement based on the distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span>.</p>
</section>
</div><p>How did we derive from a probability of classifying one sample wrongly to the expectation over the loss function?</p>
<p>Since <span class="math notranslate nohighlight">\(\boldsymbol{1}\)</span> is a binary function, the out-sample error is the expected value of a sample being misclassified over the entire distribution:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}= &amp; \mathbb{P}[h(\mathbf{x}) \neq f(\mathbf{x})] \\
= &amp; \underbrace{\boldsymbol{1}_{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)}}_{=1} \mathbb{P}\left\{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)\right\} \\
&amp; \quad+\underbrace{\boldsymbol{1}_{h\left(\mathbf{x}^{(n)}\right)=f\left(\mathbf{x}^{(n)}\right)}}_{=0}\left(1-\mathbb{P}\left\{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)\right\}\right) \\
= &amp; \mathbb{E}_{\mathcal{D}}\left\{\boldsymbol{1}_{h\left(\mathbf{x}^{(n)}\right) \neq f\left(\mathbf{x}^{(n)}\right)}\right\} .
\end{aligned}
\end{split}\]</div>
<p>Therefore, the relationship between the in-sample error <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}\)</span> and out-sample error <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}\)</span> is equivalent to the relationship between the empirical average and the population mean of a random variable, where the random variable is the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>.</p>
<p><a class="reference internal" href="#ece595-fig4-3"><span class="std std-numref">Fig. 6</span></a> shows how an in-sample error is computed.</p>
<figure class="align-default" id="ece595-fig4-3">
<img alt="../../../_images/ece595_fig4.3.jpeg" src="../../../_images/ece595_fig4.3.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 6 </span><span class="caption-text"><span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}\)</span> is evaluated using the training data, whereas <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\)</span> is evaluated using the testing sample. Here the author uses
<span class="math notranslate nohighlight">\(\mathbb{E}_{\text{in}}\)</span> and <span class="math notranslate nohighlight">\(\mathbb{E}_{\text{out}}\)</span> to denote the in-sample and out-sample error, respectively.</span><a class="headerlink" href="#ece595-fig4-3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>To this end, we recap of what we have:</p>
<p>We have a hypothesis space <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> of functions that we can use to approximate the underlying distribution. We have a loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> that we can use to measure the quality of our approximation. We have a learning algorithm that can be used to find the best function in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> that approximates the underlying distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. We have a test dataset <span class="math notranslate nohighlight">\(\mathcal{S}_{\mathrm{\text{test}}}\)</span> sampled <span class="math notranslate nohighlight">\(\iid\)</span> from the underlying and unknown distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<p>We want to know the probability that our learning algorithm will find a function in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> that approximates the underlying distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> well enough to generalize well to the test dataset <span class="math notranslate nohighlight">\(\mathcal{S}_{\mathrm{\text{test}}}\)</span>.</p>
<p>In other words, the learning problem at hand is to find a hypothesis <span class="math notranslate nohighlight">\(h \in \mathcal{H}\)</span> that minimizes the expected risk <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}\)</span> over the
training samples <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> which is generated by the underlying unknown true distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> such that
the generalization risk/error <span class="math notranslate nohighlight">\(\mathcal{R} \leq \hat{\mathcal{R}} + \epsilon\)</span> with high probability.</p>
<p>How can we do that? Let’s start with the Law of Large Numbers.</p>
<div class="proof remark admonition" id="remark-learning-problem-notations">
<p class="admonition-title"><span class="caption-number">Remark 8 </span> (Notation)</p>
<section class="remark-content" id="proof-content">
<p>It should be clear from context that <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> is the <strong>generalization error</strong> of the hypothesis
<span class="math notranslate nohighlight">\(h\)</span> over the entire distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. In other words, this is the expected error based on
the entire distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<p>On the other hand, <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}\)</span> is the <strong>empirical risk</strong> of the hypothesis <span class="math notranslate nohighlight">\(h\)</span> over the
training samples <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
</section>
</div></section>
<section id="the-generalization-gap">
<h3>The Generalization Gap<a class="headerlink" href="#the-generalization-gap" title="Permalink to this heading">#</a></h3>
<div class="proof definition admonition" id="def-generalization-gap">
<p class="admonition-title"><span class="caption-number">Definition 10 </span> (Generalization Gap)</p>
<section class="definition-content" id="proof-content">
<p>Given a sample set <span class="math notranslate nohighlight">\(\mathcal{S} = \left\{\left(\mathbf{x}^{(n)}, y^{(n)}\right)\right\}_{n=1}^{N}\)</span>
drawn <span class="math notranslate nohighlight">\(\iid\)</span> from the distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>, a hypothesis <span class="math notranslate nohighlight">\(h_S \in \mathcal{H}\)</span> learnt by the
algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> on <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, and a specific definition of loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> (i.e. zero-one loss), the <strong>generalization gap</strong> is defined as:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\epsilon_{gen}(h_S) = \left|\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h_S)\right\} - \hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h_S)\right\}\right|.
\end{aligned}
\]</div>
</section>
</div></section>
</section>
<section id="the-law-of-large-numbers">
<h2>The Law of Large Numbers<a class="headerlink" href="#the-law-of-large-numbers" title="Permalink to this heading">#</a></h2>
<p>Recall that in the section <a class="reference internal" href="../empirical_risk_minimization/concept.html#emprical-risk-approximates-true-risk"><span class="std std-ref">Empirical Risk Minimization approximates True Risk Minimization</span></a> of <a class="reference internal" href="../empirical_risk_minimization/concept.html"><span class="doc std std-doc">the chapter on ERM</span></a>, we mentioned that the the Empirical Risk
approximates the True Risk as the number of samples <span class="math notranslate nohighlight">\(N\)</span> grows. This is the <span class="xref myst">Law of Large Numbers</span> that was mentioned in an earlier <span class="xref myst">chapter</span>.</p>
<p>We restate the Weak Law of Large Numbers from <code class="xref prf prf-ref docutils literal notranslate"><span class="pre">theorem-weak-law-of-large-numbers</span></code> below again, but with notation more aligned to our notations in <span class="xref myst">machine learning notations chapter</span>. In particular, we use <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>
suggesting that the random variable is the loss value of <span class="math notranslate nohighlight">\(\mathcal{L}(\cdot)\)</span>. In other words,
<span class="math notranslate nohighlight">\(\mathcal{L}^{(n)}\)</span> is treated as realizations of the random variable <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> on the <span class="math notranslate nohighlight">\(n\)</span>-th sample.</p>
<div class="proof theorem admonition" id="theorem-weak-law-of-large-numbers-restated">
<p class="admonition-title"><span class="caption-number">Theorem 5 </span> (Weak Law of Large Numbers)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\mathcal{L}^{(1)}, \ldots, \mathcal{L}^{(N)}\)</span> be <span class="math notranslate nohighlight">\(\iid\)</span> random variables with <strong>common</strong> mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Each <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is distributed by the same probability distribution <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> (<span class="math notranslate nohighlight">\(\mathcal{D}\)</span>).</p>
<p>Let <span class="math notranslate nohighlight">\(\bar{\mathcal{L}}\)</span> be the sample average defined in <code class="xref eq docutils literal notranslate"><span class="pre">eq:sample-average</span></code> and <span class="math notranslate nohighlight">\(\mathbb{E}[\mathcal{L}^2] &lt; \infty\)</span>.</p>
<p>Then, for any <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>, we have</p>
<div class="math notranslate nohighlight" id="equation-eq-weak-law-of-large-numbers-3">
<span class="eqno">(17)<a class="headerlink" href="#equation-eq-weak-law-of-large-numbers-3" title="Permalink to this equation">#</a></span>\[
\lim_{N\to\infty}\mathbb{P}\left[\left|\underset{\mathcal{L} \sim P}{\mathbb{E}}[\mathcal{L}]-\frac{1}{N} \sum_{n=1}^N \mathbf{x}^{(n)}\right|&gt;\epsilon\right] := \lim_{N\to\infty} \mathbb{P}\left[\left|\mu - \bar{\mathcal{L}}^{(N)} \right| &gt; \epsilon\right] = 0
\]</div>
<p>This means that</p>
<div class="math notranslate nohighlight" id="equation-eq-weak-law-of-large-numbers-4">
<span class="eqno">(18)<a class="headerlink" href="#equation-eq-weak-law-of-large-numbers-4" title="Permalink to this equation">#</a></span>\[
\bar{\mathcal{L}} \xrightarrow{p} \underset{\mathcal{L} \sim P}{\mathbb{E}}[\mathcal{L}] \quad \text{as } N \to \infty
\]</div>
</section>
</div><p>In other words, as sample size <span class="math notranslate nohighlight">\(N\)</span> grows, the probability that the sample average <span class="math notranslate nohighlight">\(\bar{\mathcal{L}}\)</span> differs from the population mean <span class="math notranslate nohighlight">\(\mu\)</span> by more than <span class="math notranslate nohighlight">\(\epsilon\)</span> approaches zero.
Note this is not saying that the <em>probability</em> of the difference between the sample average and the population mean is more than epsilon is zero, the expression is the probability that the difference is more than epsilon! So in laymen terms, as <span class="math notranslate nohighlight">\(N\)</span> grows, then it is guaranteed
that the difference between the sample average and the population mean is no more than <span class="math notranslate nohighlight">\(\epsilon\)</span>. This seems strong since <span class="math notranslate nohighlight">\(\epsilon\)</span> can be arbitrarily small, but it is still a probability bound.</p>
<p>Then recall that the True Risk Function is defined as:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} := \mathbb{E}_{\mathcal{D}}\left[\mathcal{L}((\mathbf{x}, y), h)\right]
\]</div>
<p>and the Empirical Risk Function is defined as:</p>
<div class="math notranslate nohighlight">
\[
\hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} := \frac{1}{N} \sum_{n=1}^N \mathcal{L}\left(\left(\mathbf{x}^{(n)}, y^{(n)}\right), h\right)
\]</div>
<p>Furthermore, since <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is defined to be a random variable representing the loss/error of a single sample, then
we can rewrite the True Risk Function as:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} := \mathbb{E}_{\mathcal{D}}\left[\mathcal{L}\left((\mathbf{x}, y), h\right)\right]
\]</div>
<p>which means that the True Risk Function is the expected loss/error of all possible samples. This is because
we treat <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> as a <strong>random variable</strong> and we take the expected value of it.</p>
<div class="proof remark admonition" id="remark-random-variable-is-a-function">
<p class="admonition-title"><span class="caption-number">Remark 9 </span> (Random Variable is a Function)</p>
<section class="remark-content" id="proof-content">
<p>The notation might seem overloaded and abused, but since random variable in itself is a function,
and <span class="math notranslate nohighlight">\(\mathcal{L}(\cdot)\)</span> is also a function mapping states <span class="math notranslate nohighlight">\((\mathbf{x}, y)\)</span> to a real number,
then we can treat <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> as a random variable representing the loss/error of a single sample.</p>
</section>
</div><p>Now, define <span class="math notranslate nohighlight">\(\mathcal{L}^{(n)}\)</span> to be the loss/error of the <span class="math notranslate nohighlight">\(n\)</span>-th sample in the train dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.
Then we can rewrite the Empirical Risk Function as:</p>
<div class="math notranslate nohighlight">
\[
\hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} := \frac{1}{N} \sum_{n=1}^N \mathcal{L}^{(n)}
\]</div>
<p>which means that the Empirical Risk Function is the average loss/error of all training samples.</p>
<p>Notice that they both have exactly the same form as the Weak Law of Large Numbers, so we can apply the Weak Law of Large Numbers to the True Risk Function and the Empirical Risk Function.
This natural application of the Weak Law of Large Numbers allows us to answer the following question (also in <a class="reference internal" href="intro.html#equation-eq-learning-problem-solvable">(14)</a>):</p>
<div class="proof remark admonition" id="remark-summary-1">
<p class="admonition-title"><span class="caption-number">Remark 10 </span> (Summary)</p>
<section class="remark-content" id="proof-content">
<p>Given a dataset <span class="math notranslate nohighlight">\(\mathcal{S} = \left\{\left(\mathbf{x}^{(n)}, y^{(n)}\right)\right\}_{n=1}^N\)</span>, and a <strong>fixed</strong> and <strong>single</strong> hypothesis <span class="math notranslate nohighlight">\(h\)</span>, the Weak Law of Large Numbers tells us that as the number of samples in your training set increases from <span class="math notranslate nohighlight">\(N\)</span> to <span class="math notranslate nohighlight">\(\infty\)</span>, the Empirical Risk Function will converge to the True Risk Function.</p>
<div class="math notranslate nohighlight" id="equation-eq-convergence-of-empirical-risk-to-true-risk">
<span class="eqno">(19)<a class="headerlink" href="#equation-eq-convergence-of-empirical-risk-to-true-risk" title="Permalink to this equation">#</a></span>\[
\lim_{N \rightarrow \infty} \mathbb{P}\left[\left|\mathcal{R}_{\mathcal{D}}(h) - \hat{\mathcal{R}}_{\mathcal{S}}(h)\right|&gt;\epsilon\right]=0
\]</div>
<p>where the notation of <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> and <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}\)</span> are simplified to only contain <span class="math notranslate nohighlight">\(h\)</span> for readability.</p>
<p>Well, this is something. At least we know that if we can bump up the number of samples
in our training set to <span class="math notranslate nohighlight">\(\infty\)</span>, then we can guarantee that the Empirical Risk Function will be close to the True Risk Function. But this is not really very useful, because we can’t really get <span class="math notranslate nohighlight">\(\infty\)</span> samples in practice.</p>
<p>Can we do better by finding an upper bound on the
right hand side of <a class="reference internal" href="#equation-eq-convergence-of-empirical-risk-to-true-risk">(19)</a>? This bound has to be
a function of the number of samples <span class="math notranslate nohighlight">\(N\)</span> so we at least know how many samples we need to get a good approximation of the True Risk Function, or even if we cannot get more samples, then what
is the theoretical maximum error we can expect from the Empirical Risk Function?</p>
</section>
</div></section>
<section id="hoeffding-s-inequality">
<h2>Hoeffding’s Inequality<a class="headerlink" href="#hoeffding-s-inequality" title="Permalink to this heading">#</a></h2>
<p>Earlier, we also saw the discussion of this inequality in a previous <span class="xref myst">chapter</span>. This inequality will help us answer the question above.</p>
<p>We restate the Hoeffding’s Inequality here, but in machine learning context:</p>
<div class="proof theorem admonition" id="theorem-hoeffding-inequality-restated">
<p class="admonition-title"><span class="caption-number">Theorem 6 </span> (Hoeffding’s Inequality)</p>
<section class="theorem-content" id="proof-content">
<p>Consider a dataset <span class="math notranslate nohighlight">\(\mathcal{S} = \left\{\left(\mathbf{x}^{(n)}, y^{(n)}\right)\right\}_{n=1}^N\)</span> drawn i.i.d. from an unknown distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. Let the hypothesis
set <span class="math notranslate nohighlight">\(\mathcal{H} = \left\{h_{1}, \ldots, h_{K}\right\}\)</span> be a finite set of hypotheses. Then, suppose we fix a hypothesis <span class="math notranslate nohighlight">\(h\)</span> in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> (for any <span class="math notranslate nohighlight">\(h \in \mathcal{H}\)</span>) before we look at the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, which means
we have not learnt <span class="math notranslate nohighlight">\(h_S\)</span> yet.</p>
<p>Furthermore, let <span class="math notranslate nohighlight">\(\mathcal{L}((\mathbf{x}, y), h)\)</span> be the loss/error of a single sample <span class="math notranslate nohighlight">\((\mathbf{x}, y)\)</span> with respect to the hypothesis <span class="math notranslate nohighlight">\(h\)</span> such that
<span class="math notranslate nohighlight">\(0 \leq \mathcal{L}((\mathbf{x}, y), h) \leq 1\)</span> and <span class="math notranslate nohighlight">\(\mathbb{E}\left[\mathcal{L}((\mathbf{x}, y), h)\right]\)</span> be the expected loss/error over the entire distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<p>We can then define a sequence of random variables <span class="math notranslate nohighlight">\(\left\{\mathcal{L}^{(n)}\right\}_{n=1}^N\)</span> such that <span class="math notranslate nohighlight">\(\mathcal{L}^{(n)}\)</span> is the loss/error of the <span class="math notranslate nohighlight">\(n\)</span>-th sample in the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
<p>Then for any <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>, we have the following bound:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}\left[\left|\mathbb{E}\left[\mathcal{L}((\mathbf{x}, y), h)\right] - \frac{1}{N} \sum_{n=1}^N \mathcal{L}^{(n)}\left(\left(\mathbf{x}^{(n)}, y^{(n)}\right), h\right)\right|&gt;\epsilon\right] &amp;= \mathbb{P}\left[\left|\mathcal{R}_{\mathcal{D}}(h) - \hat{\mathcal{R}}_{\mathcal{S}}(h)\right|&gt;\epsilon\right] \\
&amp;\leq 2 e^{-2 \epsilon^{2} N}
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the number of samples in the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> and <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}\)</span> are the True Risk Function and the Empirical Risk Function respectively.</p>
</section>
</div><div class="proof remark admonition" id="remark-things-to-note">
<p class="admonition-title"><span class="caption-number">Remark 11 </span> (Things to Note (Important))</p>
<section class="remark-content" id="proof-content">
<ol class="arabic simple">
<li><p>Note that both <span class="math notranslate nohighlight">\(\mathcal{L}((\mathbf{x}, y), h)\)</span> and the samples
<span class="math notranslate nohighlight">\(\left(\mathbf{x}^{(n)}, y^{(n)}\right)\)</span> are drawn from the same distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p></li>
<li><p><strong>Important</strong>: Note carefully this <span class="math notranslate nohighlight">\(h\)</span> is even picked even before the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is generated from <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. This is not a trivial concept and requires quite some justification. See <a class="reference internal" href="#why-must-h-be-fixed"><span class="std std-ref">Why must h be fixed and defined before generating the dataset \mathcal{S}?</span></a>.</p></li>
<li><p>The random variable must be bounded between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>, so your loss function must be bounded between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>. This is simple to do usually since you usually apply sigmoid/softmax to your output to get a probability between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span> to feed into your loss function.</p></li>
</ol>
</section>
</div><p>As the number of training samples <span class="math notranslate nohighlight">\(N\)</span> grows, the in-sample error <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h)\)</span> (which is the training error) converges exponentially to the out-sample error <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h)\)</span> (which is the testing error). The in-sample error <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h)\)</span> is something we can compute numerically using the training set. The out-sample error is an unknown quantity because we do not know the target function <span class="math notranslate nohighlight">\(f\)</span>. Hoeffding inequality says even though we do not know <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h)\)</span>, for large enough <span class="math notranslate nohighlight">\(N\)</span> the in-sample error <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h)\)</span> will be sufficiently close to <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h)\)</span>. Therefore, we will be able to tell how good the hypothesis function is without accessing the unknown target function.</p>
<section id="comparing-hoeffding-s-inequality-with-the-chebyshev-s-inequality">
<h3>Comparing Hoeffding’s Inequality with the Chebyshev’s Inequality<a class="headerlink" href="#comparing-hoeffding-s-inequality-with-the-chebyshev-s-inequality" title="Permalink to this heading">#</a></h3>
<p>Let us take a quick comparison between the Hoeffding inequality and the Chebyshev inequality. Chebyshev inequality states that</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left[\left|\mathbb{E}\left[\mathcal{L}((\mathbf{x}, y), h)\right] - \frac{1}{N} \sum_{n=1}^N \mathcal{L}^{(n)}\right|&gt;\epsilon\right]\leq \frac{\sigma^{2}}{\epsilon^{2} N} .
\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma^{2}\)</span> is the variance of the loss/error <span class="math notranslate nohighlight">\(\mathcal{L}((\mathbf{x}, y), h)\)</span>.</p>
<p>If we let <span class="math notranslate nohighlight">\(2 e^{-2 \epsilon^{2} N} \leq \delta\)</span> for some <span class="math notranslate nohighlight">\(\delta\)</span> in Hoeffding inequality, and <span class="math notranslate nohighlight">\(\frac{\sigma^{2}}{\epsilon^{2} N}\)</span> for some <span class="math notranslate nohighlight">\(\delta\)</span> in Chebyshev inequality, we can easily see that the two inequalities imply</p>
<div class="math notranslate nohighlight">
\[
N \geq-\frac{1}{2 \epsilon^{2}} \log \frac{\delta}{2}, \quad \text { and } \quad N \geq \frac{\sigma^{2}}{\epsilon^{2} \delta} .
\]</div>
<p>For simplicity let us assume that <span class="math notranslate nohighlight">\(\sigma=1, \epsilon=0.1\)</span> and <span class="math notranslate nohighlight">\(\delta=0.01\)</span>. Then the above calculation will give <span class="math notranslate nohighlight">\(N \geq 265\)</span> for Hoeffding whereas <span class="math notranslate nohighlight">\(N \geq 10000\)</span> for Chebyshev. That means, Hoeffding inequality has a much lower prediction of how many samples we need to achieve an error of <span class="math notranslate nohighlight">\(\delta \leq 0.01\)</span>.</p>
<figure class="align-default" id="ece595-fig4-4">
<img alt="../../../_images/ece595_fig4.4.jpeg" src="../../../_images/ece595_fig4.4.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 7 </span><span class="caption-text">Comparing Hoeffding inequality and Chebyshev inequality to predict the actual probability bound.</span><a class="headerlink" href="#ece595-fig4-4" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>We see that Chebyshev is a more <strong>conservative</strong> bound than Hoeffding, and is less
strong than Hoeffding since Hoeffding does not need to know <em>anything</em> about the
random variable <span class="math notranslate nohighlight">\(\mathcal{L}((\mathbf{x}, y), h)\)</span> on the right hand side of the inequality.</p>
</section>
<section id="example-hoeffding-s-inequality-in-classification">
<h3>Example: Hoeffding’s Inequality in Classification<a class="headerlink" href="#example-hoeffding-s-inequality-in-classification" title="Permalink to this heading">#</a></h3>
<p><em>Notation may be slightly different from the rest of the section.</em></p>
<p>Following exampled adapted from <a class="reference external" href="http://faculty.washington.edu/yenchic/18W_425/Lec15_conc.pdf">STAT425</a>.</p>
<p>A powerful feature of the Hoeffding’s inequality is that it holds regardless of the classifier. Namely, even if we are considering many different types of classifiers, some are decision trees, some are kNN, some are logistic regression, they all satisfy equation above.</p>
<p>What this means is this inequality holds for any classifier <span class="math notranslate nohighlight">\(h\)</span> and any loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>.</p>
<p>So even if your loss function is not <span class="math notranslate nohighlight">\(0-1\)</span> loss, you can still use the Hoeffding’s inequality.
Say cross-entropy loss, then you just need to know that the difference between the expected loss of the classifier and the empirical loss of the classifier is bounded by the right hand side of the inequality.</p>
</section>
</section>
<section id="pac-framework">
<h2>PAC Framework<a class="headerlink" href="#pac-framework" title="Permalink to this heading">#</a></h2>
<p>The probabilistic analysis is called a probably approximately correct (PAC) framework. The word <span class="math notranslate nohighlight">\(\mathrm{P}-\mathrm{A}-\mathrm{C}\)</span> comes from three principles of the Hoeffding inequality:</p>
<ul class="simple">
<li><p><strong>Probably</strong>: We use the probability <span class="math notranslate nohighlight">\(\textcolor{red}{\mathbb{P}}\left[\left|\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} - \hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}\right|&gt;\epsilon \right] \leq 2 e^{-2 \epsilon^{2} N}\)</span> as a measure to quantify the error.</p></li>
<li><p><strong>Approximately</strong>: The in-sample error is an approximation of the out-sample error, as given by <span class="math notranslate nohighlight">\(\mathbb{P}\left[\textcolor{red}{\left|\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} - \hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}\right|&gt;\epsilon}\right] \leq 2 e^{-2 \epsilon^{2} N}\)</span>. The approximation error is controlled by <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p></li>
<li><p><strong>Correct</strong>: The error is bounded by the right hand side of the Hoeffding inequality: <span class="math notranslate nohighlight">\(\mathbb{P}\left[\left|\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\} - \hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}\right|&gt;\epsilon\right] \textcolor{red}{\leq 2 e^{-2 \epsilon^{2} N}}\)</span>. The accuracy is controlled by <span class="math notranslate nohighlight">\(N\)</span> for a fixed <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p></li>
</ul>
</section>
<section id="hoeffding-inequality-is-invalid-for-h-s-learnt-from-mathcal-s">
<h2>Hoeffding Inequality is Invalid for <span class="math notranslate nohighlight">\(h_S\)</span> learnt from <span class="math notranslate nohighlight">\(\mathcal{S}\)</span><a class="headerlink" href="#hoeffding-inequality-is-invalid-for-h-s-learnt-from-mathcal-s" title="Permalink to this heading">#</a></h2>
<p>Now, there is one last problem we need to resolve. The above Hoeffding inequality holds for a fixed hypothesis function <span class="math notranslate nohighlight">\(h\)</span>. This means that <span class="math notranslate nohighlight">\(h\)</span> is already chosen before we generate the dataset. If we allow <span class="math notranslate nohighlight">\(h\)</span> to change after we have generated the dataset, then the Hoeffding inequality is no longer valid. What do we mean by after generating the dataset? In any learning scenario, we are given a training dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. Based on this dataset, we have to choose a hypothesis function <span class="math notranslate nohighlight">\(h_S\)</span> from the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. The hypothesis <span class="math notranslate nohighlight">\(h_S\)</span> we choose depends on what samples are inside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> and which learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> we use. So <span class="math notranslate nohighlight">\(h_S\)</span> changes after the dataset is generated.</p>
<p>Now this is a non-trivial problem, and to fully understand this requires close scrutiny.
Recall in <a class="reference internal" href="#remark-things-to-note">Remark 11</a>’s point 2, we said that <span class="math notranslate nohighlight">\(h\)</span> is fixed prior to
generating the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> and using <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> to learn <span class="math notranslate nohighlight">\(h_S\)</span> from <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
<p>Here are some links that explains the issue in details on where exactly the problem lies. All in all,
one just needs to know that the <em><strong>assumption of <span class="math notranslate nohighlight">\(\iid\)</span> is broken in Hoeffding’s Inequality
if you allow <span class="math notranslate nohighlight">\(h\)</span> to change to <span class="math notranslate nohighlight">\(h_S\)</span> after learning from <span class="math notranslate nohighlight">\(\mathcal{S}\)</span></strong></em>.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://math.stackexchange.com/questions/2097429/hoeffdings-inequality-and-learning">1. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/201746/changeing-the-hypothesis-while-generating-samples">2. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/157905/in-learning-theory-why-cant-we-bound-like-pe-ing-e-outg-epsilon">3. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
</ul>
<hr class="docutils" />
<p>This has serious implications! The logic that follows is that before learning, for any fixed <span class="math notranslate nohighlight">\(h\)</span>, we can bound the error by the Hoeffding’s Inequality. But now, there is no guarantee that <span class="math notranslate nohighlight">\(\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right|&gt;\epsilon\)</span> (the “bad event”) is less than <span class="math notranslate nohighlight">\(\delta\)</span> (the “bad event probability”). It could be less, it could be more, no one knows, but we do know that <span class="math notranslate nohighlight">\(h_S \in \mathcal{H}\)</span>.</p>
<p>Let’s see how we can make use of this property to bound the error for the <strong>entire hypothesis set</strong> <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>
instead of just a single hypothesis <span class="math notranslate nohighlight">\(h\)</span>.</p>
</section>
<section id="union-bound">
<h2>Union Bound<a class="headerlink" href="#union-bound" title="Permalink to this heading">#</a></h2>
<p>Suppose that <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> contains <span class="math notranslate nohighlight">\(M\)</span> hypothesis functions <span class="math notranslate nohighlight">\(h_{1}, \ldots, h_{M}\)</span>. The final hypothesis <span class="math notranslate nohighlight">\(h_S\)</span> that your learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> picked is one of these potential hypotheses. To have <span class="math notranslate nohighlight">\(\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right|&gt;\epsilon\)</span>, we need to ensure that at least one of the <span class="math notranslate nohighlight">\(M\)</span> potential hypotheses can satisfy the inequality.</p>
<div class="proof remark admonition" id="prf:remark-bounding-the-entire-hypothesis-set">
<p class="admonition-title"><span class="caption-number">Remark 12 </span> (Bounding the Entire Hypothesis Set)</p>
<section class="remark-content" id="proof-content">
<p>This part helps visualize why you need to use union bound to bound all hypotheses in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>.</p>
<p>This is best read together with the example in <a class="reference external" href="https://en.wikipedia.org/wiki/Boole%27s_inequality#Example">Wikipedia</a>.</p>
<p><strong>First</strong>, we must establish that for the <span class="math notranslate nohighlight">\(h_S\)</span> learnt by <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> on the
dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, the generalization gap <span class="math notranslate nohighlight">\(\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right|\)</span> is no longer bounded by the Hoeffding Inequality. We turn our attention to bounding
the entire hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> instead of just a single hypothesis <span class="math notranslate nohighlight">\(h\)</span>.</p>
<p><strong>Second</strong>, let us define the bad event <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> to be:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{B} = \left\{\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right| &gt; \epsilon\right\}
\]</div>
<p>which is the event that the error is greater than <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<p>Then it follows that <span class="math notranslate nohighlight">\(\mathcal{B}_m\)</span> is the bad event for the <span class="math notranslate nohighlight">\(m\)</span>th hypothesis <span class="math notranslate nohighlight">\(h_m\)</span> in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{B}_m = \left\{\left|\mathcal{R}_{\mathcal{D}}(h_m) - \hat{\mathcal{R}}_{\mathcal{S}}(h_m)\right| &gt; \epsilon\right\}
\]</div>
<p>We define the good event <span class="math notranslate nohighlight">\(\mathcal{B}^{\mathrm{c}}\)</span> to be the good event, the complement of the bad event to be:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{B}^{\mathrm{c}} = \left\{\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right| \leq \epsilon\right\}
\]</div>
<p>which is the event that the error is less than or equal to <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<p><strong>Third</strong>, we want to show that <span class="math notranslate nohighlight">\(\forall h_m \in \mathcal{H}\)</span>, the probability of <em><strong>all</strong></em> <span class="math notranslate nohighlight">\(h_1, h_2 \ldots, h_M\)</span> is bounded below by a value of say, <span class="math notranslate nohighlight">\(\phi\)</span>.</p>
<p>In other words, denote the event <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> as the event where <em><strong>all</strong></em> <span class="math notranslate nohighlight">\(h_1, h_2 \ldots, h_M\)</span>
are “good” (none of them are “bad”). The event <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> can be defined as:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{C} = \mathcal{B_1}^{\mathrm{c}} \cap \mathcal{B_2}^{\mathrm{c}} \cap \ldots \cap \mathcal{B_M}^{\mathrm{c}}
\]</div>
<p>which is the event that <em><strong>all</strong></em> <span class="math notranslate nohighlight">\(h_1, h_2 \ldots, h_M\)</span> are “good”. Now, we seek to find
the probability of <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> to be greater than or equal to <span class="math notranslate nohighlight">\(\phi\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}\left(\mathcal{C}\right) &amp;&gt; \phi \\
\end{aligned}
\end{split}\]</div>
<p>For example, if <span class="math notranslate nohighlight">\(\phi = 0.95\)</span>, this means that we can be 95% confident that <em><strong>all</strong></em> <span class="math notranslate nohighlight">\(h_1, h_2 \ldots, h_M\)</span> are “good” (i.e. all <span class="math notranslate nohighlight">\(h_1, h_2, \ldots, h_M\)</span> give a generalization error less than or equal to <span class="math notranslate nohighlight">\(\epsilon\)</span>).</p>
<p>However, to make use of Union Bound (Boole’s Inequality), we need to express the <span class="math notranslate nohighlight">\(h_1, h_2, \ldots, h_M\)</span> as a sequence of logical <strong>or</strong> events. Let’s try to rephrase the event <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> as a sequence of logical <strong>or</strong> events.</p>
<p><strong>Fourth</strong>, let <span class="math notranslate nohighlight">\(\mathcal{C}^{\mathrm{c}}\)</span> be the complement of the event <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{C}^{\mathrm{c}} &amp;= \exists h_m \in \mathcal{H} \quad \text{s.t.} h_m \text{ is a bad} \\
&amp;= \mathcal{B_1} \cup \mathcal{B_2} \cup \ldots \cup \mathcal{B_M} \\
&amp;= h_1 \text{ gives a bad error} \cup h_2 \text{ gives a bad error} \cup \ldots \cup h_M \text{ gives a bad error}
\end{aligned}
\end{split}\]</div>
<p>Then, finding <span class="math notranslate nohighlight">\(\mathbb{P}(\mathcal{C}) &gt; \phi\)</span> is equivalent to finding the following:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp;\mathbb{P}\left(\mathcal{C}\right) &amp;&gt; \phi \\
\iff &amp;1 - \mathbb{P}\left(\mathcal{C}^{\mathrm{c}}\right) &amp;&gt; \phi \\
\iff &amp;\mathbb{P}\left(\mathcal{C}^{\mathrm{c}}\right) &amp;\leq 1 - \phi \\
\end{aligned}
\end{split}\]</div>
<p>where we invoked that <span class="math notranslate nohighlight">\(\mathcal{C} + \mathcal{C}^{\mathrm{c}} = 1\)</span>. Now, we have turned
the problem of finding <span class="math notranslate nohighlight">\(\mathbb{P}(\mathcal{C}) &gt; \phi\)</span> into finding the probability of
<span class="math notranslate nohighlight">\(\mathcal{C}^{\mathrm{c}}\)</span> to be less than or equal to <span class="math notranslate nohighlight">\(1 - \phi\)</span> (from lower bound to upper bound).</p>
<p><strong>Fifth</strong>, so now we can instead find the equivalent of the Hoeffding Inequality for the event <span class="math notranslate nohighlight">\(\mathcal{C}^{\mathrm{c}}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}\left(\mathcal{C}^{\mathrm{c}}\right) &amp;= \mathbb{P}\left(\mathcal{B_1} \cup \mathcal{B_2} \cup \ldots \cup \mathcal{B_M}\right) \\
&amp;\leq \mathbb{P}\left(\mathcal{B_1}\right) + \mathbb{P}\left(\mathcal{B_2}\right) + \ldots + \mathbb{P}\left(\mathcal{B_M}\right) \\
\end{aligned}
\end{split}\]</div>
<p>where we invoked the Union Bound (Boole’s Inequality).</p>
<p><strong>Last</strong>, in order for the entire hypothesis space to have a generalization gap bigger than <span class="math notranslate nohighlight">\(\epsilon\)</span>, at least one of its hypothesis: <span class="math notranslate nohighlight">\(h_1\)</span> or <span class="math notranslate nohighlight">\(h_2\)</span> or <span class="math notranslate nohighlight">\(h_3\)</span> or … etc should have. This can be expressed formally by stating that:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left[\sup _{h \in \mathcal{H}}\left|\mathcal{R}(h)-\hat{\mathcal{R}}(h)\right|&gt;\epsilon\right]=\mathbb{P}\left[\bigcup_{h \in \mathcal{H}}\left|\mathcal{R}(h)-\hat{\mathcal{R}}(h)\right|&gt;\epsilon\right]
\]</div>
<p>Where <span class="math notranslate nohighlight">\(\bigcup\)</span> denotes the union of the events, which also corresponds to the logical OR operator. Using the union bound inequality, we get:</p>
<div class="math notranslate nohighlight" id="equation-eq-union-bound-1">
<span class="eqno">(20)<a class="headerlink" href="#equation-eq-union-bound-1" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{aligned}
\mathbb{P}\left\{\left|\hat{\mathcal{R}}_{\mathcal{D}}(h_S)-\mathcal{R}_{\mathcal{S}}(h_S)\right|&gt;\epsilon\right\} &amp;\stackrel{(a)}{\leq} \mathbb{P}\left[\sup _{h \in \mathcal{H}}\left|\mathcal{R}(h)-\hat{\mathcal{R}}(h)\right|&gt;\epsilon\right] \\
&amp;= \mathbb{P}\left[\bigcup_{h \in \mathcal{H}}\left|\mathcal{R}(h)-\hat{\mathcal{R}}(h)\right|&gt;\epsilon\right]\\
&amp; \stackrel{(b)}{\leq} \sum_{m=1}^{M} \mathbb{P}\left\{\left|\hat{\mathcal{R}}_{\mathcal{D}}\left(h_{m}\right)-\mathcal{R}_{\mathcal{S}}\left(h_{m}\right)\right|&gt;\epsilon\right\} \\
&amp;= \sum_{m=1}^{M} 2 e^{-2 \epsilon^{2} N} \\
&amp;= \left| \mathcal{H} \right| 2 e^{-2 \epsilon^{2} N} \text{. }
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\((a)\)</span> holds because <span class="math notranslate nohighlight">\(\mathbb{P}[A] \leq \mathbb{P}[B]\)</span> if <span class="math notranslate nohighlight">\(A \Rightarrow B\)</span>, and <span class="math notranslate nohighlight">\((b)\)</span> is the Union bound which says <span class="math notranslate nohighlight">\(\mathbb{P}[A\)</span> or <span class="math notranslate nohighlight">\(B] \leq \mathbb{P}[A]+\mathbb{P}[B]\)</span>.</p>
<p>Therefore, if we bound each <span class="math notranslate nohighlight">\(h_{m}\)</span> using the Hoeffding inequality</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left\{\left|\hat{\mathcal{R}}_{\mathcal{S}}\left(h_{m}\right)-\mathcal{R}_{\mathcal{D}}\left(h_{m}\right)\right|&gt;\epsilon\right\} \leq 2 e^{-2 \epsilon^{2} N}
\]</div>
<p>then the overall bound on <span class="math notranslate nohighlight">\(h_S\)</span> is the sum of the <span class="math notranslate nohighlight">\(M\)</span> terms.</p>
<p>To see why <span class="math notranslate nohighlight">\((a)\)</span> holds, consider the following:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\left|\hat{\mathcal{R}}_{\mathcal{D}}(g)-\mathcal{R}_{\mathcal{S}}(g)\right|&gt;\epsilon &amp;\Longrightarrow \left\{\left|\hat{\mathcal{R}}_{\mathcal{D}}\left(h_1\right)-\mathcal{R}_{\mathcal{S}}\left(h_1\right)\right|&gt;\epsilon \text{ or } \left|\hat{\mathcal{R}}_{\mathcal{D}}\left(h_2\right)-\mathcal{R}_{\mathcal{S}}\left(h_2\right)\right|&gt;\epsilon \text{ or } \ldots \text{ or } \left|\hat{\mathcal{R}}_{\mathcal{D}}\left(h_M\right)-\mathcal{R}_{\mathcal{S}}\left(h_M\right)\right|&gt;\epsilon\right\} \\
\end{aligned}
\end{split}\]</div>
<p>The LHS is event <span class="math notranslate nohighlight">\(A\)</span> for example, the RHS is event <span class="math notranslate nohighlight">\(B\)</span>, then since we have <span class="math notranslate nohighlight">\(A \Rightarrow B\)</span>, we have <span class="math notranslate nohighlight">\(\mathbb{P}[A] \leq \mathbb{P}[B]\)</span>.</p>
<p>Thus, we found a bound for the whole hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. Thus our <span class="math notranslate nohighlight">\(1 - \phi\)</span> is actually
<span class="math notranslate nohighlight">\(\left| \mathcal{H} \right| 2 e^{-2 \epsilon^{2} N}\)</span>.</p>
<div class="toggle docutils container">
<p>The below content was what I initially wrote, but the argument is hand-wavy, so I tried to lay
out the argument more formally above. Still quite unsure if the reasoning is correct, but at least
should be along those lines.</p>
<p>If one has <span class="math notranslate nohighlight">\(M\)</span> hypotheses <span class="math notranslate nohighlight">\(h_1, \ldots, h_M\)</span> in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, then what is the probability that
<em><strong>all</strong></em> <span class="math notranslate nohighlight">\(M\)</span> hypotheses satisfy the inequality <span class="math notranslate nohighlight">\(\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right| \leq \epsilon\)</span>? So if our probability found is <span class="math notranslate nohighlight">\(95\%\)</span>, this means that
we can be 95% confident that <em><strong>all</strong></em> <span class="math notranslate nohighlight">\(M\)</span> hypotheses satisfy the inequality. This is setting
<span class="math notranslate nohighlight">\(\delta = 0.05\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\mathbb{P}\left(\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right| \leq \epsilon\right) \geq 1 - \delta
\end{aligned}
\]</div>
<p>If we can find this <strong>probability</strong>, then this just means that whichever <span class="math notranslate nohighlight">\(h_S\)</span> we learnt by <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>
on <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, will have an error less than or equal to <span class="math notranslate nohighlight">\(\epsilon\)</span> with probability <span class="math notranslate nohighlight">\(95\%\)</span> (similar to
confidence interval).</p>
<p>We are stating the problem by asking the event “all <span class="math notranslate nohighlight">\(M\)</span> hypotheses are good”, now we can
find the complement of “all <span class="math notranslate nohighlight">\(M\)</span> hypotheses are good” to be “at least one <span class="math notranslate nohighlight">\(h_m\)</span> is bad”
so that we can use the union bound easier.</p>
<p>Now, if we go the route of finding complement, then this objective is stated as:</p>
<p>If one has <span class="math notranslate nohighlight">\(M\)</span> hypotheses <span class="math notranslate nohighlight">\(h_1, \ldots, h_M\)</span> in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, then what is the probability that
<em><strong>at least (there exists) at least one</strong></em> <span class="math notranslate nohighlight">\(h_m\)</span> such that <span class="math notranslate nohighlight">\(\left|\mathcal{R}_{\mathcal{D}}(h_m) - \hat{\mathcal{R}}_{\mathcal{S}}(h_m)\right| &gt; \epsilon\)</span>?</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\mathbb{P}\left(\left|\mathcal{R}_{\mathcal{D}}(h_S) - \hat{\mathcal{R}}_{\mathcal{S}}(h_S)\right| &gt; \epsilon\right) \leq \delta
\end{aligned}
\]</div>
<p>These are two equivalent statements, and we can use either one.</p>
<p>Now, we can readily use the union bound since
our expression is now in the form of “at least one <span class="math notranslate nohighlight">\(h_m\)</span> is bad” which translates to a union of
“events” <span class="math notranslate nohighlight">\(h_1\)</span> is bad, <span class="math notranslate nohighlight">\(h_2\)</span> is bad, <span class="math notranslate nohighlight">\(\ldots\)</span>, <span class="math notranslate nohighlight">\(h_M\)</span> is bad.</p>
</div>
</section>
</div><div class="toggle docutils container">
<div class="proof remark admonition" id="prf:remark-major-confusion-alert">
<p class="admonition-title"><span class="caption-number">Remark 13 </span> (Major Confusion Alert)</p>
<section class="remark-content" id="proof-content">
<p>DEFUNCT AS OF 1ST MARCH, 2023, READ WITH CAUTION AS IT IS NOT CORRECT. I AM LEAVING IT HERE FOR HISTORICAL PURPOSES.</p>
<p>What this means is that out of <span class="math notranslate nohighlight">\(M\)</span> hypotheses in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, at least one of them <strong>does satisfy the Hoeffding’s Inequality, but you do not know which <span class="math notranslate nohighlight">\(h\)</span> it is.</strong>
This is because our definition of Hoeffding’s Inequality <strong>requires us to fix a <span class="math notranslate nohighlight">\(h\)</span> prior to generating the dataset</strong>. And therefore this <span class="math notranslate nohighlight">\(h\)</span> we fixed is <strong>not the same as the <span class="math notranslate nohighlight">\(h_S\)</span> we picked after generating the dataset</strong>. So the Hoeffding’s Inequality is no longer valid. It does sound confusing, because one would think that this inequality seems to satify for any <span class="math notranslate nohighlight">\(h\)</span>, but if we follow definition, it is a fixed <span class="math notranslate nohighlight">\(h\)</span>, so now when we get our new <span class="math notranslate nohighlight">\(h_S\)</span>, it is no longer the “same” as the <span class="math notranslate nohighlight">\(h\)</span> we fixed prior.</p>
<p>This is why the question boils down to calculating the following probability:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left[\sup _{h \in \mathcal{H}}\left|\mathcal{R}(h)-\hat{\mathcal{R}}(h)\right|&gt;\epsilon\right]
\]</div>
<p>That is the probability that the least upper bound (that is the supremum <span class="math notranslate nohighlight">\(\sup _{h \in \mathcal{H}}\)</span> ) of the absolute difference between <span class="math notranslate nohighlight">\(\mathcal{R}(h)\)</span> and <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}(h)\)</span> is larger than a very small value <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<p>In more laymen words, every <span class="math notranslate nohighlight">\(h_m \in \mathcal{H}\)</span> induces a difference categorized by say <span class="math notranslate nohighlight">\(\text{in_out_error_diff}_m = \mathcal{R}(h_m)-\hat{\mathcal{R}}(h_m)\)</span>, and this
<span class="math notranslate nohighlight">\(\text{in_out_error_diff}_m\)</span> is a scalar value, say ranging from <span class="math notranslate nohighlight">\(0\)</span> to <span class="math notranslate nohighlight">\(1\)</span>, sometimes, a hypothesis <span class="math notranslate nohighlight">\(h_i\)</span> can induce a difference of say <span class="math notranslate nohighlight">\(0.2\)</span>, and sometimes, another hypothesis <span class="math notranslate nohighlight">\(h_j\)</span> can induce a difference of say <span class="math notranslate nohighlight">\(0.8\)</span>. The supremum of these differences is the <em>nasty and bad</em> hypothesis <span class="math notranslate nohighlight">\(h_{\text{bad}}\)</span> that induces the maximum difference amongst all the <span class="math notranslate nohighlight">\(h_m \in \mathcal{H}\)</span>. BUT IF WE CAN BOUND THE BADDEST AND WORST CASE by a very small value <span class="math notranslate nohighlight">\(\epsilon\)</span>, then we are good. This is exactly what the Hoeffding’s Inequality does. It says that the largest difference between <span class="math notranslate nohighlight">\(\mathcal{R}(h)\)</span> and <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}(h)\)</span> exceeding <span class="math notranslate nohighlight">\(\epsilon\)</span> is lesser
or equals to <span class="math notranslate nohighlight">\(2 e^{-2 \epsilon^{2} N}\)</span>. Note this is not saying that exceeding <span class="math notranslate nohighlight">\(\epsilon\)</span> is impossible, it is saying that the probability of this bad event happening and exceeding <span class="math notranslate nohighlight">\(\epsilon\)</span> is bounded by <span class="math notranslate nohighlight">\(2 e^{-2 \epsilon^{2} N}\)</span>. This is a very important point to note.</p>
</section>
</div></div>
</section>
<section id="framing-learning-theory-with-hoeffding-s-inequality">
<h2>Framing Learning Theory with Hoeffding’s Inequality<a class="headerlink" href="#framing-learning-theory-with-hoeffding-s-inequality" title="Permalink to this heading">#</a></h2>
<div class="proof theorem admonition" id="theorem-learning-theory-1">
<p class="admonition-title"><span class="caption-number">Theorem 7 </span> (Learning Theory)</p>
<section class="theorem-content" id="proof-content">
<p>Consider a dataset <span class="math notranslate nohighlight">\(\mathcal{S} = \left\{\left(\mathbf{x}^{(n)}, y^{(n)}\right)\right\}_{n=1}^N\)</span> drawn i.i.d. from an unknown distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. Let the hypothesis
set <span class="math notranslate nohighlight">\(\mathcal{H} = \left\{h_{1}, \ldots, h_{M}\right\}\)</span> be a finite set of hypotheses. Then, suppose we fix a hypothesis <span class="math notranslate nohighlight">\(h_S\)</span> in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> which is found by the learning
algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>. Then for any <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>, we have the following bound:</p>
<div class="math notranslate nohighlight" id="equation-eq-learning-theory-1">
<span class="eqno">(21)<a class="headerlink" href="#equation-eq-learning-theory-1" title="Permalink to this equation">#</a></span>\[
\mathbb{P}\left[\left|\mathcal{R}_{\mathcal{D}}(h) - \hat{\mathcal{R}}_{\mathcal{S}}(h)\right|&gt;\epsilon\right] \leq 2\left|\mathcal{H}\right| e^{-2 \epsilon^{2} N} = 2M e^{-2 \epsilon^{2} N} \text{. }
\]</div>
<p>where <span class="math notranslate nohighlight">\(M\)</span> is the number of hypotheses in the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> and <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}\)</span> are the True Risk Function and the Empirical Risk Function respectively.</p>
</section>
</div></section>
<section id="feasibility-from-the-two-view-points">
<h2>Feasibility from the Two View Points<a class="headerlink" href="#feasibility-from-the-two-view-points" title="Permalink to this heading">#</a></h2>
<p>The deterministic analysis shows that learning is infeasible, whereas the probabilistic analysis shows that learning is feasible. Are they contradictory? If we look at them closely, we realize that there is in fact no contradiction. Here are the reasons.</p>
<ol class="arabic">
<li><p>Guarantee and Possibility. If we want a deterministic answer, then the question we ask is “Can <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> tell us something certain about <span class="math notranslate nohighlight">\(f\)</span> outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> ?” In this case the answer is no because if we have not seen the example, there is always uncertainty about the true <span class="math notranslate nohighlight">\(f\)</span>. If we want a probabilistic answer, then the question we ask is “Can <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> tell us something possibly about <span class="math notranslate nohighlight">\(f\)</span> outside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> ?” In this case the answer is yes.</p></li>
<li><p>Role of the distribution. There is one common distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span> which generates both the in-samples and the out-samples. Thus, whatever <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}\)</span> we use to generate <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, we must use it to generate the testing samples. The testing samples are not inside <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, but they come from the same distribution. Also, all samples are generated independently, so that we have i.i.d. when using the Hoeffding inequality.</p></li>
<li><p>Learning goal. The ultimate goal of learning is to make <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S) \approx 0\)</span>. However, in order establish this result, we need two levels of approximation:<br></p>
<div class="math notranslate nohighlight">
\[
    \mathcal{R}(h_S) \textcolor{red}{\underset{\text{Hoeffding Inequality}}{\approx}} \quad \hat{\mathcal{R}}(h_S) \textcolor{red}{\underset{\text{Training Error}}{\approx}} 0
    \]</div>
<p>The first approximation is made by the Hoeffding inequality, which ensures that for sufficiently large <span class="math notranslate nohighlight">\(N\)</span>, we can approximate the out-sample error by the examples in <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. The second approximation is to make the in-sample error, i.e., the training error, small. This requires a good hypothesis and a good learning algorithm.</p>
</li>
</ol>
<hr class="docutils" />
<section id="complex-hypothesis-set-and-complex-target-function">
<h3>Complex Hypothesis Set and Complex Target Function<a class="headerlink" href="#complex-hypothesis-set-and-complex-target-function" title="Permalink to this heading">#</a></h3>
<p>The results earlier tells us something about the complexity of the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> and the target function <span class="math notranslate nohighlight">\(f\)</span>.</p>
<ul>
<li><p><strong>More complex <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>?</strong> If <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is complex with a large <span class="math notranslate nohighlight">\(M\)</span>, then the approximation by the Hoeffding inequality becomes loose. Remember, Hoeffing inequality states that</p>
<div class="math notranslate nohighlight">
\[
    \mathbb{P}\left\{\left|\hat{\mathcal{R}}_{\mathcal{S}}(h_S)-\mathcal{R}_{\mathcal{D}}(h_S)\right|&gt;\epsilon\right\} \leq 2 M e^{2 \epsilon^{2} N}
    \]</div>
<p>As <span class="math notranslate nohighlight">\(M\)</span> grows, the upper bound on the right hand side becomes loose, and so we will run into risk where <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S)\)</span> can deviate from <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S)\)</span>. In other words, if <span class="math notranslate nohighlight">\(M\)</span> is large, then the right hand side will be very big and therefore the bound will be meaningless, it is like saying your deviation is less than <span class="math notranslate nohighlight">\(+\infty\)</span> (an exxageration), which is of course true.</p>
<p>However, if <span class="math notranslate nohighlight">\(M\)</span> is large, we have more candidate hypotheses to choose from and so the second approximation about the training error will go down. This gives the following relationship.</p>
<div class="math notranslate nohighlight">
\[
    \mathcal{R}(h_S) \textcolor{red}{\underset{\text{worse if }\mathcal{H} \text{ complex}}{\approx}} \quad \hat{\mathcal{R}}(h_S) \textcolor{red}{\underset{\text{good if }\mathcal{H} \text{ complex}}{\approx}} 0
    \]</div>
<p>Where is the optimal trade-off? This requires more investigation.</p>
</li>
<li><p><strong>More complex <span class="math notranslate nohighlight">\(f\)</span>?</strong> If the target function <span class="math notranslate nohighlight">\(f\)</span> is complex, we will suffer from being not able to push the training error down. This makes <span class="math notranslate nohighlight">\(E_{\mathrm{in}}(h_S) \approx 0\)</span> difficult. However, since the complexity of <span class="math notranslate nohighlight">\(f\)</span> has no influence to the Hoeffding inequality, the first approximation <span class="math notranslate nohighlight">\(E_{\mathrm{in}}(h_S) \approx \mathcal{R}_{\mathcal{D}}(h_S)\)</span> is unaffected. This gives us</p>
<div class="math notranslate nohighlight">
\[
      \mathcal{R}(h_S) \textcolor{red}{\underset{\text{no effect by } f}{\approx}} \quad \hat{\mathcal{R}}(h_S) \textcolor{red}{\underset{\text{worse if }f \text{ complex}}{\approx}} 0
      \]</div>
<p>Trying to improve the approximation <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S) \approx 0\)</span> by increasing the complexity of <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> needs to pay a price. If <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> becomes complex, then the approximation <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S) \approx \mathcal{R}_{\mathcal{D}}(h_S)\)</span> will be hurt.</p>
</li>
</ul>
<p>To this end, this definitely looks very similar to the bias-variance trade-off, which is often discussed in
many machine learning courses. We will get to that later!</p>
</section>
</section>
<section id="vc-analysis">
<h2>VC-Analysis<a class="headerlink" href="#vc-analysis" title="Permalink to this heading">#</a></h2>
<p>The objective of this section is go further into the analysis of the Hoeffding inequality to derive something called the <strong>generalization bound</strong>. There are two parts of our discussion.</p>
<ol class="arabic simple">
<li><p>The first part is easy, which is to rewrite the Hoeffding inequality into a form of “confidence interval” or “error bar”. This will allow us interpret the result better.</p></li>
<li><p>The second part is to replace the constant <span class="math notranslate nohighlight">\(M\)</span> in the Hoeffding inequality by something smaller. This will allow us derive something more meaningful. Why do we want to do that? What could go wrong with <span class="math notranslate nohighlight">\(M\)</span> ? Remember that <span class="math notranslate nohighlight">\(M\)</span> is the number of hypotheses in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. If <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is a finite set, then everything is fine because the exponential decaying function of the Hoeffding inequality will override the constant <span class="math notranslate nohighlight">\(M\)</span>. However, for any practical <span class="math notranslate nohighlight">\(\mathcal{H}, M\)</span> is infinite. Think of a perceptron algorithm. If we slightly perturb the decision boundary by an infinitesimal translation, we will get an infinite number of hypotheses, although these hypotheses could be very similar to each other. If <span class="math notranslate nohighlight">\(M\)</span> is infinite, then the probability bound offered by the Hoeffding inequality can potentially be bigger than 1 which is valid but meaningless. To address this issue we need to learn a concept called the <span class="math notranslate nohighlight">\(\mathbf{V C}\)</span> <strong>dimension</strong>.</p></li>
</ol>
<section id="generalization-bound">
<h3>Generalization Bound<a class="headerlink" href="#generalization-bound" title="Permalink to this heading">#</a></h3>
<p>We first see that the Hoeffding’s and Union bound earlier in <a class="reference internal" href="#equation-eq-union-bound-1">(20)</a> give us the following result:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}\left\{\underbrace{\left|\hat{\mathcal{R}}_{\mathcal{D}}(h_S)-\mathcal{R}_{\mathcal{S}}(h_S)\right|&gt;\epsilon}_{\text{Bad Event } \mathcal{B}}\right\}
&amp;\leq \sum_{m=1}^{M} 2 e^{-2 \epsilon^{2} N} \\
&amp;= \left| \mathcal{H} \right| 2 e^{-2 \epsilon^{2} N} \text{. }
\end{aligned}
\end{split}\]</div>
<p>Now, we can rewrite the above inequality. We first say that <span class="math notranslate nohighlight">\(\mathcal{B} = \left|\hat{\mathcal{R}}_{\mathcal{D}}(h_S)-\mathcal{R}_{\mathcal{S}}(h_S)\right|&gt;\epsilon\)</span> is a <strong>bad event</strong> because the generalization
gap is more than <span class="math notranslate nohighlight">\(\epsilon\)</span>. We then say that the probability <span class="math notranslate nohighlight">\(\mathbb{P}\left[\mathcal{B}\right] \leq \delta\)</span> for some event <span class="math notranslate nohighlight">\(\mathcal{B}\)</span>, which is equivalent to say that with probability <span class="math notranslate nohighlight">\(1-\delta\)</span>, the event <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> does not happen.</p>
<p>This means that:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left[\mathcal{B}\right] \leq \delta \Rightarrow \mathbb{P}\left[\mathcal{B}^{\mathrm{c}}\right] \geq 1-\delta
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{B}^{\mathrm{c}}\)</span> is the complement of <span class="math notranslate nohighlight">\(\mathcal{B}\)</span>, which is the event that <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> does not happen:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{B}^{\mathrm{c}}=\left|\hat{\mathcal{R}}_{\mathcal{D}}(h_S)-\mathcal{R}_{\mathcal{S}}(h_S)\right| \leq \epsilon
\]</div>
<p>We can say that with a confidence <span class="math notranslate nohighlight">\(1-\delta\)</span> :</p>
<div class="math notranslate nohighlight">
\[
\left|\mathcal{R}(h_S)-\hat{\mathcal{R}}(h_S)\right| \leq \epsilon \Rightarrow \hat{\mathcal{R}}(h_S)-\epsilon \leq \mathcal{R}(h_S) \leq \hat{\mathcal{R}}(h_S)+\epsilon
\]</div>
<p>where this is a result of the triangle inequality.</p>
<p>If we can express <span class="math notranslate nohighlight">\(\epsilon\)</span> in terms of <span class="math notranslate nohighlight">\(\delta\)</span>, then we will arrive our goal of rewriting the Hoeffding inequality. How about we substitute <span class="math notranslate nohighlight">\(\delta=2 M e^{-2 \epsilon^{2} N}\)</span>, which is the upper bound on the right hand side. By rearrange the terms, we can show that <span class="math notranslate nohighlight">\(\epsilon=\sqrt{\frac{1}{2 N} \log \frac{2 M}{\delta}}\)</span>. Therefore, we arrive at the following inequality.</p>
<div class="proof theorem admonition" id="thm:generalization-bound">
<p class="admonition-title"><span class="caption-number">Theorem 8 </span> (Generalization Bound)</p>
<section class="theorem-content" id="proof-content">
<p>Consider a learning problem where we have a dataset <span class="math notranslate nohighlight">\(\mathcal{S}=\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right\}\)</span>, and a hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}=\left\{h_{1}, \ldots, h_{M}\right\}\)</span>. Suppose <span class="math notranslate nohighlight">\(h_S\)</span> is the final hypothesis picked by the learning algorithm. Then, with probability at least <span class="math notranslate nohighlight">\(1-\delta\)</span>,</p>
<div class="math notranslate nohighlight" id="equation-eq-generalization-bound-1">
<span class="eqno">(22)<a class="headerlink" href="#equation-eq-generalization-bound-1" title="Permalink to this equation">#</a></span>\[
\hat{\mathcal{R}}_{\mathcal{S}}(h_S)-\sqrt{\frac{1}{2 N} \log \frac{2 M}{\delta}} \leq \mathcal{R}_{\mathcal{D}}(h_S) \leq \hat{\mathcal{R}}_{\mathcal{S}}(h_S)+\sqrt{\frac{1}{2 N} \log \frac{2 M}{\delta}} .
\]</div>
</section>
</div><p>The inequality given by <a class="reference internal" href="#equation-eq-generalization-bound-1">(22)</a> is called the generalization bound, which we can consider it as an “error bar”. There are two sides of the generalization bound:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S) \leq \hat{\mathcal{R}}_{\mathcal{S}}(h_S)+\epsilon\)</span> (Upper Bound). The upper bound gives us a safe-guard of how worse <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S)\)</span> can be compared to <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S)\)</span>. It says that the unknown quantity <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S)\)</span> will not be significantly higher than <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S)\)</span>. The amount is specified by <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S) \geq \hat{\mathcal{R}}_{\mathcal{S}}(h_S)+\epsilon\)</span> (Lower Bound). The lower bound tells us what to expect. It says that the unknown quantity <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S)\)</span> cannot be better than <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S)-\epsilon\)</span>.</p></li>
</ul>
<p>To make sense of the generalization bound, we need to ensure that <span class="math notranslate nohighlight">\(\epsilon \rightarrow 0\)</span> as <span class="math notranslate nohighlight">\(N \rightarrow \infty\)</span>. In doing so, we need to assume that <span class="math notranslate nohighlight">\(M\)</span> does not grow exponentially fast, for otherwise term <span class="math notranslate nohighlight">\(\log 2 M\)</span> will cancel out the effect of <span class="math notranslate nohighlight">\(1 / N\)</span>. However, if <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is an infinite set, then <span class="math notranslate nohighlight">\(M\)</span> is unavoidably infinite.</p>
<p>To concluse, this is our first generalization bound, it states that the generalization error is upper bounded by the training error plus a function of the hypothesis space size and the dataset size. We can also see that the the bigger the hypothesis space gets, the bigger the generalization error becomes.</p>
<div class="proof remark admonition" id="rmk:infinite-hypothesis-space">
<p class="admonition-title"><span class="caption-number">Remark 14 </span> (What is the Hypothesis Space is Infinite?)</p>
<section class="remark-content" id="proof-content">
<p>For a linear hypothesis of the form <span class="math notranslate nohighlight">\(h(x)=w x+b\)</span>, we also have <span class="math notranslate nohighlight">\(|\mathcal{H}|=\infty\)</span> as there is infinitely many lines that can be drawn. So the generalization error of the linear hypothesis space should be unbounded! If that’s true, how does perceptrons, logistic regression, support vector machines and essentially any ML model that uses a linear hypothesis work with the learning theory bound we just proposed?</p>
<p>There is something missing from the picture. Let’s take a deeper look at the generalization bound.</p>
</section>
</div><p>It is good to stop here and read section <strong>Examining the Independence Assumption</strong> and <strong>The Symmetrization Lemma</strong>
in <a class="reference external" href="https://mostafa-samir.github.io/ml-theory-pt2/">the post written by Mostafa</a> before proceeding.</p>
</section>
<section id="the-growth-function">
<h3>The Growth Function<a class="headerlink" href="#the-growth-function" title="Permalink to this heading">#</a></h3>
<p>To resolve the issue of having an infinite <span class="math notranslate nohighlight">\(M\)</span>, we realize that there is a serious slack caused by the union bound when deriving the Hoeffding inequality. If we look at the union bound, we notice that for every hypothesis <span class="math notranslate nohighlight">\(h \in \mathcal{H}\)</span> there is an event <span class="math notranslate nohighlight">\(\mathcal{B}=\left\{\left|\hat{\mathcal{R}}_{\mathcal{S}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}-\mathcal{R}_{\mathcal{D}}\left\{\mathcal{L}((\mathbf{x}, y), h)\right\}\right|&gt;\epsilon\right\}\)</span>. If we have <span class="math notranslate nohighlight">\(M\)</span> of these hypotheses, the union bound tells us that</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left[\mathcal{B}_{1} \text { or } \ldots \text { or } \mathcal{B}_{M}\right] \leq \mathbb{P}\left[\mathcal{B}_{1}\right]+\ldots+\mathbb{P}\left[\mathcal{B}_{M}\right]
\]</div>
<p>The union bound is tight ( ” <span class="math notranslate nohighlight">\(\leq\)</span> ” is replaced by “=”) when all the events <span class="math notranslate nohighlight">\(\mathcal{B}_{1}, \ldots, \mathcal{B}_{M}\)</span> are not overlapping (independent events). But if the events <span class="math notranslate nohighlight">\(\mathcal{B}_{1}, \ldots, \mathcal{B}_{M}\)</span> are overlapping (not independent), then the union bound is loose, in fact, very loose. Having a loose bound does not mean that the bound is wrong. The bound is still correct, but the right hand side of the inequality will be a severe overestimate of the left hand side. Will this happen in practice? Unfortunately many hypotheses are indeed very similar to each other and so the events <span class="math notranslate nohighlight">\(\mathcal{B}_{1}, \ldots, \mathcal{B}_{M}\)</span> are overlapping. For example, if we move the decision boundary returned by a perceptron algorithm by an infinitesimal step then we will have infinitely many hypotheses, and everyone is highly dependent on each other.</p>
<p>We need some tools to handle the overlapping situation. To do so we introduce two concepts. The first concept is called the <strong>dichotomy</strong>, and the second concept is called the <strong>growth function</strong>. Dichotomies will define a growth function, and the growth function will allow us replace <span class="math notranslate nohighlight">\(M\)</span> by a much smaller quantity that takes care of the overlapping issue.</p>
<p>Consider a dataset containing <span class="math notranslate nohighlight">\(N\)</span> data points <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>. Pick a hypothesis <span class="math notranslate nohighlight">\(h\)</span> from the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, and for simplicity assume that the hypothesis is binary: <span class="math notranslate nohighlight">\(\{+1,-1\}\)</span>. If we apply <span class="math notranslate nohighlight">\(h\)</span> to <span class="math notranslate nohighlight">\(\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span>, we will get a <span class="math notranslate nohighlight">\(N\)</span>-tuple <span class="math notranslate nohighlight">\(\left(h\left(\mathbf{x}^{(1)}\right), \ldots, h\left(\mathbf{x}^{(N)}\right)\right)\)</span> of <span class="math notranslate nohighlight">\(\pm 1\)</span> ‘s. Each <span class="math notranslate nohighlight">\(N\)</span>-tuple is called a <strong>dichotomy</strong>. The collection of all possible <span class="math notranslate nohighlight">\(N\)</span>-tuples (by picking all <span class="math notranslate nohighlight">\(h \in \mathcal{H}\)</span> ) is defined as <span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span>. For example, if <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> contains two hypotheses <span class="math notranslate nohighlight">\(h_{\alpha}\)</span> and <span class="math notranslate nohighlight">\(h_{\beta}\)</span> such that <span class="math notranslate nohighlight">\(h_{\alpha}\)</span> turns all training samples <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> to <span class="math notranslate nohighlight">\(+1\)</span> and <span class="math notranslate nohighlight">\(h_{\beta}\)</span> turns all training samples <span class="math notranslate nohighlight">\(\mathbf{x}^{(n)}\)</span> to <span class="math notranslate nohighlight">\(-1\)</span>, then we have two dichotomies and <span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right) &amp; =\left\{\left(h_{\alpha}\left(\mathbf{x}^{(1)}\right), \ldots, h_{\alpha}\left(\mathbf{x}^{(N)}\right)\right),\left(h_{\beta}\left(\mathbf{x}^{(1)}\right), \ldots, h_{\beta}\left(\mathbf{x}^{(N)}\right)\right)\right\} \\
&amp; =\{(+1, \ldots,+1),(-1, \ldots,-1)\}
\end{aligned}
\end{split}\]</div>
<p>More generally, the definition of <span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span> is as follows.</p>
<div class="proof definition admonition" id="def:dichotomy">
<p class="admonition-title"><span class="caption-number">Definition 11 </span> (Dichotomy)</p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)} \in \mathcal{X}\)</span>. The dichotomies generated by <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> on these points are</p>
<div class="math notranslate nohighlight" id="equation-eq-dichotomy">
<span class="eqno">(23)<a class="headerlink" href="#equation-eq-dichotomy" title="Permalink to this equation">#</a></span>\[
\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)=\left\{\left(h\left(\mathbf{x}^{(1)}\right), \ldots, h\left(\mathbf{x}^{(N)}\right)\right) \middle \vert h \in \mathcal{H}\right\}
\]</div>
</section>
</div><p>The above definition suggests that <span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span> is a function depending on the training samples <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>. Therefore, a different set (different <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>) of <span class="math notranslate nohighlight">\(\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right\}\)</span> will give a different <span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span>. However, since <span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span> is a binary <span class="math notranslate nohighlight">\(N\)</span>-tuple, there will be identical sequences of <span class="math notranslate nohighlight">\(\pm 1\)</span> ‘s in <span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span>. Let us look at one example.</p>
<p>Suppose there are <span class="math notranslate nohighlight">\(N=3\)</span> data points in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> so that we have <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span> (red color is <span class="math notranslate nohighlight">\(+1\)</span> and blue color is <span class="math notranslate nohighlight">\(-1\)</span>). Use any method to build a linear classifier (could be a linear regression of a perceptron algorithm). Since there are infinitely many lines we can draw in the <span class="math notranslate nohighlight">\(2 \mathrm{D}\)</span> plane, the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> contains infinitely many hypotheses. Now, let us assume that the training data <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span> are located at position <span class="math notranslate nohighlight">\(A, B, C\)</span> respectively, as illustrated in <a class="reference internal" href="#ece595-fig4-5"><span class="std std-numref">Fig. 8</span></a>. These locations are fixed, and the 3 data points <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span> must stay at these three locations. For this particular configuration of the locations, we can make as many as <span class="math notranslate nohighlight">\(2^{3}=8\)</span> dichotomies. Notice that one dichotomy can still have infinitely many hypotheses. For example in the top left case of <a class="reference internal" href="#ece595-fig4-5"><span class="std std-numref">Fig. 8</span></a>, we can move the yellow decision boundary up and low slightly, and we will still get the same dichotomy of <span class="math notranslate nohighlight">\([-1,-1,-1]\)</span>. However, as we move the decision boundary away by changing the slope and intercept, we will eventually land on a different dichotomy, e.g., <span class="math notranslate nohighlight">\([-1,+1,-1]\)</span> as shown in the bottom left of <a class="reference internal" href="#ece595-fig4-5"><span class="std std-numref">Fig. 8</span></a>. As we move around the decision boundary, we can construct at most 8 dichotomies for <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span> located at <span class="math notranslate nohighlight">\(A, B\)</span> and <span class="math notranslate nohighlight">\(C\)</span>.</p>
<p><em>Typo: I think the bottom left <span class="math notranslate nohighlight">\([-1, +1, -1]\)</span> has the linear yellow line drawn wrongly, it should cut through
such that the <span class="math notranslate nohighlight">\(-1\)</span> is on one side, and <span class="math notranslate nohighlight">\(+1\)</span> is on the other.</em></p>
<p>What if we move <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span> to somewhere else, for example the locations specified by the red part of <a class="reference internal" href="#ece595-fig4-5"><span class="std std-numref">Fig. 8</span></a> In this case some dichotomies are not allowed, e.g., the cases of <span class="math notranslate nohighlight">\([+1,-1,+1]\)</span> and <span class="math notranslate nohighlight">\([-1,+1,-1]\)</span> are not allowed because our hypothesis set contains only linear models and a linear model is not able to cut through 3 data points of alternating classes with a straight line. We can still get the remaining six configurations, but the total will be less than 8 . The total number of dichotomies here is 6 .</p>
<figure class="align-default" id="ece595-fig4-5">
<img alt="../../../_images/ece595_fig4.5.jpeg" src="../../../_images/ece595_fig4.5.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 8 </span><span class="caption-text">For a fixed configuration of <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span>, we can obtain different numbers of dichotomies. Suppose the hypothesis set contains linear models. [Left] There are 8 dichotomies for three data points located not on a line. [Right] When the three data points are located on a line, the number of dichotomies becomes 6.</span><a class="headerlink" href="#ece595-fig4-5" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Now we want to define a quantity that measures the number of dichotomies. This quantity should be universal for any configuration of <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>, and should only be a function of <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> and <span class="math notranslate nohighlight">\(N\)</span>. If we can obtain such quantity, then we will have a way to make a better estimate than <span class="math notranslate nohighlight">\(M\)</span>. To eliminate the dependency on <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>, we realize that among all the possible configurations of <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>, there exists one that can maximize the size of <span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span>. Define this maximum as the growth function.</p>
<div class="proof definition admonition" id="ece595_def4.6">
<p class="admonition-title"><span class="caption-number">Definition 12 </span> (Growth Function)</p>
<section class="definition-content" id="proof-content">
<p>The growth function for a hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is</p>
<div class="math notranslate nohighlight" id="equation-eq-growth-function">
<span class="eqno">(24)<a class="headerlink" href="#equation-eq-growth-function" title="Permalink to this equation">#</a></span>\[
m_{\mathcal{H}}(N)=\max _{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)} \in \mathcal{X}}\left|\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\right|
\]</div>
<p>where <span class="math notranslate nohighlight">\(|\cdot|\)</span> denotes the cardinality of a set.</p>
</section>
</div><div class="proof example admonition" id="example_growth_function">
<p class="admonition-title"><span class="caption-number">Example 5 </span> (Example of Growth Function)</p>
<section class="example-content" id="proof-content">
<p>For example, <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(3)\)</span> of a linear model is 8 , because if we configure <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}\)</span> like the ones in the green part of <a class="reference internal" href="#ece595-fig4-5"><span class="std std-numref">Fig. 8</span></a>, we will get 8 dichotomies. Of course, if we land on the red case we will get 6 dichotomies only, but the definition of <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(3)\)</span> asks for the maximum which is 8. How about <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> when <span class="math notranslate nohighlight">\(N=4\)</span> ? It turns out that there are at most 14 dichotomies no matter where we put the four data points <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \mathbf{x}^{(3)}, \mathbf{x}^{(4)}\)</span>.</p>
<p>So what is the difference between <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> and <span class="math notranslate nohighlight">\(M\)</span> ? Both are measures of the number of hypotheses. However, <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> is measured from the <span class="math notranslate nohighlight">\(N\)</span> training samples in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> whereas <span class="math notranslate nohighlight">\(M\)</span> is the number of hypotheses we have in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. The latter could be infinite, the former is upper bounded (at most) <span class="math notranslate nohighlight">\(2^{N}\)</span>. Why <span class="math notranslate nohighlight">\(2^{N}\)</span> ? Suppose we have <span class="math notranslate nohighlight">\(N\)</span> data points and the hypothesis is binary. Then the set of all dichotomies <span class="math notranslate nohighlight">\(\mathcal{H}\left(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\right)\)</span> must be a subset in <span class="math notranslate nohighlight">\(\{+1,-1\}^{N}\)</span>, and hence there are at most <span class="math notranslate nohighlight">\(2^{N}\)</span> dichotomies:</p>
<div class="math notranslate nohighlight">
\[
m_{\mathcal{H}}(N) \leq 2^{N}
\]</div>
<p>If a hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is able to generate all <span class="math notranslate nohighlight">\(2^{N}\)</span> dichotomies, then we say that <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> shatter <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>. For example, a <span class="math notranslate nohighlight">\(2 \mathrm{D}\)</span> perceptron algorithm is able to shatter 3 data points because <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(3)=2^{3}\)</span>. However, the same <span class="math notranslate nohighlight">\(2 \mathrm{D}\)</span> perceptron algorithm is not able to shatter 4 data points because <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(4)=14&lt;2^{4}\)</span></p>
</section>
</div><div class="proof definition admonition" id="restricted_hypothesis_space">
<p class="admonition-title"><span class="caption-number">Definition 13 </span> (Restricted Hypothesis Space)</p>
<section class="definition-content" id="proof-content">
<p>By only choosing the distinct effective hypotheses on the dataset <span class="math notranslate nohighlight">\(S\)</span>, we restrict the hypothesis space <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> to a smaller subspace that depends on the dataset. We call this new hypothesis space a restricted one:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{H}_{\mid S}
\]</div>
</section>
</div><p>Ah, what is a consequence of all this? Can we do better with the generalization bound <a class="reference internal" href="#equation-eq-generalization-bound-1">(22)</a> defined in <a class="reference internal" href="#thm:generalization-bound">Theorem 8</a>.</p>
<p>The most straight forward step is to replace <span class="math notranslate nohighlight">\(M\)</span> by <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> :</p>
<div class="math notranslate nohighlight">
\[
\hat{\mathcal{R}}(h_S)-\sqrt{\frac{1}{2 N} \log \frac{2 \textcolor{red}{m_{\mathcal{H}}(N)}}{\delta}} \leq \mathcal{R}_{\mathcal{D}}(h_S) \leq \hat{\mathcal{R}}(h_S)+\sqrt{\frac{1}{2 N} \log \frac{2 \textcolor{red}{m_{\mathcal{H}}(N)}}{\delta}}
\]</div>
<p>Since we know that</p>
<div class="math notranslate nohighlight">
\[
m_{\mathcal{H}}(N) \leq 2^{N}
\]</div>
<p>a natural attempt is to upper bound <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> by <span class="math notranslate nohighlight">\(2^{N}\)</span>.</p>
<p>However, this will not help us because</p>
<div class="math notranslate nohighlight">
\[
\sqrt{\frac{1}{2 N} \log \frac{2 m_{\mathcal{H}}(N)}{\delta}} \leq \sqrt{\frac{1}{2 N} \log \frac{2\left(\textcolor{red}{2^{N}}\right)}{\delta}}=\sqrt{\frac{1}{2 N} \log \frac{2^{N+1}}{\delta}}
\]</div>
<p>For large <span class="math notranslate nohighlight">\(N\)</span> we can approximate <span class="math notranslate nohighlight">\(2^{N+1} \approx 2^{N}\)</span>, and so</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{2 N} \log \frac{2^{N}}{\delta} \approx \frac{N \log 2-\log \delta}{2 N}=\frac{\log 2}{2}-\frac{\log \delta}{2 N} \rightarrow(\log 2) / 2 .
\]</div>
<p>Therefore, as <span class="math notranslate nohighlight">\(N \rightarrow \infty\)</span>, the error bar will never approach zero but to a constant. This makes the generalization fail.</p>
<p>Furthermore, even though now the restricted hypothesis space <span class="math notranslate nohighlight">\(\mathcal{H}_{\mid S}\)</span> is “finite”, but <span class="math notranslate nohighlight">\(2^N\)</span> is exponential in terms of <span class="math notranslate nohighlight">\(N\)</span> and would grow too fast for large datasets, which makes the odds in our inequality go too bad too fast! Is that the best bound we can get on that growth function? Can we do better?</p>
</section>
<section id="the-vc-dimension">
<h3>The VC Dimension<a class="headerlink" href="#the-vc-dimension" title="Permalink to this heading">#</a></h3>
<p>Can we find a better upper bound on <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> so that we can send the error bar to zero as <span class="math notranslate nohighlight">\(N\)</span> grows? Here we introduce some definitions allows us to characterize the growth function.</p>
<div class="proof definition admonition" id="shatters">
<p class="admonition-title"><span class="caption-number">Definition 14 </span> (Shattering)</p>
<section class="definition-content" id="proof-content">
<p>If a hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is able to generate all <span class="math notranslate nohighlight">\(2^N\)</span> dichotomies, then we say that <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> shatter <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>.</p>
<p>In other words, a set of data points <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is shattered by a hypothesis class <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> if there are hypotheses in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> that split <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> in all of the <span class="math notranslate nohighlight">\(2^{\left|\mathcal{S}\right|}\)</span> possible ways; i.e., all possible ways of classifying points in <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> are achievable using concepts in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>.</p>
</section>
</div><div class="proof definition admonition" id="vc_dimension">
<p class="admonition-title"><span class="caption-number">Definition 15 </span> (VC Dimension of <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>)</p>
<section class="definition-content" id="proof-content">
<p>The <strong>Vapnik-Chervonenkis</strong> dimension of a hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, denoted by <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span>, is the largest value of <span class="math notranslate nohighlight">\(N\)</span> for which <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)=2^{N}\)</span>.</p>
</section>
</div><div class="proof example admonition" id="vc_dimension_of_a_2d_perceptron">
<p class="admonition-title"><span class="caption-number">Example 6 </span> (VC Dimension of a 2D Perceptron)</p>
<section class="example-content" id="proof-content">
<p>For example, consider the <span class="math notranslate nohighlight">\(2 \mathrm{D}\)</span> perceptron algorithm, which has hypothesis
<span class="math notranslate nohighlight">\(h\)</span> of the following form:</p>
<div class="math notranslate nohighlight">
\[
\operatorname{sign}\left(\left(\mathbf{x}^{(n)}\right)^{T} \mathbf{w}\right) = y^{(n)}
\]</div>
<p>We can start with <span class="math notranslate nohighlight">\(N=3\)</span>, and gradual increase <span class="math notranslate nohighlight">\(N\)</span> until we hit a critical point.</p>
<p>Suppose <span class="math notranslate nohighlight">\(N=3\)</span>. Recall that <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(3)\)</span> is the maximum number of dichotomies that can be generated by a hypothesis set under <span class="math notranslate nohighlight">\(N=3\)</span> data points. As we have shown earlier, as long as the 3 data points are not on a straight line, it is possible to draw 8 different dichotomies. If the 3 data points are on a straight line, we can only generate 6 dichotomies. However, since <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(3)\)</span> picks the maximum, we have that <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(3)=2^{3}\)</span>. Therefore, a 2 D percetpron can shatter 3 data points.</p>
<p>Suppose <span class="math notranslate nohighlight">\(N=4\)</span>. As we have discussed earlier, if we have <span class="math notranslate nohighlight">\(N=4\)</span> data points, there are always 2 dichotomies that cannot be generated by the perceptron algorithm. This implies that the growth function is <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(4)=14&lt;2^{4}\)</span>. Since the perceptron algorithm can shatter <span class="math notranslate nohighlight">\(N=3\)</span> data points but not <span class="math notranslate nohighlight">\(N=4\)</span> data points, the <span class="math notranslate nohighlight">\(\mathrm{VC}\)</span> dimension is <span class="math notranslate nohighlight">\(\mathrm{VCdim}=3\)</span>.</p>
<p>The following animation shows how many ways a linear classifier in 2D can label 3 points (on the left) and 4 points (on the right).</p>
<figure class="align-default" id="shatter">
<img alt="../../../_images/shatter.gif" src="../../../_images/shatter.gif" />
<figcaption>
<p><span class="caption-number">Fig. 9 </span><span class="caption-text">Image Credit: <a class="reference external" href="https://mostafa-samir.github.io/ml-theory-pt2/">Machine Learning Theory by Mostafa</a>.</span><a class="headerlink" href="#shatter" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Actually, no linear classifier in 2D can shatter any set of 4 points, not just that set; because there will always be two labellings that cannot be produced by a linear classifier. But why? See the image below.</p>
<figure class="align-default" id="impossible-dichotomy">
<img alt="../../../_images/impossible-dichotomy.png" src="../../../_images/impossible-dichotomy.png" />
<figcaption>
<p><span class="caption-number">Fig. 10 </span><span class="caption-text">Image Credit: <a class="reference external" href="https://mostafa-samir.github.io/ml-theory-pt2/">Machine Learning Theory by Mostafa</a>.</span><a class="headerlink" href="#impossible-dichotomy" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>If we arranged the points in a rectangular way like the one in the image, then let the
blue dot be class <span class="math notranslate nohighlight">\(-1\)</span> and red dot be class <span class="math notranslate nohighlight">\(+1\)</span>, then there exists no way for a
single line (hyperplane if in higher dimensions) to cut the points into two classes.</p>
<p>Moreover, <strong>no matter how you arrange these 4 points, whether be it in a line, a rectangle, S-shape or any
other arrangements, there will always be at least 2 dichotomies that cannot be generated by a linear classifier.
Maybe you could draw some arrangements for yourself and see!</strong> Come to think of it, even if you arrange you 4 points
in a circle or Z-shape, it will always have 4 “corners” which resemble the 4 points in the image above.</p>
<p>We will soon see how this fact of the impossibility of shattering 4 points is related to the VC dimension of a hypothesis set can be scaled to <span class="math notranslate nohighlight">\(N\)</span> data points. And how
this can lead us to finding a better bound!</p>
</section>
</div><p>First, let’s find a general formula for the VC dimension of a perceptron algorithm.</p>
<div class="proof theorem admonition" id="vc_dimension_of_a_perceptron">
<p class="admonition-title"><span class="caption-number">Theorem 9 </span> (VC Dimension of a Perceptron)</p>
<section class="theorem-content" id="proof-content">
<p>In general, if we have a high-dimensional perceptron algorithm, we can show this:</p>
<p>Consider the input space <span class="math notranslate nohighlight">\(\mathcal{X}=\mathbb{R}^{D} \cup\{1\}\)</span> <span class="math notranslate nohighlight">\(\left(\mathbf{x}=\left[x_{1}, \ldots, x_{D}, 1\right]^{T}\right)\)</span>. The VC dimension of the perceptron algorithm is</p>
<div class="math notranslate nohighlight">
\[
\mathrm{VCdim}=D+1
\]</div>
</section>
</div><div class="proof admonition" id="proof">
<p>Proof. See page 16 of <a class="reference external" href="https://engineering.purdue.edu/ChanGroup/ECE595/files/chapter4.pdf">ECE595: Learning Theory</a></p>
</div>
</section>
<section id="sauers-lemma-and-bounding-the-growth-function">
<h3>Sauer’s Lemma and Bounding the Growth Function<a class="headerlink" href="#sauers-lemma-and-bounding-the-growth-function" title="Permalink to this heading">#</a></h3>
<p>Now that we have the VC dimension, we can bound the growth function. The following theorem show that <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> is indeed upper bounded by a polynomial of order no greater than <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span>.</p>
<div class="proof lemma admonition" id="sauer's_lemma">
<p class="admonition-title"><span class="caption-number">Lemma 1 </span> (Sauer’s Lemma)</p>
<section class="lemma-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> be the VC dimension of a hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
m_{\mathcal{H}}(N) \leq \sum_{i=0}^{\mathrm{VCdim}}\left(\begin{array}{c}
N \\
i
\end{array}\right)
\end{split}\]</div>
</section>
</div><div class="proof admonition" id="proof">
<p>Proof. Proof can be found in Theorem <span class="math notranslate nohighlight">\(2.4\)</span> of AML’s Learning from Data textbook.</p>
</div>
<p>The bound on the growth function provided by Sauer’s Lemma is indeed much better than the exponential one we already have because it is actually a polynomial function.</p>
<p>Using this result, we can show that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
m_{\mathcal{H}}(N) \leq \sum_{i=0}^{\mathrm{VCdim}}\left(\begin{array}{c}
N \\
i
\end{array}\right) \leq \left(\frac{Ne}{\mathrm{VCdim}}\right)^{\mathrm{VCdim}} \leq \mathcal{O}\left(N^{\mathrm{VCdim}}+1\right)
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(e\)</span> is the base of the natural logarithm and <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> is the <a class="reference external" href="https://en.wikipedia.org/wiki/Big_O_notation">Big-O</a> notation for functions asymptotic (near the limits) behavior.</p>
<p>If we substitute <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> by this upper bound <span class="math notranslate nohighlight">\(N^{\mathrm{VCdim}}+1\)</span>, then the generalization bound becomes</p>
<div class="math notranslate nohighlight">
\[
\epsilon=\sqrt{\frac{1}{2 N} \log \frac{2 m_{\mathcal{H}}(N)}{\delta}} \leq \sqrt{\frac{1}{2 N} \log \frac{2\left(\textcolor{red}{N^{\mathrm{VCdim}}+1}\right)}{\delta}} .
\]</div>
<p>How do we interpret the VC dimension? The VC dimension can be informally viewed as the <strong>effective number of parameters of a model</strong>. Higher VC dimension means a more complex model, and hence a more diverse hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. Well, we have just shown that for a perceptron or linear classifier, the VC dimension is <span class="math notranslate nohighlight">\(D+1\)</span> where <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the input space. We have seen that even in 2-dimensional space, if <span class="math notranslate nohighlight">\(N=4\)</span> points, then
the linear/percepton classifier cannot shatter the points. This is because linear models being linear,
cannot model the non-linear decision boundary that can separate the 4 points. However, imagine a complex model
like a deep neural network, then you can easily shatter 4 points in 2D space because the decision
boundary can be very complex. See <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py">the moon dataset in scikit-learn</a> and have a look.</p>
<p>As a result, the growth function <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> will be big. (Think about the number of dichotomies that can be generated by a complex model versus a simple model, and hence the overlap we encounter in the union bound.) There are two scenarios of the VC dimension.</p>
<ol class="arabic">
<li><p><span class="math notranslate nohighlight">\(\mathrm{VCdim}&lt;\infty\)</span>. This implies that the generalization error will go to zero as <span class="math notranslate nohighlight">\(N\)</span> grows:</p>
<div class="math notranslate nohighlight">
\[
    \epsilon=\sqrt{\frac{1}{2 N} \log \frac{2\left(\textcolor{red}{N^{\mathrm{VCdim}}+1}\right)}{\delta}} \rightarrow 0
    \]</div>
<p>as <span class="math notranslate nohighlight">\(N \rightarrow \infty\)</span> because <span class="math notranslate nohighlight">\((\log N) / N \rightarrow 0\)</span>. If this is the case, then the final hypothesis <span class="math notranslate nohighlight">\(h_S \in \mathcal{H}\)</span> will generalize. Such generalization result holds independent of the learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>, independent of the input distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}\)</span> and independent of the target function <span class="math notranslate nohighlight">\(f\)</span>. It only depends on the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> and the training examples <span class="math notranslate nohighlight">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)}\)</span>.</p>
</li>
<li><p><span class="math notranslate nohighlight">\(\mathrm{VCdim}=\infty\)</span>. This means that the hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> is as diverse as it can be, and it is not possible to generalize. The generalization error will never go to zero.</p></li>
</ol>
<p>Are we all set about the generalization bound? It turns out that we need some additional technical modifications to ensure the validity of the generalization bound. We shall not go into the details but just state the result.</p>
<div class="proof theorem admonition" id="vc_generalization_bound">
<p class="admonition-title"><span class="caption-number">Theorem 10 </span> (The VC Generalization Bound)</p>
<section class="theorem-content" id="proof-content">
<p>For any tolerance <span class="math notranslate nohighlight">\(\delta&gt;0\)</span></p>
<div class="math notranslate nohighlight" id="equation-eq-vc-generalization-bound">
<span class="eqno">(25)<a class="headerlink" href="#equation-eq-vc-generalization-bound" title="Permalink to this equation">#</a></span>\[
\mathcal{R}_{\mathcal{D}}(h_S) \leq \hat{\mathcal{R}}_{\mathcal{S}}(h_S)+\sqrt{\frac{\mathscr{8}}{N} \log \frac{\mathscr{4} m_{\mathcal{H}}(\mathscr{2}N)}{\delta}}
\]</div>
<p>with probability at least <span class="math notranslate nohighlight">\(1-\delta\)</span>.</p>
</section>
</div><p>To this end, we have more or less answered the question “Is Learning Feasible?”.</p>
</section>
<section id="interpretating-the-generalization-bound">
<h3>Interpretating the Generalization Bound<a class="headerlink" href="#interpretating-the-generalization-bound" title="Permalink to this heading">#</a></h3>
<p>The VC generalization bound in <a class="reference internal" href="#equation-eq-vc-generalization-bound">(25)</a> is universal in the sense that it applies to all hypothesis set <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>, input space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}\)</span>, and <strong>binary</strong> target function <span class="math notranslate nohighlight">\(f\)</span>. So can we use the VC generalization bound to predict the exact generalization error for any learning scenario? Unfortunately the answer is no. The VC generalization bound we derived is a valid upper bound but also a very loose upper bound. The loose-ness nature of the generalization bound comes from the following reasons (among others):</p>
<ul class="simple">
<li><p>The Hoeffding inequality has a slack. The inequality works for all values of <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\)</span>. However, the behavior of <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\)</span> could be very different at different values, e.g., at 0 or at 0.5. Using one bound to capture both cases will result in some slack.</p></li>
<li><p>The growth function <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> gives the worst case scenario of how many dichotomies are there. If we draw the <span class="math notranslate nohighlight">\(N\)</span> data points at random, it is unlikely that we will land on the worst case, and hence the typical value of <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> could be far fewer than <span class="math notranslate nohighlight">\(2^{N}\)</span> even if <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)=2^{N}\)</span>.</p></li>
<li><p>Bounding <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(N)\)</span> by a polynomial introduces further slack.</p></li>
</ul>
<p>Therefore, the VC generalization bound can only be used a rough guideline of understanding how well the learning algorithm generalize.</p>
</section>
<section id="sample-complexity">
<h3>Sample Complexity<a class="headerlink" href="#sample-complexity" title="Permalink to this heading">#</a></h3>
<p>Sample complexity concerns about the number of training samples <span class="math notranslate nohighlight">\(N\)</span> we need to achieve the generalization performance. Recall from the generalization bound:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{R}_{\mathcal{D}}(h_S) \leq \hat{\mathcal{R}}_{\mathcal{S}}(h_S)+\sqrt{\frac{8}{N} \log \frac{4 m_{\mathcal{H}}(2 N)}{\delta}} .
\]</div>
<p>Fix a <span class="math notranslate nohighlight">\(\delta&gt;0\)</span>, if we want the generalization error to be at most <span class="math notranslate nohighlight">\(\epsilon\)</span>, we can enforce that</p>
<div class="math notranslate nohighlight">
\[
\sqrt{\frac{8}{N} \log \frac{4 m_{\mathcal{H}}(2 N)}{\delta}} \leq \epsilon
\]</div>
<p>Rearranging the terms yields <span class="math notranslate nohighlight">\(N \geq \frac{8}{\epsilon^{2}} \log \left(\frac{4 m_{\mathcal{H}}(2 N)}{\delta}\right)\)</span>. If we replace <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(2 N)\)</span> by the VC dimension, then we obtain a similar bound</p>
<div class="math notranslate nohighlight">
\[
N \geq \frac{8}{\epsilon^{2}} \log \left(\frac{4(2 N)^{\mathrm{VCdim}}+1}{\delta}\right) .
\]</div>
<div class="proof example admonition" id="sample_complexity_example">
<p class="admonition-title"><span class="caption-number">Example 7 </span> (Sample Complexity)</p>
<section class="example-content" id="proof-content">
<p>Suppose <span class="math notranslate nohighlight">\(\mathrm{VCdim}=3, \epsilon=0.1\)</span> and <span class="math notranslate nohighlight">\(\delta=0.1\)</span> (90% confidence). The number of samples we need satisfies the equation</p>
<div class="math notranslate nohighlight">
\[
N \geq \frac{8}{0.1^{2}} \log \left(\frac{4(2 N)^{3}+4}{0.1}\right) .
\]</div>
<p>If we plug in <span class="math notranslate nohighlight">\(N=1000\)</span> to the right hand side, we will obtain</p>
<div class="math notranslate nohighlight">
\[
N \geq \frac{8}{0.1^{2}} \log \left(\frac{4(2 \times 1000)^{3}+4}{0.1}\right) \approx 21,193 .
\]</div>
<p>If we repeat the calculation by plugging in <span class="math notranslate nohighlight">\(N=21,193\)</span>, obtain a new <span class="math notranslate nohighlight">\(N\)</span>, and iterate, we will eventually obtain <span class="math notranslate nohighlight">\(N \approx 30,000\)</span>. If <span class="math notranslate nohighlight">\(\mathrm{VCdim}=4\)</span>, we obtain <span class="math notranslate nohighlight">\(N \approx 40,000\)</span> samples. This means that every value of <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> corresponds to 10,000 samples. In practice, we may require significantly less number of samples. A typical number of samples is approximately <span class="math notranslate nohighlight">\(10 \times \mathrm{VCdim}\)</span>.</p>
</section>
</div></section>
<section id="model-complexity">
<h3>Model Complexity<a class="headerlink" href="#model-complexity" title="Permalink to this heading">#</a></h3>
<p>The other piece of information that can be obtained from the generalization bound is how complex the model could be. If we look at the generalization bound, we realize that the error <span class="math notranslate nohighlight">\(\epsilon\)</span> is a function of <span class="math notranslate nohighlight">\(N, \mathcal{H}\)</span> and <span class="math notranslate nohighlight">\(\delta\)</span> :</p>
<div class="math notranslate nohighlight">
\[
\mathcal{R}(h_S) \leq \hat{\mathcal{R}}(h_S)+\underbrace{\sqrt{\frac{8}{N} \log \frac{4 m_{\mathcal{H}}(2 N)}{\delta}}}_{=\epsilon(N, \mathcal{H}, \delta)}
\]</div>
<p>If we replace <span class="math notranslate nohighlight">\(m_{\mathcal{H}}(2 N)\)</span> by <span class="math notranslate nohighlight">\((2 N)^{\mathrm{VCdim}}+1\)</span>, then we can write <span class="math notranslate nohighlight">\(\epsilon(N, \mathcal{H}, \delta)\)</span> as</p>
<div class="math notranslate nohighlight">
\[
\epsilon\left(N, \mathrm{VCdim}, \delta\right)=\sqrt{\frac{8}{N} \log \left(\frac{4\left((2 N)^{\mathrm{VCdim}}+1\right)}{\delta}\right)}
\]</div>
<p>The three factors <span class="math notranslate nohighlight">\(N, \mathrm{VCdim}\)</span> and <span class="math notranslate nohighlight">\(\delta\)</span> have different influence on the error <span class="math notranslate nohighlight">\(\epsilon\)</span> :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> : The VC dimension controls the complexity of the model. As <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> grows, the in-sample error <span class="math notranslate nohighlight">\(E_{\mathrm{in}}\)</span> drops because large <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> implies that we have a more complex model to fit the training data. However, <span class="math notranslate nohighlight">\(\epsilon\)</span> grows as <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> grows. If we have a very complex model, then it would be more difficult to generalize to the out-samples. The trade-off between model complexity and generalization is shown in <a class="reference internal" href="#ece595-fig4-6"><span class="std std-numref">Fig. 11</span></a>. The blue curve represents the in-sample error <span class="math notranslate nohighlight">\(E_{\mathrm{in}}\)</span> which drops as <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> increases. The red curve represents the model complexity which increases as <span class="math notranslate nohighlight">\(\mathrm{VCdim}\)</span> increases. The black curve is the out-sample error <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\)</span>. There exists an optimal model complexity so that <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\)</span> is minimized.</p></li>
<li><p><span class="math notranslate nohighlight">\(N\)</span> : A large number of training samples always helps the generalization bound, as reflected by the fact that <span class="math notranslate nohighlight">\(\epsilon(N, \mathcal{H}, \delta) \rightarrow 0\)</span> as <span class="math notranslate nohighlight">\(N \rightarrow \infty\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\delta\)</span> : The confidence level tells us how harsh we want the generalization to be. If we want a very high confidence interval, e.h_S., <span class="math notranslate nohighlight">\(99.99 \%\)</span>, then we need a very small <span class="math notranslate nohighlight">\(\delta=0.0001\)</span>. This will in turn affect the number of training samples <span class="math notranslate nohighlight">\(N\)</span> required to achieve the confidence level and the desired error bound.</p></li>
</ul>
<figure class="align-default" id="ece595-fig4-6">
<img alt="../../../_images/ece595_fig4.6.jpeg" src="../../../_images/ece595_fig4.6.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 11 </span><span class="caption-text">The VC generalization bound suggests a trade-off between model complexity and generalization. If we use a more complex model, the in-sample error drops but the out-sample error increases. The optimal model complexity is determined when the out-sample error is minimized.</span><a class="headerlink" href="#ece595-fig4-6" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="testing-data">
<h3>Testing Data<a class="headerlink" href="#testing-data" title="Permalink to this heading">#</a></h3>
<p>The VC analysis provides us a good guideline to train a model. However, the estimate provided by the <span class="math notranslate nohighlight">\(\mathrm{VC}\)</span> analysis is often too loose to provide any accurate prediction of <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}\)</span>. In practice, no one really uses <span class="math notranslate nohighlight">\(\mathrm{VC}\)</span> analysis to inform a training process. What is more often used is a testing dataset. The testing dataset</p>
<div class="math notranslate nohighlight">
\[
\mathcal{S}_{\text {test }}=\left\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(Q)}\right\}
\]</div>
<p>contains <span class="math notranslate nohighlight">\(Q\)</span> samples drawn from the distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{D}}(\mathbf{x})\)</span>. No testing data <span class="math notranslate nohighlight">\(\mathbf{x}^{(q)}\)</span> can be in the training dataset <span class="math notranslate nohighlight">\(\mathcal{S}_{\text{train}}\)</span>.</p>
<p>Since in the testing phase the final hypothesis <span class="math notranslate nohighlight">\(h_S\)</span> is already determined, we will not run into the same trouble in the training phase where we need to use the Union bound to account for the <span class="math notranslate nohighlight">\(M\)</span> candidate hypotheses in <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>. As a result, the Hoeffding inequality simplifies to</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left\{\left|\hat{\mathcal{R}}_{\mathcal{S}}(h_S)-\mathcal{R}_{\mathcal{D}}(h_S)\right|&gt;\epsilon\right\} \leq 2 e^{-2 \epsilon^{2} Q}
\]</div>
<p>and the generalization bound becomes</p>
<div class="math notranslate nohighlight">
\[
\mathcal{R}_{\mathcal{D}}(h_S) \leq \hat{\mathcal{R}}_{\mathcal{S}}(h_S)+\sqrt{\frac{1}{2 Q} \log \frac{2}{\delta}}
\]</div>
<p>Therefore, as the number of testing samples increases, we can certify the out-sample error by evaluating <span class="math notranslate nohighlight">\(\hat{\mathcal{R}(h_S)}\)</span> using the testing samples.</p>
<p>There are a few reminders about using the testing data:</p>
<ul class="simple">
<li><p>The common notion of testing accuracy is <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S)\)</span>, calculated based on the <span class="math notranslate nohighlight">\(Q\)</span> testing samples. Therefore, having <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}(h_S)\)</span> does not imply that we will generalize well. If we change another testing dataset, <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}(h_S)\)</span> will change because it is a numerical value based on empirical sum. What is guaranteed by the generalization bound is that as long as <span class="math notranslate nohighlight">\(Q\)</span> is sufficiently large, <span class="math notranslate nohighlight">\(\mathcal{R}_{\mathcal{D}}(h_S)\)</span> will stay close to <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}_{\mathcal{S}}(h_S)\)</span> no matter which particular testing dataset we use. There is a variance associated with <span class="math notranslate nohighlight">\(\hat{\mathcal{R}}(h_S)\)</span>, and this variance is reflected by <span class="math notranslate nohighlight">\(\sqrt{\frac{1}{2 Q} \log \frac{2}{\delta}}\)</span>.</p></li>
<li><p>The testing data has to be used after the hypothesis is determined. If we ever use the testing data as a feedback to re-select the hypothesis, then it is cheating. For example, we cannot train a SVM, submit to a competition website, and mark the misclassified samples to re-design the SVM.</p></li>
<li><p>In principle the generalization bound is improved when we have more testing samples. However, most practical datasets only have training data points and no testing data points. We can partition the training set into training and validation. The proportion of training and validation needs to be carefully chosen. If we allocate too many samples for validation purpose, then we will loose our ability to training a good classifier.</p></li>
</ul>
</section>
</section>
<section id="why-must-h-be-fixed-and-defined-before-generating-the-dataset-mathcal-s">
<span id="why-must-h-be-fixed"></span><h2>Why must <span class="math notranslate nohighlight">\(h\)</span> be fixed and defined before generating the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>?<a class="headerlink" href="#why-must-h-be-fixed-and-defined-before-generating-the-dataset-mathcal-s" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://math.stackexchange.com/questions/2097429/hoeffdings-inequality-and-learning">Question and Answer from MathStackExchange</a>.</p>
<section id="some-intuition-on-the-difference-between-a-priori-and-a-posteriori">
<h3>Some intuition on the difference between <em>a-priori</em> and <em>a-posteriori</em>:<a class="headerlink" href="#some-intuition-on-the-difference-between-a-priori-and-a-posteriori" title="Permalink to this heading">#</a></h3>
<p>Some intuition on the difference between <em>a-priori</em> and <em>a-posteriori</em>:
Let <span class="math notranslate nohighlight">\(\{Y_1, ..., Y_4\}\)</span> be i.i.d. uniform random variables over <span class="math notranslate nohighlight">\([0,1]\)</span>. So for each <span class="math notranslate nohighlight">\(m \in \{1, ..., 4\}\)</span> we have</p>
<div class="math notranslate nohighlight">
\[
P[Y_m&gt;15/16]=1/16 = 0.0625
\]</div>
<section id="a-priori">
<h4>A-priori:<a class="headerlink" href="#a-priori" title="Permalink to this heading">#</a></h4>
<p>Let’s <em>a-priori</em> pick an index <span class="math notranslate nohighlight">\(K \in \{1, 2, 3, 4\}\)</span>, independent of the <span class="math notranslate nohighlight">\(Y_i\)</span> variables and before observing these variables.  We can use <em>any mass function</em> <span class="math notranslate nohighlight">\(P[K=m]\)</span> for <span class="math notranslate nohighlight">\(m \in \{1, 2, 3, 4\}\)</span>. What is <span class="math notranslate nohighlight">\(P[Y_K&gt;15/16]\)</span>?  It is still <span class="math notranslate nohighlight">\(1/16\)</span> (regardless of the mass function we use) because, by the law of total probability:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
P[Y_K&gt;15/16] &amp;= \sum_{m=1}^4P[Y_K&gt;15/16|K=m]P[K=m]\\
&amp;=\sum_{m=1}^4\underbrace{P[Y_m&gt;15/16|K=m]}_{P[Y_m&gt;15/16]}P[K=m]  \\
&amp;=\sum_{m=1}^4 (1/16)P[K=m]\\
&amp;=1/16
\end{align}
\end{split}\]</div>
<p>where the equality <span class="math notranslate nohighlight">\(P[Y_m&gt;15/16|K=m]=P[Y_m&gt;15/16]\)</span> holds because <span class="math notranslate nohighlight">\(Y_m\)</span> is independent of <span class="math notranslate nohighlight">\(K\)</span>.</p>
</section>
<section id="a-posteriori">
<h4>A-posteriori:<a class="headerlink" href="#a-posteriori" title="Permalink to this heading">#</a></h4>
<p>Now let’s <em>a-posteriori</em> pick the index <span class="math notranslate nohighlight">\(K\)</span> associated with the largest <span class="math notranslate nohighlight">\(Y_m\)</span> value, so <span class="math notranslate nohighlight">\(Y_K = \max[Y_1, Y_2, Y_3, Y_4]\)</span>.  This choice of index <span class="math notranslate nohighlight">\(K\)</span> <em>depends on the observed data</em>. Then:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
P[Y_K&gt;15/16] &amp;= 1-P[Y_1\leq 15/16, Y_2\leq 15/16, Y_3\leq 15/16,Y_4\leq 15/16]\\
&amp;=1-(15/16)^4 \\
&amp;\approx 0.2275
\end{align}
\end{split}\]</div>
<p>and so this probability is <em>much larger</em> than 1/16, even though <span class="math notranslate nohighlight">\(Y_K\)</span> is just one of the <span class="math notranslate nohighlight">\(Y_m\)</span> values and we know <span class="math notranslate nohighlight">\(P[Y_m&gt;15/16]=1/16\)</span> for all <span class="math notranslate nohighlight">\(m \in \{1, ..., 4\}\)</span>.</p>
<p>On the other hand, we know by the <em>union bound</em> that</p>
<div class="math notranslate nohighlight">
\[
\{Y_K&gt;15/16\} \subseteq \cup_{m=1}^4 \{Y_m&gt;15/16\} \implies P[Y_K&gt;15/16]\leq \sum_{m=1}^4P[Y_m&gt;15/16]=1/4
\]</div>
<p>and indeed <span class="math notranslate nohighlight">\(0.2275 \leq 1/4\)</span>.</p>
</section>
</section>
</section>
<section id="your-specific-setup">
<h2>Your specific setup<a class="headerlink" href="#your-specific-setup" title="Permalink to this heading">#</a></h2>
<p>As in my above comment, I believe we need the following extra assumptions:  We have a finite set <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and an unknown function <span class="math notranslate nohighlight">\(f:\mathcal{X}\rightarrow\mathbb{R}\)</span>.  We are certain that <span class="math notranslate nohighlight">\(f\)</span> is one of the <span class="math notranslate nohighlight">\(M\)</span> functions in the known set <span class="math notranslate nohighlight">\(\{h_1, ..., h_M\}\)</span>. We have the ability to exactly evaluate the function <span class="math notranslate nohighlight">\(f\)</span> one step at a time.  However, the set <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is too large so we want to do a probabilistic estimate.   Every time step <span class="math notranslate nohighlight">\(i\)</span> we independently chose <span class="math notranslate nohighlight">\(X_i \in \mathcal{X}\)</span>, uniformly over all points in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>.  We then observe the value of <span class="math notranslate nohighlight">\(f(X_i)\)</span> (with no noise).</p>
<p>So for a given function <span class="math notranslate nohighlight">\(h_m\)</span> we define <span class="math notranslate nohighlight">\(\phi_m\)</span> by:</p>
<div class="math notranslate nohighlight">
\[
\phi_m = P[f(X_i) \neq h_m(X_i)] = \frac{\text{number of points } x \in \mathcal{X} \text{ such that } f(x)\neq h_m(x)}{|\mathcal{X}|}
\]</div>
<p>For each <span class="math notranslate nohighlight">\(m \in \{1, ..., M\}\)</span>  define the sequence of indicator functions <span class="math notranslate nohighlight">\(\{I^{(m)}_i\}_{i=1}^{\infty}\)</span> by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
I^{(m)}_i = \left\{ \begin{array}{ll}
1 &amp;\mbox{ if $h_m(X_i) \neq f(X_i)$} \\
0  &amp; \mbox{ otherwise}
\end{array}
\right.
\end{split}\]</div>
<p>For any fixed <span class="math notranslate nohighlight">\(m \in \{1, ..., M\}\)</span> the <span class="math notranslate nohighlight">\(\{I^{(m)}_i\}_{i=1}^{\infty}\)</span> indicators are i.i.d. so we can apply Hoeffding.  Note that for each individual <span class="math notranslate nohighlight">\(m\)</span>, Hoeffding is a bound on the following <em>a-priori probability</em>:</p>
<div class="math notranslate nohighlight">
\[
P\left[\left|\frac{1}{N}\sum_{i=1}^NI_i^{(m)} - \phi_m\right|&gt;\epsilon\right] \leq 2e^{-2\epsilon^2 N} \quad (Eq. 1)
\]</div>
<p>and it is nice that the bound on the right-hand-side does not depend on the index <span class="math notranslate nohighlight">\(m\)</span>.</p>
<section id="your-specific-questions">
<h3>Your specific questions<a class="headerlink" href="#your-specific-questions" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Your first question asks why Hoeffding requires a fixed function <span class="math notranslate nohighlight">\(h\)</span> rather than a random function <span class="math notranslate nohighlight">\(H\)</span>.  It is because Hoeffding applies to i.i.d. random variables.  If we fix an index <span class="math notranslate nohighlight">\(m \in \{1, .., M\}\)</span> then the indicators <span class="math notranslate nohighlight">\(\{I^{(m)}_1, I^{(m)}_2, I^{(m)}_3, ...\}\)</span> are i.i.d. over the indices <span class="math notranslate nohighlight">\(i \in \{1, 2, 3, ...\}\)</span>. If we have a random index <span class="math notranslate nohighlight">\(K\)</span> then the indicators <span class="math notranslate nohighlight">\(\{I^{(K)}_1, I^{(K)}_2, I^{(K)}_3, ...\}\)</span> are not necessarily independent because they share a common random index <span class="math notranslate nohighlight">\(K\)</span>.</p></li>
</ol>
<p>2-4) Your remaining questions boil down to the difference between <em>a-priori probability</em> and <em>a-posteriori probability</em>.  The Hoeffding bounds in (Eq. 1) are a-priori bounds that hold for all <span class="math notranslate nohighlight">\(m \in \{1, ..., M\}\)</span>.  They are bounds on the probability the data behaves in a certain way. That probability (and its bound) is determined without observing the actual data outcome (in the same way that the probability of a fair coin flip being heads is 1/2, and this probability is determined without looking at the outcome of the flip).</p>
<p>If we <em>a-priori</em> pick a random index <span class="math notranslate nohighlight">\(K \in \{1, ..., M\}\)</span> (before observing the data and independent of the data), then we do not need the union bound:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
P\left[\left|\frac{1}{N}\sum_{i=1}^NI_i^{(K)} - \phi_K\right|&gt;\epsilon\right] &amp;= \sum_{m=1}^M P\left[\left|\frac{1}{N}\sum_{i=1}^NI_i^{(K)} - \phi_K\right|&gt;\epsilon | K=m\right]P[K=m] \\
&amp;= \sum_{m=1}^M P\left[\left|\frac{1}{N}\sum_{i=1}^NI_i^{(m)} - \phi_m\right|&gt;\epsilon | K=m \right]P[K=m] \\
&amp;\overset{(a)}{=} \sum_{m=1}^M P\left[\left|\frac{1}{N}\sum_{i=1}^NI_i^{(m)} - \phi_m\right|&gt;\epsilon \right]P[K=m] \\
&amp;\leq \sum_{m=1}^m [2e^{-2\epsilon^2 N}]P[K=m]\\
&amp;= 2e^{-2\epsilon^2 N}
\end{align}
\end{split}\]</div>
<p>where equality (a) holds because the random index <span class="math notranslate nohighlight">\(K\)</span> is independent of the data <span class="math notranslate nohighlight">\(\{I^{(m)}_i\}_{i=1}^{\infty}\)</span>.
So, if we were to <em>a-priori pick</em> a guess function <span class="math notranslate nohighlight">\(g\)</span>, independent of the data, by just picking a random index, the bound would indeed be <span class="math notranslate nohighlight">\(2e^{-2\epsilon^2 N}\)</span> rather than <span class="math notranslate nohighlight">\(2M e^{-2\epsilon^2 N}\)</span>.</p>
<p>However, if we observe the results of the data and then <em>a-posteriori</em> pick a random index <span class="math notranslate nohighlight">\(K \in \{1, ..., M\}\)</span>, the way we choose might lead us to pick an index that exhibits “atypical” a-posteriori sample paths.  So the equality (a) in the above chain of equalities does not necessarily hold for such picks.  We need to be more careful by using the union bound.</p>
<hr class="docutils" />
<p>Exercise: Code up hoefdding inequality with plot.</p>
</section>
</section>
<section id="further-readings">
<h2>Further Readings<a class="headerlink" href="#further-readings" title="Permalink to this heading">#</a></h2>
<p>This is a difficult topic to learn.  I recommend the following resources:</p>
<ul class="simple">
<li><p>Mohri, Mehryar, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of Machine Learning. MIT press, 2012.</p></li>
<li><p>Shalev-Shwartz, Shai, and Shai Ben-David. Understanding Machine Learning: From Theory to Algorithms. Cambridge University Press, 2014.</p></li>
<li><p>Abu-Mostafa, Y. S., Magdon-Ismail, M., &amp; Lin, H. (2012). Learning from Data: A Short Course.</p></li>
<li><p>Mitchell, Tom M. Machine learning. Vol. 1. , bk. 9. : McGraw-hill New York, 1997.</p></li>
<li><p><a class="reference external" href="https://www.nathanieldake.com/Mathematics/03-Probability-03-Inequalities.html">Nathaniel Dake: Probability Inequalities</a></p></li>
<li><p><a class="reference external" href="https://engineering.purdue.edu/ChanGroup/ECE595/files/chapter4.pdf">ECE595: Learning Theory</a></p></li>
<li><p><a class="reference external" href="https://engineering.purdue.edu/ChanGroup/ECE595/video.html">ECE595: Learning Theory Lectures (Part 3)</a></p></li>
<li><p><a class="reference external" href="https://mostafa-samir.github.io/ml-theory-pt2/">Mostafa Samir: Machine Learning Theory</a></p></li>
<li><p><a class="reference external" href="https://wei2624.github.io/MachineLearning/sv_learning_theory/">Zhang Wei: Learning Theory</a></p></li>
<li><p><a class="reference external" href="https://www.nathanieldake.com/Mathematics/03-Probability-03-Inequalities.html">Nathaniel Dake: Probability Inequalities</a></p></li>
<li><p>Prof chan’s video lectures ECE595: Learning Theory</p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_linear-classification/generalization-classification.html">https://d2l.ai/chapter_linear-classification/generalization-classification.html</a></p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/606895/in-learning-theory-why-cant-we-use-hoeffdings-inequality-as-our-final-bound-i">1. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
<li><p><a class="reference external" href="https://math.stackexchange.com/questions/2097429/hoeffdings-inequality-and-learning">2. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/201746/changeing-the-hypothesis-while-generating-samples">3. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/157905/in-learning-theory-why-cant-we-bound-like-pe-ing-e-outg-epsilon">4. Why is Hoeffding’s inequality invalid if we use <span class="math notranslate nohighlight">\(h_S\)</span> instead of <span class="math notranslate nohighlight">\(h\)</span>?</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Boole%27s_inequality#Example">Why do we need to use Union Bound?</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Boole%27s_inequality#Example">Union Bound Example</a></p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_linear-classification/generalization-classification.html">Generalization in Classification</a></p></li>
<li><p><a class="reference external" href="http://www.cs.cmu.edu/~ninamf/courses/601sp15/sc-2015.pdf">CMU 10-601: Machine Learning</a></p></li>
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/172191/why-is-hoeffdings-inequality-correct-in-machine-learning?">Why is the Hoeffding’s Inequality correct in Machine Learning?</a></p></li>
</ul>
<hr class="footnotes docutils" />
<aside class="footnote brackets" id="f-and-c" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Sometimes <span class="math notranslate nohighlight">\(f\)</span> is denoted as <span class="math notranslate nohighlight">\(\mathcal{c}\)</span>, the concept function.</p>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./machine_learning/fundamentals/learning_theory"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

            </article>
            

            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Is the Learning Problem Solvable?</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="../bias_and_variance/intro.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Bias and Variance Tradeoff</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#some-abuse-of-notations">
   Some Abuse of Notations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problem-statement">
   Problem Statement
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notations">
   Notations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#is-learning-feasible">
   Is Learning Feasible?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learing-outside-the-training-set-mathcal-s-deterministic-case">
     Learing Outside the Training Set
     <span class="math notranslate nohighlight">
      \(\mathcal{S}\)
     </span>
     (Deterministic Case)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#identically-and-independently-distributed-random-variables">
     Identically and Independently Distributed Random Variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learing-outside-the-training-set-mathcal-s-probabilistic-case">
     Learing Outside the Training Set
     <span class="math notranslate nohighlight">
      \(\mathcal{S}\)
     </span>
     (Probabilistic Case)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-generalization-gap">
     The Generalization Gap
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-law-of-large-numbers">
   The Law of Large Numbers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hoeffding-s-inequality">
   Hoeffding’s Inequality
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comparing-hoeffding-s-inequality-with-the-chebyshev-s-inequality">
     Comparing Hoeffding’s Inequality with the Chebyshev’s Inequality
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-hoeffding-s-inequality-in-classification">
     Example: Hoeffding’s Inequality in Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pac-framework">
   PAC Framework
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hoeffding-inequality-is-invalid-for-h-s-learnt-from-mathcal-s">
   Hoeffding Inequality is Invalid for
   <span class="math notranslate nohighlight">
    \(h_S\)
   </span>
   learnt from
   <span class="math notranslate nohighlight">
    \(\mathcal{S}\)
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#union-bound">
   Union Bound
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#framing-learning-theory-with-hoeffding-s-inequality">
   Framing Learning Theory with Hoeffding’s Inequality
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feasibility-from-the-two-view-points">
   Feasibility from the Two View Points
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complex-hypothesis-set-and-complex-target-function">
     Complex Hypothesis Set and Complex Target Function
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vc-analysis">
   VC-Analysis
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generalization-bound">
     Generalization Bound
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-growth-function">
     The Growth Function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-vc-dimension">
     The VC Dimension
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sauers-lemma-and-bounding-the-growth-function">
     Sauer’s Lemma and Bounding the Growth Function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpretating-the-generalization-bound">
     Interpretating the Generalization Bound
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sample-complexity">
     Sample Complexity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-complexity">
     Model Complexity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#testing-data">
     Testing Data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-must-h-be-fixed-and-defined-before-generating-the-dataset-mathcal-s">
   Why must
   <span class="math notranslate nohighlight">
    \(h\)
   </span>
   be fixed and defined before generating the dataset
   <span class="math notranslate nohighlight">
    \(\mathcal{S}\)
   </span>
   ?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-intuition-on-the-difference-between-a-priori-and-a-posteriori">
     Some intuition on the difference between
     <em>
      a-priori
     </em>
     and
     <em>
      a-posteriori
     </em>
     :
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-priori">
       A-priori:
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-posteriori">
       A-posteriori:
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-specific-setup">
   Your specific setup
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#your-specific-questions">
     Your specific questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-readings">
   Further Readings
  </a>
 </li>
</ul>

</nav>
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gao Hongnan
</p>

  </div>
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2023.<br>

</p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
Last updated on None.<br>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </div>
        </footer>
        

      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  </body>
</html>