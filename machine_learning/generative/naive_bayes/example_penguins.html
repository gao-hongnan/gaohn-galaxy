
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Naive Bayes Application: Penguins &#8212; Machine Learning Chronicles</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
    <script src="../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"defeq": "\\overset{\\text{def}}{=}", "defa": "\\overset{\\text{(a)}}{=}", "defb": "\\overset{\\text{(b)}}{=}", "defc": "\\overset{\\text{(c)}}{=}", "defd": "\\overset{\\text{(d)}}{=}", "st": "\\mid", "mod": "\\mid", "S": "\\Omega", "s": "\\omega", "e": "\\exp", "P": "\\mathbb{P}", "R": "\\mathbb{R}", "expectation": "\\mathbb{E}", "v": "\\mathbf{v}", "a": "\\mathbf{a}", "b": "\\mathbf{b}", "c": "\\mathbf{c}", "u": "\\mathbf{u}", "w": "\\mathbf{w}", "x": "\\mathbf{x}", "y": "\\mathbf{y}", "z": "\\mathbf{z}", "0": "\\mathbf{0}", "1": "\\mathbf{1}", "A": "\\mathbf{A}", "B": "\\mathbf{B}", "C": "\\mathbf{C}", "E": "\\mathcal{F}", "eventA": "\\mathcal{A}", "lset": "\\left\\{", "rset": "\\right\\}", "lsq": "\\left[", "rsq": "\\right]", "lpar": "\\left(", "rpar": "\\right)", "lcurl": "\\left\\{", "rcurl": "\\right\\}", "pmf": "p_X", "pdf": "f_X", "pdftwo": "f_{X,Y}", "pdfjoint": "f_{\\mathbf{X}}", "pmfjointxy": "p_{X, Y}", "pdfjointxy": "f_{X, Y}", "cdf": "F_X", "pspace": "(\\Omega, \\mathcal{F}, \\mathbb{P})", "var": "\\operatorname{Var}", "std": "\\operatorname{Std}", "bern": "\\operatorname{Bernoulli}", "binomial": "\\operatorname{Binomial}", "geometric": "\\operatorname{Geometric}", "poisson": "\\operatorname{Poisson}", "uniform": "\\operatorname{Uniform}", "normal": "\\operatorname{Normal}", "gaussian": "\\operatorname{Gaussian}", "gaussiansymbol": "\\mathcal{N}", "exponential": "\\operatorname{Exponential}", "iid": "\\textbf{i.i.d.}", "and": "\\text{and}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'machine_learning/generative/naive_bayes/example_penguins';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Naive Bayes Application (MNIST)" href="application_mnist.html" />
    <link rel="prev" title="Naives Bayes Implementation" href="implementation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../../intro.html">

  
  
  
  
  
  
  

  
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../../../_static/logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../notations/mathematical_notations.html">
                        Mathematical Notations
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../notations/machine_learning_notations.html">
                        Machine Learning Notations
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../notations/deep_learning_notations.html">
                        Deep Learning Notations
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/01_mathematical_preliminaries/intro.html">
                        Chapter 1. Mathematical Preliminaries
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/02_probability/intro.html">
                        Chapter 2. Probability
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/03_discrete_random_variables/intro.html">
                        Chapter 3. Discrete Random Variables
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/04_continuous_random_variables/intro.html">
                        Chapter 4. Continuous Random Variables
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/05_joint_distributions/intro.html">
                        Chapter 5. Joint Distributions
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/06_sample_statistics/intro.html">
                        Chapter 6. Sample Statistics
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/08_estimation_theory/intro.html">
                        Estimation Theory
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../optimization/gradient_descent/intro.html">
                        Gradient Descent
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../framework.html">
                        The Machine Learning Framework
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../fundamentals/intro.html">
                        Fundamentals
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../linear_models/intro.html">
                        Linear Models
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../intro.html">
                        Generative
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../model_selection_and_evaluation/intro.html">
                        Model Selection and Evaluation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../trees/intro.html">
                        Trees, Forests, Bagging and Boosting
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../decomposition/intro.html">
                        Dimensionality Reduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../neighbours/intro.html">
                        Neighbourhood
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mixtures/intro.html">
                        Mixture Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../clustering/intro.html">
                        Clustering
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../deep_learning/natural_language_processing/intro.html">
                        Natural Language Processing (NLP)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../references_resources_roadmap/bibliography.html">
                        Bibliography
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../references_resources_roadmap/resources.html">
                        Resources
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../notations/mathematical_notations.html">
                        Mathematical Notations
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../notations/machine_learning_notations.html">
                        Machine Learning Notations
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../notations/deep_learning_notations.html">
                        Deep Learning Notations
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/01_mathematical_preliminaries/intro.html">
                        Chapter 1. Mathematical Preliminaries
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/02_probability/intro.html">
                        Chapter 2. Probability
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/03_discrete_random_variables/intro.html">
                        Chapter 3. Discrete Random Variables
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/04_continuous_random_variables/intro.html">
                        Chapter 4. Continuous Random Variables
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/05_joint_distributions/intro.html">
                        Chapter 5. Joint Distributions
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/06_sample_statistics/intro.html">
                        Chapter 6. Sample Statistics
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../probability_theory/08_estimation_theory/intro.html">
                        Estimation Theory
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../optimization/gradient_descent/intro.html">
                        Gradient Descent
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../framework.html">
                        The Machine Learning Framework
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../fundamentals/intro.html">
                        Fundamentals
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../linear_models/intro.html">
                        Linear Models
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../intro.html">
                        Generative
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../model_selection_and_evaluation/intro.html">
                        Model Selection and Evaluation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../trees/intro.html">
                        Trees, Forests, Bagging and Boosting
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../decomposition/intro.html">
                        Dimensionality Reduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../neighbours/intro.html">
                        Neighbourhood
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mixtures/intro.html">
                        Mixture Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../clustering/intro.html">
                        Clustering
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../deep_learning/natural_language_processing/intro.html">
                        Natural Language Processing (NLP)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../references_resources_roadmap/bibliography.html">
                        Bibliography
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../references_resources_roadmap/resources.html">
                        Resources
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
  


<a class="navbar-brand logo" href="../../../intro.html">

  
  
  
  
  
  
  

  
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../../../_static/logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    </div>
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Notations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../notations/mathematical_notations.html">Mathematical Notations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notations/machine_learning_notations.html">Machine Learning Notations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notations/deep_learning_notations.html">Deep Learning Notations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Probability Theory</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../probability_theory/01_mathematical_preliminaries/intro.html">Chapter 1. Mathematical Preliminaries</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/01_mathematical_preliminaries/01_combinatorics.html">Permutations and Combinations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/01_mathematical_preliminaries/02_calculus.html">Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/01_mathematical_preliminaries/contours.html">Contour Maps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/01_mathematical_preliminaries/exercises.html">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../probability_theory/02_probability/intro.html">Chapter 2. Probability</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/02_probability/0202_probability_space.html">Probability Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/02_probability/0203_probability_axioms.html">Probability Axioms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/02_probability/0204_conditional_probability.html">Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/02_probability/0205_independence.html">Independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/02_probability/0206_bayes_theorem.html">Baye’s Theorem and the Law of Total Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/02_probability/summary.html">Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/intro.html">Chapter 3. Discrete Random Variables</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/0301_random_variables.html">Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/0302_discrete_random_variables.html">Discrete Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/0303_probability_mass_function.html">Probability Mass Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/0304_cumulative_distribution_function.html">Cumulative Distribution Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/0305_expectation.html">Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/0306_moments_and_variance.html">Moments and Variance</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/uniform/intro.html">Discrete Uniform Distribution</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/uniform/0307_discrete_uniform_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/uniform/0307_discrete_uniform_distribution_application.html">Application</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/bernoulli/intro.html">Bernoulli Distribution</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/bernoulli/0308_bernoulli_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/bernoulli/0308_bernoulli_distribution_application.html">Application</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/iid.html">Independent and Identically Distributed (IID)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/binomial/intro.html">Binomial Distribution</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_implementation.html">Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/binomial/0309_binomial_distribution_application.html">Real World Examples</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/geometric/intro.html">Geometric Distribution</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/geometric/0310_geometric_distribution_concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/poisson/intro.html">Poisson Distribution</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/poisson/0311_poisson_distribution_concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/poisson/0311_poisson_distribution_implementation.html">Implementation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/summary.html">Important</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/03_discrete_random_variables/exercises.html">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/intro.html">Chapter 4. Continuous Random Variables</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/from_discrete_to_continuous.html">From Discrete to Continuous</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/0401_continuous_random_variables.html">Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/0402_probability_density_function.html">Probability Density Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/0403_expectation.html">Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/0404_moments_and_variance.html">Moments and Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/0405_cumulative_distribution_function.html">Cumulative Distribution Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/0406_mean_median_mode.html">Mean, Median and Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/0407_continuous_uniform_distribution.html">Continuous Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/0408_exponential_distribution.html">Exponential Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/0409_gaussian_distribution.html">Gaussian Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/0410_skewness_and_kurtosis.html">Skewness and Kurtosis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/0411_convolve_and_sum_of_random_variables.html">Convolution and Sum of Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/04_continuous_random_variables/0412_functions_of_random_variables.html">Functions of Random Variables</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/intro.html">Chapter 5. Joint Distributions</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/from_single_variable_to_joint_distributions.html">From Single Variable to Joint Distributions</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0501_joint_pmf_pdf/intro.html">Joint PMF and PDF</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0501_joint_pmf_pdf/concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0502_joint_expectation_and_correlation/intro.html">Joint Expectation and Correlation</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0502_joint_expectation_and_correlation/concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/intro.html">Conditional PMF and PDF</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0503_conditional_pmf_pdf/application.html">Application</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/intro.html">Conditional Expectation and Variance</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0504_conditional_expectation_variance/exercises.html">Exercises</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0505_sum_of_random_variables/intro.html">Sum of Random Variables</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0505_sum_of_random_variables/concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0506_random_vectors/intro.html">Random Vectors</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0506_random_vectors/concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/intro.html">Multivariate Gaussian Distribution</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/application_transformation.html">Application: Plots and Transformations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/psd.html">Covariance Matrix is Positive Semi-Definite</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/eigendecomposition.html">Eigendecomposition and Covariance Matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/05_joint_distributions/0507_multivariate_gaussian/geometry_of_multivariate_gaussian.html">The Geometry of Multivariate Gaussians</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../probability_theory/06_sample_statistics/intro.html">Chapter 6. Sample Statistics</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/intro.html">Moment Generating and Characteristic Functions</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/moment_generating_function.html">Moment Generating Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/moment_generating_function_application_sum_of_rv.html">Application: Moment Generating Function and the Sum of Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/06_sample_statistics/0601_moment_generating_and_characteristic_functions/characteristic_function.html">Characteristic Function</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/06_sample_statistics/0602_probability_inequalities/intro.html">Probability Inequalities</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/06_sample_statistics/0602_probability_inequalities/concept.html">Probability Inequalities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/06_sample_statistics/0602_probability_inequalities/application.html">Application: Learning Theory</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/intro.html">Law of Large Numbers</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/convergence.html">Convergence of Sample Average</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/06_sample_statistics/0603_law_of_large_numbers/application.html">Application: Learning Theory</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../probability_theory/08_estimation_theory/intro.html">Estimation Theory</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../probability_theory/08_estimation_theory/maximum_likelihood_estimation/intro.html">Maximum Likelihood Estimation</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../probability_theory/08_estimation_theory/maximum_likelihood_estimation/concept.html">Concept</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Optimization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../optimization/gradient_descent/intro.html">Gradient Descent</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../optimization/gradient_descent/concept.html">Gradient Descent Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../optimization/gradient_descent/implementation.html">Gradient Descent Construction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../optimization/gradient_descent/application.html">Application: Gradient Descent</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../framework.html">The Machine Learning Framework</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../fundamentals/intro.html">Fundamentals</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../fundamentals/criterions/intro.html">Loss</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../fundamentals/criterions/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../fundamentals/criterions/cross_entropy_loss.html">Cross Entropy Loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../fundamentals/criterions/focal_loss.html">Focal Loss</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../fundamentals/empirical_risk_minimization/intro.html">Empirical Risk Minimization</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../fundamentals/empirical_risk_minimization/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../fundamentals/empirical_risk_minimization/bayes_optimal_classifier.html">Bayes Optimal Classifier</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../fundamentals/learning_theory/intro.html">Is the Learning Problem Solvable?</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../fundamentals/learning_theory/concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../fundamentals/bias_and_variance/intro.html">Bias and Variance Tradeoff</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../fundamentals/bias_and_variance/concept.html">Bias-Variance Tradeoff Concept</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../fundamentals/decision_boundary/intro.html">Decision Boundary</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../fundamentals/decision_boundary/concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../fundamentals/voronoi_region/intro.html">Voronoi Region</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-31"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../fundamentals/voronoi_region/concept.html">Concept</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linear_models/intro.html">Linear Models</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-32"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../linear_models/linear_regression/intro.html">Linear Regression</a><input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-33"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../linear_models/linear_regression/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../linear_models/linear_regression/implementation.html">Implementation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../linear_models/logistic_regression/intro.html">Logistic Regression</a><input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-34"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../linear_models/logistic_regression/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../linear_models/logistic_regression/implementation.html">Implementation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_models/generalized_linear_models/intro.html">Generalized Linear Models</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../intro.html">Generative</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-35"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active has-children"><a class="reference internal" href="intro.html">Naive Bayes</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-36"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="implementation.html">Naives Bayes Implementation</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">Naive Bayes Application: Penguins</a></li>
<li class="toctree-l3"><a class="reference internal" href="application_mnist.html">Naive Bayes Application (MNIST)</a></li>

</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../model_selection_and_evaluation/intro.html">Model Selection and Evaluation</a><input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-37"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../model_selection_and_evaluation/metrics/intro.html">Metrics and Scoring Rules</a><input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-38"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../model_selection_and_evaluation/metrics/classification/intro.html">Classification Metrics</a><input class="toctree-checkbox" id="toctree-checkbox-39" name="toctree-checkbox-39" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-39"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_selection_and_evaluation/metrics/classification/accuracy.html">Accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_selection_and_evaluation/metrics/classification/precision_recall_f1.html">Precision, Recall and F1 Score</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_selection_and_evaluation/metrics/classification/brier_score.html">Brier Score</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../model_selection_and_evaluation/metrics/regression/intro.html">Regression Metrics</a><input class="toctree-checkbox" id="toctree-checkbox-40" name="toctree-checkbox-40" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-40"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_selection_and_evaluation/metrics/regression/mae.html">Mean Absolute Error</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_selection_and_evaluation/metrics/regression/rmse.html">(Root) Mean Squared Error</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_selection_and_evaluation/metrics/regression/mape.html">Mean Absolute Percentage Error</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../trees/intro.html">Trees, Forests, Bagging and Boosting</a><input class="toctree-checkbox" id="toctree-checkbox-41" name="toctree-checkbox-41" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-41"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../trees/decision_trees/intro.html">Decision Trees</a><input class="toctree-checkbox" id="toctree-checkbox-42" name="toctree-checkbox-42" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-42"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../trees/decision_trees/concept.html">Braindump</a></li>





</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../trees/ensemble_learning/intro.html">Ensemble Learning</a><input class="toctree-checkbox" id="toctree-checkbox-43" name="toctree-checkbox-43" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-43"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../trees/ensemble_learning/bagging/intro.html">Bagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../trees/ensemble_learning/random_forests/intro.html">Random Forests</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../trees/ensemble_learning/boosting/intro.html">Boosting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../decomposition/intro.html">Dimensionality Reduction</a><input class="toctree-checkbox" id="toctree-checkbox-44" name="toctree-checkbox-44" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-44"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../decomposition/pca/intro.html">Principal Component Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-45" name="toctree-checkbox-45" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-45"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../decomposition/pca/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decomposition/pca/implementation.html">PCA</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../decomposition/pca/eigenface.html">Eigenface</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../neighbours/intro.html">Neighbourhood</a><input class="toctree-checkbox" id="toctree-checkbox-46" name="toctree-checkbox-46" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-46"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../neighbours/k_nearest_neighbours/intro.html">K-Nearest Neighbours</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mixtures/intro.html">Mixture Models</a><input class="toctree-checkbox" id="toctree-checkbox-47" name="toctree-checkbox-47" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-47"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mixtures/gmm/intro.html">Gaussian Mixture Models</a><input class="toctree-checkbox" id="toctree-checkbox-48" name="toctree-checkbox-48" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-48"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mixtures/gmm/concept.html">Concept</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../clustering/intro.html">Clustering</a><input class="toctree-checkbox" id="toctree-checkbox-49" name="toctree-checkbox-49" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-49"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../clustering/kmeans/intro.html">K-Means</a><input class="toctree-checkbox" id="toctree-checkbox-50" name="toctree-checkbox-50" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-50"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../clustering/kmeans/concept.html">Concept</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../clustering/kmeans/implementation.html">Implementation: K-Means (Lloyd)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../clustering/kmeans/image_segmentation.html">Application: Image Compression and Segmentation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../deep_learning/natural_language_processing/intro.html">Natural Language Processing (NLP)</a><input class="toctree-checkbox" id="toctree-checkbox-51" name="toctree-checkbox-51" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-51"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../deep_learning/natural_language_processing/vector_semantics_and_embeddings/intro.html">Vector Semantics and Embeddings</a><input class="toctree-checkbox" id="toctree-checkbox-52" name="toctree-checkbox-52" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-52"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../deep_learning/natural_language_processing/vector_semantics_and_embeddings/words_and_vectors/intro.html">Words and Vectors</a><input class="toctree-checkbox" id="toctree-checkbox-53" name="toctree-checkbox-53" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-53"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../deep_learning/natural_language_processing/vector_semantics_and_embeddings/words_and_vectors/concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../deep_learning/natural_language_processing/vector_semantics_and_embeddings/cosine_similarity/intro.html">Cosine Similarity and Notion of Closeness</a><input class="toctree-checkbox" id="toctree-checkbox-54" name="toctree-checkbox-54" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-54"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../deep_learning/natural_language_processing/vector_semantics_and_embeddings/cosine_similarity/concept.html">Concept</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deep_learning/natural_language_processing/vector_semantics_and_embeddings/cosine_similarity/implementation.html">Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deep_learning/natural_language_processing/vector_semantics_and_embeddings/cosine_similarity/word_similarity.html">Application: Word Similarity</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../deep_learning/natural_language_processing/vector_semantics_and_embeddings/tf_idf/intro.html">Term Frequency-Inverse Document Frequency (TF-IDF)</a><input class="toctree-checkbox" id="toctree-checkbox-55" name="toctree-checkbox-55" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-55"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../deep_learning/natural_language_processing/vector_semantics_and_embeddings/tf_idf/concept.html">Concept</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deep_learning/natural_language_processing/vector_semantics_and_embeddings/tf_idf/implementation.html">Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deep_learning/natural_language_processing/vector_semantics_and_embeddings/tf_idf/application.html">Movie Recommender System</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References, Resources and Roadmap</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../references_resources_roadmap/bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../references_resources_roadmap/resources.html">Resources</a></li>
</ul>

    </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        <label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" data-toggle="tooltip" data-placement="right" title="Toggle primary sidebar">
            <span class="fa-solid fa-bars"></span>
        </label>
    </div>
    <div class="header-article__right">


<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://colab.research.google.com/github/gao-hongnan/gaohn-galaxy/blob/main/galaxy/machine_learning/generative/naive_bayes/example_penguins.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="btn__icon-container">
  
    <img src="../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</a>
      
  </ul>
</div>

<button onclick="toggleFullScreen()"
  class="btn btn-sm"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<div class="dropdown dropdown-repository-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="https://github.com/gao-hongnan/gaohn-galaxy" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">repository</span>
</a>
</a>
      
      <li><a href="https://github.com/gao-hongnan/gaohn-galaxy/issues/new?title=Issue%20on%20page%20%2Fmachine_learning/generative/naive_bayes/example_penguins.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">open issue</span>
</a>
</a>
      
  </ul>
</div>



<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      <li><a href="../../../_sources/machine_learning/generative/naive_bayes/example_penguins.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</a>
      
      <li>
<button onclick="printPdf(this)"
  class="btn btn-sm dropdown-item"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</a>
      
  </ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary" data-toggle="tooltip" data-placement="left" title="Toggle secondary sidebar">
            <span class="fa-solid fa-list"></span>
        </label>
    </div>
</div>
            </div>
            
            

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Naive Bayes Application: Penguins</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dependencies">
   Dependencies
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problem-statement">
   Problem Statement
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-prior">
   The Prior
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classifying-one-penguin">
   Classifying one penguin
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-categorical-feature">
     One Categorical Feature
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-quantitative-predictor">
     One Quantitative Predictor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#two-continuous-predictors">
     Two (Continuous) Predictors
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#conditional-independence">
       Conditional Independence
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#three-predictors">
     Three Predictors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pytorch">
   PyTorch
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-readings">
   Further Readings
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>

            <article class="bd-article" role="main">
              
  <section class="tex2jax_ignore mathjax_ignore" id="naive-bayes-application-penguins">
<h1>Naive Bayes Application: Penguins<a class="headerlink" href="#naive-bayes-application-penguins" title="Permalink to this heading">#</a></h1>
<p>References</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.bayesrulesbook.com/chapter-2.html#building-a-bayesian-model-for-events">The Bayes Rules Book</a>.</p></li>
<li><p>Reference: <a class="reference external" href="https://www.bayesrulesbook.com/chapter-2.html#building-a-bayesian-model-for-events">The Bayes Rules Book</a>.</p></li>
<li><p>prior reading of concept before this.</p></li>
</ul>
<section id="dependencies">
<h2>Dependencies<a class="headerlink" href="#dependencies" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">mpatches</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">model_selection</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>
<span class="kn">from</span> <span class="nn">rich</span> <span class="kn">import</span> <span class="nb">print</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="n">parent_dir</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">()</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">parent_dir</span><span class="p">)</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parent_dir</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">src.utils.plot</span> <span class="kn">import</span> <span class="n">plot_scatter</span><span class="p">,</span> <span class="n">plot_contour</span><span class="p">,</span> <span class="n">plot_surface</span><span class="p">,</span> <span class="n">plot_bar</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">D:\a\gaohn-galaxy\gaohn-galaxy
</pre>
</div></div>
</div>
</section>
<section id="problem-statement">
<h2>Problem Statement<a class="headerlink" href="#problem-statement" title="Permalink to this heading">#</a></h2>
<p>There exist multiple penguin species throughout Antarctica, including the Adelie, Chinstrap, and Gentoo. When encountering one of these penguins on an Antarctic trip, we might classify its species</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Y= \begin{cases}A &amp; \text { Adelie } \\ C &amp; \text { Chinstrap } \\ G &amp; \text { Gentoo }\end{cases}
\end{split}\]</div>
<p>by examining various physical characteristics, such as whether the penguin weighs more than the average <span class="math notranslate nohighlight">\(4200 \mathrm{~g}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
X_1= \begin{cases}1 &amp; \text { above-average weight } \\ 0 &amp; \text { below-average weight }\end{cases}
\end{split}\]</div>
<p>as well as measurements of the penguin’s bill</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp; X_2=\text { bill length }(\text { in } \mathrm{mm}) \\
&amp; X_3=\text { flipper length }(\text { in } \mathrm{mm})
\end{aligned}
\end{split}\]</div>
<p>The penguins_bayes data, originally made available by Gorman, Williams, and Fraser (2014) and distributed by Horst, Hill, and Gorman (2020), contains the above species and feature information for a sample of 344 Antarctic penguins:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;penguins&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="c1"># penguins.head().style.set_table_attributes(&#39;style=&quot;font-size: 13px&quot;&#39;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>species</th>
      <th>island</th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>sex</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.1</td>
      <td>18.7</td>
      <td>181.0</td>
      <td>3750.0</td>
      <td>Male</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.5</td>
      <td>17.4</td>
      <td>186.0</td>
      <td>3800.0</td>
      <td>Female</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>40.3</td>
      <td>18.0</td>
      <td>195.0</td>
      <td>3250.0</td>
      <td>Female</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>36.7</td>
      <td>19.3</td>
      <td>193.0</td>
      <td>3450.0</td>
      <td>Female</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 344 entries, 0 to 343
Data columns (total 7 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   species            344 non-null    object 
 1   island             344 non-null    object 
 2   bill_length_mm     342 non-null    float64
 3   bill_depth_mm      342 non-null    float64
 4   flipper_length_mm  342 non-null    float64
 5   body_mass_g        342 non-null    float64
 6   sex                333 non-null    object 
dtypes: float64(4), object(3)
memory usage: 18.9+ KB
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>None
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>342.000000</td>
      <td>342.000000</td>
      <td>342.000000</td>
      <td>342.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>43.921930</td>
      <td>17.151170</td>
      <td>200.915205</td>
      <td>4201.754386</td>
    </tr>
    <tr>
      <th>std</th>
      <td>5.459584</td>
      <td>1.974793</td>
      <td>14.061714</td>
      <td>801.954536</td>
    </tr>
    <tr>
      <th>min</th>
      <td>32.100000</td>
      <td>13.100000</td>
      <td>172.000000</td>
      <td>2700.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>39.225000</td>
      <td>15.600000</td>
      <td>190.000000</td>
      <td>3550.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>44.450000</td>
      <td>17.300000</td>
      <td>197.000000</td>
      <td>4050.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>48.500000</td>
      <td>18.700000</td>
      <td>213.000000</td>
      <td>4750.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>59.600000</td>
      <td>21.500000</td>
      <td>231.000000</td>
      <td>6300.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Among these penguins, 152 are Adelies, 68 are Chinstraps, and 124 are Gentoos. We’ll assume throughout that the proportional breakdown of these species in our dataset reflects the species breakdown in the wild. That is, our prior assumption about any new penguin is that it’s most likely an Adelie and least likely a Chinstrap:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Adelie       152
Gentoo       124
Chinstrap     68
Name: species, dtype: int64
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Adelie       0.441860
Gentoo       0.360465
Chinstrap    0.197674
Name: species, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">missing_values_table</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function to calculate missing values by column.</span>

<span class="sd">    credit: https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Total missing values per column</span>
    <span class="n">missing_values_per_column</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># Percentage of missing values</span>
    <span class="n">missing_values_per_column_percent</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

    <span class="c1"># Make a table with the results</span>
    <span class="n">missing_value_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">missing_values_per_column</span><span class="p">,</span> <span class="n">missing_values_per_column_percent</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>

    <span class="c1"># Rename the columns</span>
    <span class="n">missing_value_table_renamed</span> <span class="o">=</span> <span class="n">missing_value_table</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
        <span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;Missing Values&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;</span><span class="si">% o</span><span class="s2">f Total Values&quot;</span><span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># Sort the table by percentage of missing descending</span>
    <span class="n">missing_value_table_renamed</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">missing_value_table_renamed</span><span class="p">[</span><span class="n">missing_value_table_renamed</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
        <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">% o</span><span class="s2">f Total Values&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Print some summary information</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Your selected dataframe has </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="si">}</span><span class="s2"> columns.</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">missing_value_table_renamed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="s2">&quot; columns that have missing values.&quot;</span>
    <span class="p">)</span>

    <span class="c1"># Return the dataframe with missing information</span>
    <span class="k">return</span> <span class="n">missing_value_table_renamed</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">missing_values_table</span><span class="p">(</span><span class="n">penguins</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Your selected dataframe has <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">7</span> columns.
There are <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5</span> columns that have missing values.
</pre>
</div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Missing Values</th>
      <th>% of Total Values</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>sex</th>
      <td>11</td>
      <td>3.2</td>
    </tr>
    <tr>
      <th>bill_length_mm</th>
      <td>2</td>
      <td>0.6</td>
    </tr>
    <tr>
      <th>bill_depth_mm</th>
      <td>2</td>
      <td>0.6</td>
    </tr>
    <tr>
      <th>flipper_length_mm</th>
      <td>2</td>
      <td>0.6</td>
    </tr>
    <tr>
      <th>body_mass_g</th>
      <td>2</td>
      <td>0.6</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We drop <code class="docutils literal notranslate"><span class="pre">sex</span></code> column for simplicity as there are quite a few missing values in it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;sex&quot;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We also drop the other NA rows for simplicity, there are only 2 of them
and they turn out to be the same row.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># drop rows with NAs, only 2 rows</span>
<span class="n">penguins</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>species</th>
      <th>island</th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.1</td>
      <td>18.7</td>
      <td>181.0</td>
      <td>3750.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.5</td>
      <td>17.4</td>
      <td>186.0</td>
      <td>3800.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>40.3</td>
      <td>18.0</td>
      <td>195.0</td>
      <td>3250.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>36.7</td>
      <td>19.3</td>
      <td>193.0</td>
      <td>3450.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Adelie</td>
      <td>Torgersen</td>
      <td>39.3</td>
      <td>20.6</td>
      <td>190.0</td>
      <td>3650.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>337</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>47.2</td>
      <td>13.7</td>
      <td>214.0</td>
      <td>4925.0</td>
    </tr>
    <tr>
      <th>338</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>46.8</td>
      <td>14.3</td>
      <td>215.0</td>
      <td>4850.0</td>
    </tr>
    <tr>
      <th>339</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>50.4</td>
      <td>15.7</td>
      <td>222.0</td>
      <td>5750.0</td>
    </tr>
    <tr>
      <th>340</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>45.2</td>
      <td>14.8</td>
      <td>212.0</td>
      <td>5200.0</td>
    </tr>
    <tr>
      <th>341</th>
      <td>Gentoo</td>
      <td>Biscoe</td>
      <td>49.9</td>
      <td>16.1</td>
      <td>213.0</td>
      <td>5400.0</td>
    </tr>
  </tbody>
</table>
<p>342 rows × 6 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Adelie       151
Gentoo       123
Chinstrap     68
Name: species, dtype: int64
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Adelie       0.441520
Gentoo       0.359649
Chinstrap    0.198830
Name: species, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_body_mass_g</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s1">&#39;body_mass_g&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The mean body mass of penguins is </span><span class="si">{</span><span class="n">mean_body_mass_g</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> grams.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">The mean body mass of penguins is <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">4201.75</span> grams.
</pre>
</div></div>
</div>
<p>We create a new categorical feature <code class="docutils literal notranslate"><span class="pre">overweight</span></code> which is 1 if the <code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code> is over the
mean, and 0 otherwise. This feature corresponds to our earlier defined random variable <span class="math notranslate nohighlight">\(X_1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;overweight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;body_mass_g&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;body_mass_g&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;overweight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    193
1    149
Name: overweight, dtype: int64
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-prior">
<span id="naive-bayes-penguin-the-prior"></span><h2>The Prior<a class="headerlink" href="#the-prior" title="Permalink to this heading">#</a></h2>
<p>The prior distribution for <span class="math notranslate nohighlight">\(Y\)</span> is a <a class="reference external" href="https://en.wikipedia.org/wiki/Categorical_distribution">categorical distribution</a> with three categories, one for each species. The prior probabilities are given by the relative frequencies of each species in the dataset:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp; \text { A } \sim \text { Categorical }(\pi_A=0.44) \\
&amp; \text { C } \sim \text { Categorical }(\pi_C=0.20) \\
&amp; \text { G } \sim \text { Categorical }(\pi_G=0.36)
\end{aligned}
\end{split}\]</div>
<p>which implies</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}(Y=A) &amp;= 0.44 \\
\mathbb{P}(Y=C) &amp;= 0.20 \\
\mathbb{P}(Y=G) &amp;= 0.36
\end{aligned}
\end{split}\]</div>
<p>Given a new penguin not in the dataset, the <strong>prior assumption</strong> says that the probability
of it being an Adelie is <span class="math notranslate nohighlight">\(0.44\)</span>, the probability of it being a Chinstrap is <span class="math notranslate nohighlight">\(0.20\)</span>, and the probability of it being a Gentoo is <span class="math notranslate nohighlight">\(0.36\)</span>.</p>
<p>We then map <span class="math notranslate nohighlight">\(A \rightarrow 0\)</span>, <span class="math notranslate nohighlight">\(C \rightarrow 1\)</span>, and <span class="math notranslate nohighlight">\(G \rightarrow 2\)</span> for convenience, as well as
to allow us to plug these values for training.</p>
<p>Let us create a new column <code class="docutils literal notranslate"><span class="pre">class_id</span></code> which is 0 for Adelie, 1 for Chinstrap, and 2 for Gentoo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;class_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s2">&quot;Adelie&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Chinstrap&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Gentoo&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span>
<span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;class_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    151
2    123
1     68
Name: class_id, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;class_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_prior</span><span class="p">(</span><span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">distribution</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">probs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">distribution</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">get_prior</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The prior distribution is </span><span class="si">{</span><span class="n">prior</span><span class="o">.</span><span class="n">probs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">The prior distribution is <span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.4415</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.1988</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.3596</span><span style="font-weight: bold">])</span>
</pre>
</div></div>
</div>
<p>This indeed matches the prior probabilities (i.e. the relative frequencies of each species in the dataset).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Adelie&quot;</span><span class="p">,</span> <span class="s2">&quot;Chinstrap&quot;</span><span class="p">,</span> <span class="s2">&quot;Gentoo&quot;</span><span class="p">]</span>
<span class="n">class_colours</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">bar</span> <span class="o">=</span> <span class="n">plot_bar</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">prior</span><span class="o">.</span><span class="n">probs</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="n">class_colours</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Class&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Prior probability&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prior distribution of penguin species&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/e6e868e76957aaea21a4a35bcee94b904ee457a1467929beaa514384e3219601.png" src="../../../_images/e6e868e76957aaea21a4a35bcee94b904ee457a1467929beaa514384e3219601.png" />
</div>
</div>
</section>
<section id="classifying-one-penguin">
<h2>Classifying one penguin<a class="headerlink" href="#classifying-one-penguin" title="Permalink to this heading">#</a></h2>
<p>Consider a <strong>new</strong> penguin with the following features:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code>: <span class="math notranslate nohighlight">\(&lt; 4200 \mathrm{~g}\)</span> (<code class="docutils literal notranslate"><span class="pre">overweight</span></code> = 0 if <code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code> <span class="math notranslate nohighlight">\(&lt; 4200 \mathrm{~g}\)</span>, 1 otherwise)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code>: <span class="math notranslate nohighlight">\(50 \mathrm{~mm}\)</span></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code>: <span class="math notranslate nohighlight">\(195 \mathrm{~mm}\)</span></p></li>
</ul>
<p>Then we want to find out the <strong>posterior</strong> distribution of the species of this penguin, given the <strong>features</strong>.
In other words, what is the probability of this penguin being an Adelie, Chinstrap, or Gentoo, given the features mentioned above.</p>
<section id="one-categorical-feature">
<h3>One Categorical Feature<a class="headerlink" href="#one-categorical-feature" title="Permalink to this heading">#</a></h3>
<p>Let us assume that we are building our Naive Bayes based off one categorical feature, <code class="docutils literal notranslate"><span class="pre">overweight</span></code>.
Then, since this penguin has a <code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code> of <span class="math notranslate nohighlight">\(&lt; 4200 \mathrm{~g}\)</span>, it belongs to the category <span class="math notranslate nohighlight">\(0\)</span> of the feature <code class="docutils literal notranslate"><span class="pre">overweight</span></code>.</p>
<p>Let us call this feature <span class="math notranslate nohighlight">\(X_1\)</span>, and the species <span class="math notranslate nohighlight">\(Y\)</span>. Then we want to find out the posterior distribution of <span class="math notranslate nohighlight">\(Y\)</span>, given <span class="math notranslate nohighlight">\(X_1=0\)</span>.</p>
<p>Let’s reproduce the figure 14.1 from the <a class="reference external" href="https://www.bayesrulesbook.com/chapter-14.html">book</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">total</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;species&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;counts&quot;</span><span class="p">)</span>
<span class="n">overweight</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">penguins</span><span class="p">[</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;overweight&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
    <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;species&quot;</span><span class="p">)[</span><span class="s2">&quot;overweight&quot;</span><span class="p">]</span>
    <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">overweight</span><span class="p">[</span><span class="s2">&quot;overweight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">i</span> <span class="o">/</span> <span class="n">j</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">overweight</span><span class="p">[</span><span class="s2">&quot;overweight&quot;</span><span class="p">],</span> <span class="n">total</span><span class="p">[</span><span class="s2">&quot;counts&quot;</span><span class="p">])</span>
<span class="p">]</span>
<span class="n">total</span><span class="p">[</span><span class="s2">&quot;counts&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">/</span> <span class="n">j</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">total</span><span class="p">[</span><span class="s2">&quot;counts&quot;</span><span class="p">],</span> <span class="n">total</span><span class="p">[</span><span class="s2">&quot;counts&quot;</span><span class="p">])]</span>

<span class="n">display</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">overweight</span><span class="p">)</span>  <span class="c1"># percentage of overweight penguins for each species</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>species</th>
      <th>counts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adelie</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Chinstrap</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Gentoo</td>
      <td>100.0</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>species</th>
      <th>overweight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adelie</td>
      <td>16.556291</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Chinstrap</td>
      <td>10.294118</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Gentoo</td>
      <td>95.121951</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># bar chart 1 -&gt; top bars (group of &#39;overweight=No&#39;)</span>
<span class="n">bar1</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;counts&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">total</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;darkblue&quot;</span><span class="p">)</span>

<span class="c1"># bar chart 2 -&gt; bottom bars (group of &#39;overweight=Yes&#39;)</span>
<span class="n">bar2</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;overweight&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">overweight</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightblue&quot;</span><span class="p">)</span>

<span class="c1"># add legend</span>
<span class="n">top_bar</span> <span class="o">=</span> <span class="n">mpatches</span><span class="o">.</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;darkblue&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;overweight = No&quot;</span><span class="p">)</span>
<span class="n">bottom_bar</span> <span class="o">=</span> <span class="n">mpatches</span><span class="o">.</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightblue&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;overweight = Yes&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="p">[</span><span class="n">top_bar</span><span class="p">,</span> <span class="n">bottom_bar</span><span class="p">])</span>

<span class="c1"># show the graph</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/c8cb8405b22ee80d5f51a7d0ed551559217bd7837f3e2d816525fddd66b50bf0.png" src="../../../_images/c8cb8405b22ee80d5f51a7d0ed551559217bd7837f3e2d816525fddd66b50bf0.png" />
</div>
</div>
<p>From the conditionals below, the Chinstrap species have the highest probability of underweight penguins by
the relative freqeuncy table. That is, for each species, we compute the relative frequency within each species as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[X_1=0|Y=A] &amp;= \frac{126}{151} \approx 0.8344 \\
\mathbb{P}[X_1=0|Y=C] &amp;= \frac{61}{68} \approx 0.8971 \\
\mathbb{P}[X_1=0|Y=G] &amp;= \frac{6}{123} \approx 0.0488
\end{aligned}
\end{split}\]</div>
<p>Note that we are abusing the notation <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> here,
since we are not talking about the <strong>true probability distribution</strong>,
but rather the <strong>(empirical) relative frequency</strong> of feature <span class="math notranslate nohighlight">\(X_1\)</span> within
each species <span class="math notranslate nohighlight">\(Y=k \in \{A, C, G\}\)</span>.</p>
<p>The expressions above are the conditional probability of <span class="math notranslate nohighlight">\(X_1=0\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> is a certain species,
also termed as the <strong>likelihood</strong> of <span class="math notranslate nohighlight">\(Y\)</span> being a certain species given <span class="math notranslate nohighlight">\(X_1=0\)</span>. Again, we are being loose with notation here as everything here is empirical!</p>
<p>So one might say that the Chinstrap species is the least likely to be overweight, and the Gentoo species is the most likely to be overweight. Well, this makes intuitive sense since we are talking
about “likelihood” here: of all <span class="math notranslate nohighlight">\(P(X_1=0|Y=A)\)</span>, <span class="math notranslate nohighlight">\(P(X_1=0|Y=C)\)</span>, and <span class="math notranslate nohighlight">\(P(X_1=0|Y=G)\)</span>, the Chinstrap species is the least likely to be overweight. This is because within the Chinstrap species, <span class="math notranslate nohighlight">\(P(X_1=0|Y=C)\)</span> is the highest,
and therefore the complement <span class="math notranslate nohighlight">\(P(X_1=1|Y=C)\)</span> is the lowest.</p>
<p>Yet before we can make any conclusions, we need to take into account the prior probabilities of each species. We should weight the relative frequencies by the prior probabilities of each species. Intuitively, since Chinstrap is also the <em><strong>rarest</strong></em> species, it diminishes the likelihood of the penguin being a Chinstrap.</p>
<p>We need to use both the prior and the likelihood to compute the <strong>posterior distribution</strong> of the species of the penguin.
The posterior distribution is the probability of the species of the penguin given the features.</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
\mathbb{P}[Y=y|X_1=x_1] = \frac{\mathbb{P}[X_1=x_1|Y=y] \mathbb{P}[Y=y]}{\mathbb{P}[X_1=x_1]}
\end{aligned}
\]</div>
<p>For example, if our given feature of the test penguin is <span class="math notranslate nohighlight">\(X_1=0\)</span>, then we need
to find the posterior distribution of <strong>all</strong> species given <span class="math notranslate nohighlight">\(X_1=0\)</span>. That is, we need to compute</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[Y=A|X_1=0] &amp;= \frac{\mathbb{P}[X_1=0|Y=A] \mathbb{P}[Y=A]}{\mathbb{P}[X_1=0]} \\
\mathbb{P}[Y=C|X_1=0] &amp;= \frac{\mathbb{P}[X_1=0|Y=C] \mathbb{P}[Y=C]}{\mathbb{P}[X_1=0]} \\
\mathbb{P}[Y=G|X_1=0] &amp;= \frac{\mathbb{P}[X_1=0|Y=G] \mathbb{P}[Y=G]}{\mathbb{P}[X_1=0]}
\end{aligned}
\end{split}\]</div>
<p>and get the <strong>argmax</strong> of the above three expressions. The argmax is the species with the highest probability.
Note this makes sense because <span class="math notranslate nohighlight">\(\mathbb{P}[Y=y|X_1=x_1]\)</span> is a legitimate probability measure
over the sample space <span class="math notranslate nohighlight">\(\Omega_Y = \{A, C, G\} = \{0, 1, 2\}\)</span>. Therefore, the argmax is the species with the highest probability in this sample space.</p>
<p>The <strong>argmax</strong> expression is as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\underbrace{\underset{y \in \{A, C, G\}}{\text{argmax}}}_{\text{species}} \underbrace{\mathbb{P}[Y=y|X_1=0]}_{\text{posterior}} &amp;= \underbrace{\underset{y \in \{A, C, G\}}{\text{argmax}}}_{\text{species}} \dfrac{\overbrace{\mathbb{P}[X_1=0|Y=y]}^{\text{likelihood}} \overbrace{\mathbb{P}[Y=y]}^{\text{prior}}}{\underbrace{\mathbb{P}[X_1=0]}_{\text{marginal}}} \\
&amp;= \underset{y \in \{A, C, G\}}{\text{argmax}} \frac{\mathbb{P}[X_1=0|Y=y] \mathbb{P}[Y=y]}{\sum_{y' \in \{A, C, G\}} \mathbb{P}[X_1=0|Y=y'] \mathbb{P}[Y=y']}
\end{aligned}
\end{split}\]</div>
<p>Note in the Bayes Rules Book, the authors used the notation <span class="math notranslate nohighlight">\(f\)</span> instead of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>,
they are the same thing in this context since both <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are discrete random variables.
Consequently, the right hand side of the equation <span class="math notranslate nohighlight">\(\mathbb{P}[X_1=x_1|Y=y]\)</span>
gives us a concrete value (the probability). However, if <span class="math notranslate nohighlight">\(X_1\)</span> were a continuous random variable, as we will see in the
next section, then the expression <span class="math notranslate nohighlight">\(\mathbb{P}[X_1=x_1|Y=y]\)</span> would not make much sense since
we the conditional probability of a continuous random variable at a point <span class="math notranslate nohighlight">\(x_1\)</span> is <span class="math notranslate nohighlight">\(0\)</span> by definition.</p>
<p>Let’s digress slightly:</p>
<p>We reconcile this by expressing Bayes Rule in terms of the probability density function (PDF) of the posterior distribution, see <a class="reference external" href="https://en.wikipedia.org/wiki/Bayes%27_theorem#Simple_form">Bayes’ Rule forms</a>.</p>
<p>The conditional PDF of the posterior distribution is</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
f_{Y|X_1}(y|x_1) = \frac{f_{X_1|Y}(x_1|y) f_{Y}(y)}{f_{X_1}(x_1)}
\end{aligned}
\]</div>
<p>We make a bold statement (not proved here but true) now that the <span class="math notranslate nohighlight">\(\hat{Y}\)</span> that maximizes
the posterior distribution in terms of Bayes Rules is the same as the <span class="math notranslate nohighlight">\(\hat{Y}\)</span> that maximizes
the posterior distribution in terms of the conditional PDF.</p>
<p>If this statement is true, then finding the argmax of the posterior PDF is the same as finding the argmax of the posterior distribution in terms of Bayes Rule.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\underset{y \in \{A, C, G\}}{\text{argmax}} f_{Y|X_1}(y|x_1) &amp;= \underset{y \in \{A, C, G\}}{\text{argmax}} \frac{f_{X_1|Y}(x_1|y) f_{Y}(y)}{f_{X_1}(x_1)} \\
&amp;= \underset{y \in \{A, C, G\}}{\text{argmax}} \frac{f_{X_1|Y}(x_1|y) f_{Y}(y)}{\sum_{y' \in \{A, C, G\}} f_{X_1|Y}(x_1|y') f_{Y}(y')}
\end{aligned}
\end{split}\]</div>
<p>Let’s go back to where we left off.</p>
<p>The table below breaks down the joint distribution table of <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X_1\)</span>, since
both are categorical, it is easy to compute the joint distribution table.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(Y\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(X_1 = 0\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(X_1 = 1\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\sum\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>A</p></td>
<td><p>126</p></td>
<td><p>25</p></td>
<td><p>151</p></td>
</tr>
<tr class="row-odd"><td><p>C</p></td>
<td><p>61</p></td>
<td><p>7</p></td>
<td><p>68</p></td>
</tr>
<tr class="row-even"><td><p>G</p></td>
<td><p>6</p></td>
<td><p>117</p></td>
<td><p>123</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\sum\)</span></p></td>
<td><p>193</p></td>
<td><p>149</p></td>
<td><p>342</p></td>
</tr>
</tbody>
</table>
<p>The below table represents the marginal distribution table of <span class="math notranslate nohighlight">\(X_1\)</span> in terms
of the relative frequency.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(Y\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(X_1 = 0\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(X_1 = 1\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\sum\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>A</p></td>
<td><p>0.365</p></td>
<td><p>0.072</p></td>
<td><p>0.437</p></td>
</tr>
<tr class="row-odd"><td><p>C</p></td>
<td><p>0.178</p></td>
<td><p>0.020</p></td>
<td><p>0.198</p></td>
</tr>
<tr class="row-even"><td><p>G</p></td>
<td><p>0.017</p></td>
<td><p>0.342</p></td>
<td><p>0.359</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\sum\)</span></p></td>
<td><p>0.560</p></td>
<td><p>0.434</p></td>
<td><p>1.000</p></td>
</tr>
</tbody>
</table>
<p>The image is a sketch of the joint distribution table of <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X_1\)</span>.</p>
<figure class="align-default" id="penguin-overweight-joint">
<a class="reference internal image-reference" href="../../../_images/penguin_overweight_joint_sketch.jpg"><img alt="../../../_images/penguin_overweight_joint_sketch.jpg" src="../../../_images/penguin_overweight_joint_sketch.jpg" style="height: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 29 </span><span class="caption-text">Joint distribution diagram of <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X_1\)</span>.</span><a class="headerlink" href="#penguin-overweight-joint" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>We can also use seaborns <code class="docutils literal notranslate"><span class="pre">jointgrid</span></code> to do a joint distribution plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">JointGrid</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;overweight&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">)</span>
<span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
<span class="c1"># bins =  np.arange(0, high + 1.5) - 0.5 # [-0.5, 0.5, 1.5]</span>
<span class="n">g</span><span class="o">.</span><span class="n">plot_joint</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">,</span><span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">plot_marginals</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/85724bd9c1c6eabeb95f89f5288d432c5205e90c03e28155d00b4bb7ed1494ef.png" src="../../../_images/85724bd9c1c6eabeb95f89f5288d432c5205e90c03e28155d00b4bb7ed1494ef.png" />
</div>
</div>
<p>The darker tone of color corresponds to a higher impulse of the joint distribution.</p>
<p>Indeed we can see that the combo of Adelie + overweight = 0 and Gentoo + overweight = 1 presents
a darker tone than the rest, indicating that <span class="math notranslate nohighlight">\(\mathbb{P}[X_1=0, Y=A]\)</span> and <span class="math notranslate nohighlight">\(\mathbb{P}[X_1=1, Y=G]\)</span> are the highest impulses of the joint distribution.</p>
<p>In our table they correspond to 0.365 and 0.342 respectively, which is consistent with the
plot.</p>
<p>The top and right are the marginal distribution of <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X_1\)</span> respectively. They are
just relative frequencies of both <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X_1\)</span> respectively.</p>
<p>Note the above all uses histogram as default, where we used normal histograms to
“estimate” the PDF of the joint distribution. We can also use a kernel density estimation (KDE) to
do so, which is a bit more smooth and accurate. Note everything here is just an estimation. We will
use it in continuous distributions later.</p>
<p>To see the empirical conditional distribution of <span class="math notranslate nohighlight">\(X_1=0\)</span> given <span class="math notranslate nohighlight">\(Y=C\)</span> for example,
it is simply given by the table above. To calculate we ask ourselves the following question:</p>
<p>What is <span class="math notranslate nohighlight">\(P(X_1=0|Y=C)\)</span>? We simply look at the table constructed earlier and see that it is <span class="math notranslate nohighlight">\(0.8971\)</span>. But to
read it off this joint distribution table, you first need to recognize that when <span class="math notranslate nohighlight">\(Y=C\)</span>, we have shrinked our table to only the rows where <span class="math notranslate nohighlight">\(Y=C\)</span> (2nd row). Then we look at the column where <span class="math notranslate nohighlight">\(X_1=0\)</span> and see that it is 61, then we divide by the sum of the row, which is 68, to get <span class="math notranslate nohighlight">\(0.8971\)</span>. Alternatively, it is
the same as saying that <span class="math notranslate nohighlight">\(\mathbb{P}[X_1=0, Y=C] / \mathbb{P}[Y=C] = 61 / 68 = 0.8971\)</span>.</p>
<p>In this scenario, the author mentioned that we can actually directly compute the posterior probability from the empirical joint distribution table.</p>
<p>For example, if we want to calculate the posterior probability of <span class="math notranslate nohighlight">\(Y=A\)</span> given <span class="math notranslate nohighlight">\(X_1=0\)</span>,
we simply look at the column <span class="math notranslate nohighlight">\(X_1=0\)</span> and calculate the relative frequency of <span class="math notranslate nohighlight">\(Y=A\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[Y=A|X_1=0] = \frac{126}{193} = 0.652
\]</div>
<p>or equivalently</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[Y=A|X_1=0] = \frac{0.365}{0.560} = 0.652
\]</div>
<p>Note that we are still talking about empirical here, so nothing is really proven yet.</p>
<p>In a similar fashion, we have</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[Y=C|X_1=0] = \frac{61}{193} = 0.315
\]</div>
<div class="math notranslate nohighlight">
\[
\mathbb{P}[Y=G|X_1=0] = \frac{6}{193} = 0.031
\]</div>
<p>This should not be surprising, since if we can construct the joint probability table,
then both the marginal and conditional probability tables can be constructed from it.
We can confirm this by computing the posterior distribution using the formula above,
using Bayes’ rule.</p>
<p>Firstly, our prior says that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[Y=A] &amp;= \frac{151}{342} = 0.4415 \\
\mathbb{P}[Y=C] &amp;= \frac{68}{342} = 0.1988 \\
\mathbb{P}[Y=G] &amp;= \frac{123}{342} = 0.3596 \\
\end{aligned}
\end{split}\]</div>
<p>These values will handle the <span class="math notranslate nohighlight">\(\mathbb{P}[Y=y]\)</span> term in the formula above.
I have to emphasize again that all of these are empirical probabilities, the actual
probability of the species of the penguin is not known, i.e <span class="math notranslate nohighlight">\(\mathbb{P}[Y=y]\)</span> is not known
but we can reasonably estimate it using statistics, and in this case we estimate
it using the relative frequency of each species, we will see later that the
relative frequency is an estimator of the actual probability by Maximum Likelihood Estimation.</p>
<p>Next, we find the likelihood terms of <span class="math notranslate nohighlight">\(\mathbb{P}[X_1=0|Y=y]\)</span> for each species <span class="math notranslate nohighlight">\(y\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[X_1=0|Y=A] &amp;= \frac{126}{151} = 0.8344 \\
\mathbb{P}[X_1=0|Y=C] &amp;= \frac{61}{68} = 0.8971 \\
\mathbb{P}[X_1=0|Y=G] &amp;= \frac{6}{123} = 0.0488 \\
\end{aligned}
\end{split}\]</div>
<p>Again, these are empirical probabilities, we are not sure if these are the actual probabilities of the features given the species, but we can reasonably estimate it using statistics, and
in this case we again use relative frequency to estimate it. We will see later this is modelled
by the Multinomial (Categorical) distribution with parameter <span class="math notranslate nohighlight">\(\pi_y\)</span>.</p>
<p>The Categorical distribution is a generalization of the Bernoulli and Binomial distributions.
When <span class="math notranslate nohighlight">\(k=2\)</span> and <span class="math notranslate nohighlight">\(n=1\)</span>, it is the Bernoulli distribution. When <span class="math notranslate nohighlight">\(k=2\)</span> and <span class="math notranslate nohighlight">\(n&gt;1\)</span>, it is the Binomial distribution.
When <span class="math notranslate nohighlight">\(k&gt;2\)</span> and <span class="math notranslate nohighlight">\(n=1\)</span>, it is the Categorical distribution.</p>
<p>Plugging these <strong>priors</strong> and <strong>likelihoods</strong> into the formula above, we get the
denominator, the normalizing constant, which is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[X_1=0] &amp;= \mathbb{P}[X_1=0|Y=A] \mathbb{P}[Y=A] \\
&amp;+ \mathbb{P}[X_1=0|Y=C] \mathbb{P}[Y=C] \\
&amp;+ \mathbb{P}[X_1=0|Y=G] \mathbb{P}[Y=G] \\
&amp;= \dfrac{193}{342} = 0.565
\end{aligned}
\end{split}\]</div>
<p>We pause a while to note that <span class="math notranslate nohighlight">\(\mathbb{P}[X_1]\)</span> is the probability of observing <span class="math notranslate nohighlight">\(X_1=x_1\)</span>,
which is independent of <span class="math notranslate nohighlight">\(Y\)</span>. We can compute it using the law of total probability.</p>
<p>Of course, this is also merely the relative frequency of <span class="math notranslate nohighlight">\(X_1=0\)</span> in the dataset, which is expected
since <span class="math notranslate nohighlight">\(X_1\)</span> is discrete (binary), but we will never know the actual probability of <span class="math notranslate nohighlight">\(X_1=0\)</span>. We can also
estimate it using Binomial distribution if we assume that it is a Bernoulli process, but
if it is continuous, then it is often harder to estimate it. We will see later that
we can omit the denominator since it is “constant” for all <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>Finally, by Bayes’ rule, we get the posterior probability of <span class="math notranslate nohighlight">\(Y=A\)</span> given <span class="math notranslate nohighlight">\(X_1=0\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[Y=A|X_1=0] &amp;= \dfrac{\mathbb{P}[X_1=0|Y=A] \mathbb{P}[Y=A]}{\mathbb{P}[X_1=0]} \\
&amp;= \dfrac{151/342 \times 126/151}{193/342} \\
&amp;= \dfrac{126}{193} = 0.6528
\end{aligned}
\end{split}\]</div>
<p>which is the same as the one we calculated earlier using the empirical joint distribution table.</p>
<p>In a similar fashion, we get the posterior probability of <span class="math notranslate nohighlight">\(Y=C\)</span> given <span class="math notranslate nohighlight">\(X_1=0\)</span>, and <span class="math notranslate nohighlight">\(Y=G\)</span> given <span class="math notranslate nohighlight">\(X_1=0\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}[Y=C|X_1=0] &amp;= \dfrac{68/342 \times 61/68}{193/342} = \dfrac{61}{193} = 0.3161 \\
\mathbb{P}[Y=G|X_1=0] &amp;= \dfrac{123/342 \times 6/123}{193/342} = \dfrac{6}{193} = 0.0311
\end{aligned}
\end{split}\]</div>
<p>And the argmax of these three posterior probabilities is <span class="math notranslate nohighlight">\(Y=A\)</span>, so we predict that the penguin is of species <span class="math notranslate nohighlight">\(A\)</span>.
We observe that to get the argmax, we do not need the denominator, because it is the same for all <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>So we can omit the denominator, and we get the same result, it may no longer sum to 1, but
it does not affect the final result.</p>
<p>We also saw here that if our prior is very low, then even though the likelihood is high, the posterior can still be
low if <code class="docutils literal notranslate"><span class="pre">prior</span> <span class="pre">&lt;&lt;</span> <span class="pre">likelihood</span></code>. This is the reason why we need to use prior knowledge to help us make better predictions.</p>
</section>
<section id="one-quantitative-predictor">
<h3>One Quantitative Predictor<a class="headerlink" href="#one-quantitative-predictor" title="Permalink to this heading">#</a></h3>
<p>We now ignore the earlier categorical predictor <span class="math notranslate nohighlight">\(X_1\)</span> and focus on the quantitative predictor <span class="math notranslate nohighlight">\(X_2\)</span>,
<code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code>. This penguin has a <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> of 50mm,
so we want to predict the species of the penguin given this information.</p>
<p>We know that as we move on to continuous space, we can no longer use “relative frequency” to estimate the probability of a continuous variable happening, as we will see later.</p>
<p>Let’s do some EDA.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bill_length_mm</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[[</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="s2">&quot;class_id&quot;</span><span class="p">]]</span>
<span class="n">display</span><span class="p">(</span><span class="n">bill_length_mm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>species</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39.1</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>39.5</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>40.3</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>36.7</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>39.3</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>337</th>
      <td>47.2</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>338</th>
      <td>46.8</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>339</th>
      <td>50.4</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>340</th>
      <td>45.2</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>341</th>
      <td>49.9</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>342 rows × 3 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x2_mean</span> <span class="o">=</span> <span class="n">bill_length_mm</span><span class="p">[</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Mean bill length across the whole population &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;without conditioning on class: </span><span class="si">{</span><span class="n">x2_mean</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> mm&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Mean bill length across the whole population without conditioning on class: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">43.92</span> mm
</pre>
</div></div>
</div>
<p>The kdeplot above is for an univariate, empirical estimation of the whole dataset, not
conditional on any class label.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plotting both distibutions on the same figure</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">common_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># plot vertical line </span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x2_mean</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="c1"># plt.legend()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/86521512c7db19687bad005e87d5715fbac2e958f3b9f60cffe84a8e898d82fc.png" src="../../../_images/86521512c7db19687bad005e87d5715fbac2e958f3b9f60cffe84a8e898d82fc.png" />
</div>
</div>
<p>To see the conditional distribution, we can use the <code class="docutils literal notranslate"><span class="pre">hue</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">seaborn.kdeplot</span></code> to plot the conditional distribution <span class="math notranslate nohighlight">\(f_{X_2|Y}(x_2|y)\)</span>. Recall that this conditional distribution
is a distribution of <span class="math notranslate nohighlight">\(X_2\)</span> in the reduced sample space <span class="math notranslate nohighlight">\(\mathcal{\Omega}_{X_2|Y}\)</span>, where <span class="math notranslate nohighlight">\(Y=y\)</span> has happened.</p>
<p>More concretely, you just imagine that given
say Adelie has happened, then we zoom into the reduced sample space of the dataset where <span class="math notranslate nohighlight">\(Y\)</span> is Adelie, and plot the distribution of <span class="math notranslate nohighlight">\(X_2\)</span> in this <strong>reduced sample space</strong> (reduced dataset). Things get a bit more complicated when we have more than one predictor, but the idea is the same, we will see later as well.</p>
<p>I want to emphasize that for 1 predictor conditioned on another random variable,
in this case <span class="math notranslate nohighlight">\(X_2\)</span> conditioned on <span class="math notranslate nohighlight">\(Y\)</span>, the conditional distribution is like a <strong>univariate distribution</strong>
in <span class="math notranslate nohighlight">\(X_2\)</span>. This is because once we <span class="math notranslate nohighlight">\(Y=y\)</span> has happened,
there is no randomness left in <span class="math notranslate nohighlight">\(Y\)</span>, we are only looking at the distribution of <span class="math notranslate nohighlight">\(X_2\)</span> in the reduced sample space <span class="math notranslate nohighlight">\(\mathcal{\Omega}_{X_2|Y}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x2</span> <span class="o">=</span> <span class="mi">50</span> <span class="c1"># penguin bill length</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plotting both distibutions on the same figure</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span>
    <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">common_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50 mm&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Density plot of bill length&quot;</span><span class="p">)</span>
<span class="c1"># plt.legend()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/f42f28e8f6761a8d45a554432fef5ad2833bb45e9cc4fc8c63bdc36d2e4613a4.png" src="../../../_images/f42f28e8f6761a8d45a554432fef5ad2833bb45e9cc4fc8c63bdc36d2e4613a4.png" />
</div>
</div>
<p>We have seen the conditional distribution plot above, let see the joint distribution of <span class="math notranslate nohighlight">\(X_2\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.
Note very carefully that this is a <strong>joint distribution</strong> of <span class="math notranslate nohighlight">\(X_2\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, not a <strong>conditional distribution</strong> of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">JointGrid</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">plot_joint</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">plot_marginals</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.JointGrid at 0x17950579730&gt;
</pre></div>
</div>
<img alt="../../../_images/17c578d73b06408ce157e317fb0ce455ae7edb729b3bdd4fe6d91a3c5031488c.png" src="../../../_images/17c578d73b06408ce157e317fb0ce455ae7edb729b3bdd4fe6d91a3c5031488c.png" />
<img alt="../../../_images/c80ca0415eaa724b211b8bc19ebd52826f2190cf703a5b032f071c53a5592256.png" src="../../../_images/c80ca0415eaa724b211b8bc19ebd52826f2190cf703a5b032f071c53a5592256.png" />
</div>
</div>
<p>We see that the for this penguin with <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> of 50mm, our gut feeling tells us
that it most likely is not an Adelie, since the distribution of <span class="math notranslate nohighlight">\(X_2\)</span> for Adelie is
much less than 50 mm. It could be a Chinstrap or a Gentoo, but we are not sure which one,
though Chinstrap is tends to be longer for bill length, but the earlier section has
told us that we should weigh the prior probability of each species into consideration.</p>
<p>We can again use Bayes’ rule to compute the posterior probability of <span class="math notranslate nohighlight">\(Y=A\)</span> given <span class="math notranslate nohighlight">\(X_2=50\)</span>,
this time we use the notation <span class="math notranslate nohighlight">\(f\)</span> to represent our earlier <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2}(y|x_2) &amp;= \dfrac{f_{X_2|Y}(x_2|y) f_{Y}(y)}{f_{X_2}(x_2)} \\
\end{aligned}
\end{split}\]</div>
<p>For example, since our given feature is <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> of 50mm, we see</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
\begin{aligned}
f_{Y|X_2}(A|50) &amp;= \dfrac{f_{X_2|Y}(50|A) f_{Y}(A)}{f_{X_2}(50)} \\
f_{Y|X_2}(C|50) &amp;= \dfrac{f_{X_2|Y}(50|C) f_{Y}(C)}{f_{X_2}(50)} \\
f_{Y|X_2}(G|50) &amp;= \dfrac{f_{X_2|Y}(50|G) f_{Y}(G)}{f_{X_2}(50)} \\
\end{aligned}
\end{split}\]</div>
<p>Again, we use argmax to solve the problem,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\underset{y \in \{A, C, G\}}{\text{argmax}} f_{Y|X_2}(y|50) &amp;= \underset{y \in \{A, C, G\}}{\text{argmax}} \dfrac{f_{X_2|Y}(50|y) f_{Y}(y)}{f_{X_2}(50)} \\
&amp;= \underset{y \in \{A, C, G\}}{\text{argmax}} \dfrac{f_{X_2|Y}(50|y) f_{Y}(y)}{\sum_{y' \in \{A, C, G\}} f_{X_2|Y}(50|y') f_{Y}(y')}\\
\end{aligned}
\end{split}\]</div>
<p>Now we met our first hurdle here since <span class="math notranslate nohighlight">\(f_{X_2|Y}(50|y)\)</span> is not easy to compute since
<span class="math notranslate nohighlight">\(X_2\)</span> is a continuous variable, we cannot construct a empirical joint distribution table like
how we did earlier (<code class="docutils literal notranslate"><span class="pre">species</span></code> vs <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> does not work here).</p>
<p>Further, we haven’t assumed a model for <span class="math notranslate nohighlight">\(X_2\)</span> yet from which to define the likelihood <span class="math notranslate nohighlight">\(\mathbb{P}[X_2=50|Y=y]\)</span> or <span class="math notranslate nohighlight">\(\mathcal{L}(X_2=50|Y=y)\)</span>. We can do like previously to assume <strong>naively (pun intended)</strong> that the distribution of <span class="math notranslate nohighlight">\(X_2\)</span> <strong>given Y</strong> is Gaussian, note carefully
that this is a <strong>conditional distribution</strong> of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>, we can also say in same
term that <span class="math notranslate nohighlight">\(X_2\)</span> is <strong>continuous</strong> and <strong>conditionally normal</strong>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
X_2 \mid Y=A \sim \mathcal{N}(\mu_A, \sigma_A^2) \\
X_2 \mid Y=C \sim \mathcal{N}(\mu_C, \sigma_C^2) \\
X_2 \mid Y=G \sim \mathcal{N}(\mu_G, \sigma_G^2)
\end{aligned}
\end{split}\]</div>
<p>Notice here that it is possible that the three conditional distributions are different with
different <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>. Technically, we can even assume that the three conditional
distributions come from different families, but we will stick to the Gaussian family for now.
We usually call this the <strong>Gaussian Naive Bayes</strong> model.</p>
<p>From the conditional plot above, we can see that the three species are not well separated in the joint distribution space, so we cannot expect a good performance from the Gaussian Naive Bayes model. For example,
50 mm could very well be either Gentoo or Chinstrap from the plot since they are not well separated.</p>
<p>In our example, the conditional distribution of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> appears quite Gaussian.
Even if not so, the Central Limit Theorem tells us that the sum of many independent random
variables tends to be Gaussian, so we can still use the Gaussian Naive Bayes model
if we have enough data (?).</p>
<p>The next question is how do we estimate the <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> for each <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>?
We can use the <strong>Maximum Likelihood Estimation</strong> (MLE) method to estimate the parameters.</p>
<p>It turns out that the MLE of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> for each <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> is the sample mean
and sample standard deviation of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>. They are unbiased estimators of the true
<span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>!</p>
<p>The below table summarizes the sample (empirical) mean and sample standard deviation of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>.
For example, the sample mean of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y=A\)</span> is 38.8 mm, and the sample standard deviation
is 2.66 mm.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Species</p></th>
<th class="head"><p>Sample Mean</p></th>
<th class="head"><p>Sample Standard Deviation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>A</p></td>
<td><p>38.8</p></td>
<td><p>2.66</p></td>
</tr>
<tr class="row-odd"><td><p>C</p></td>
<td><p>48.8</p></td>
<td><p>3.34</p></td>
</tr>
<tr class="row-even"><td><p>G</p></td>
<td><p>47.5</p></td>
<td><p>3.08</p></td>
</tr>
</tbody>
</table>
<p>Remember again, the sample mean and sample standard deviation are unbiased estimators of the true
<span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>, and can be shown by MLE.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bill_length_mean_std</span> <span class="o">=</span> <span class="n">bill_length_mm</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;species&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;bill_length_mm&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;std&#39;</span><span class="p">]})</span>
<span class="n">bill_length_mean_std</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">bill_length_mm</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
    </tr>
    <tr>
      <th>species</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>38.791391</td>
      <td>2.663405</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>48.833824</td>
      <td>3.339256</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>47.504878</td>
      <td>3.081857</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s plot the normal distribution with the sample mean and sample standard deviation for each <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>.
We also round off the sample mean and sample standard deviation to 2 decimal places for convenience and
stay true to the original book.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># rv_adelie = stats.norm(bill_length_mean_std.loc[&#39;Adelie&#39;][&#39;bill_length_mm&#39;][&#39;mean&#39;], bill_length_mean_std.loc[&#39;Adelie&#39;][&#39;bill_length_mm&#39;][&#39;std&#39;])</span>
<span class="c1"># rv_chinstrap = stats.norm(bill_length_mean_std.loc[&#39;Chinstrap&#39;][&#39;bill_length_mm&#39;][&#39;mean&#39;], bill_length_mean_std.loc[&#39;Chinstrap&#39;][&#39;bill_length_mm&#39;][&#39;std&#39;])</span>
<span class="c1"># rv_gentoo = stats.norm(bill_length_mean_std.loc[&#39;Gentoo&#39;][&#39;bill_length_mm&#39;][&#39;mean&#39;], bill_length_mean_std.loc[&#39;Gentoo&#39;][&#39;bill_length_mm&#39;][&#39;std&#39;])</span>

<span class="n">rv_adelie</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">38.8</span><span class="p">,</span> <span class="mf">2.66</span><span class="p">)</span>
<span class="n">rv_chinstrap</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">48.8</span><span class="p">,</span> <span class="mf">3.34</span><span class="p">)</span>
<span class="n">rv_gentoo</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">47.5</span><span class="p">,</span> <span class="mf">3.08</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">rv_adelie</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adelie&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">rv_chinstrap</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Chinstrap&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">rv_gentoo</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="s1">&#39;g-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gentoo&#39;</span><span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="o">+</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50.5 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;49.5 mm&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;bill_length_mm&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability density&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/11feda9f6346cfdec4decdcb8170a08483547f5887e829cc7722d0a2b252a72f.png" src="../../../_images/11feda9f6346cfdec4decdcb8170a08483547f5887e829cc7722d0a2b252a72f.png" />
</div>
</div>
<p>As we can see, the this naive assumption of Gaussian distribution for <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> is not
perfect, but it isn’t too bad either. Note the distinction in the plot here and previously.
The previous diagram is the empirical density plot of the raw data, while this one is the
density plot of the conditional gaussian distribution of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> where we have
used the sample mean and sample standard deviation as the parameters of the Gaussian <span class="math notranslate nohighlight">\(X_2 \mid Y \sim \mathcal{N}(\mu, \sigma^2)\)</span>.</p>
<p>Now we can finally solve our “hurdle” problem of computing <span class="math notranslate nohighlight">\(f_{X_2|Y}(50|y)\)</span> for each <span class="math notranslate nohighlight">\(y \in \{A, C, G\}\)</span>.</p>
<p>We can use the Gaussian density function to compute the probability density of <span class="math notranslate nohighlight">\(X_2=50\)</span> given <span class="math notranslate nohighlight">\(Y=y\)</span>.
Geometrically, we can see that the probability density of <span class="math notranslate nohighlight">\(X_2=50\)</span> given <span class="math notranslate nohighlight">\(Y=y\)</span> is the area under the
curve of the Gaussian density function at <span class="math notranslate nohighlight">\(X_2=50\)</span> for each <span class="math notranslate nohighlight">\(Y=y\)</span> around a small neighborhood <span class="math notranslate nohighlight">\(\delta\)</span>
of <span class="math notranslate nohighlight">\(X_2=50\)</span>. Illustrated in diagram above, the <span class="math notranslate nohighlight">\(\delta=0.5\)</span> mm and the area under the curve is
computed by the integral of the Gaussian density function from <span class="math notranslate nohighlight">\(X_2=49.5\)</span> to <span class="math notranslate nohighlight">\(X_2=50.5\)</span>. In reality however,
the <span class="math notranslate nohighlight">\(\delta\)</span> is infinitesimally small.</p>
<p>In practice, we just need to compute the probability density of <span class="math notranslate nohighlight">\(X_2=50\)</span> given <span class="math notranslate nohighlight">\(Y=y\)</span> at <span class="math notranslate nohighlight">\(X_2=50\)</span> and
not the actual probability. Note very carefully that PDF is not probability, it is the probability density!!!</p>
<p>As mentioned earlier, we should compute
the posterior conditional PDF and maximize over it instead of the posterior conditional probability
since probability at a point is 0 for continuous variables.</p>
<p>And so,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{X_2 \mid Y}(x_2=50 \mid y=A) &amp;= \frac{1}{\sqrt{2\pi}\sigma_A} \exp \left( -\frac{(x_2 - \mu_A)^2}{2\sigma_A^2} \right) \\
&amp;= \frac{1}{\sqrt{2\pi}\sigma_A} \exp \left( -\frac{(50 - \mu_A)^2}{2\sigma_A^2} \right) \\
&amp;= \frac{1}{\sqrt{38.8} \cdot 2.66} \exp \left( -\frac{(50 - 38.8)^2}{2 \cdot 2.66^2} \right) \\
&amp;= 0.0000212 
\end{aligned}
\end{split}\]</div>
<p>Similarly,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{X_2 \mid Y}(x_2=50 \mid y=C) &amp;= 0.112 \\
f_{X_2 \mid Y}(x_2=50 \mid y=G) &amp;= 0.09317 \\
\end{aligned}
\end{split}\]</div>
<p>Note that <span class="math notranslate nohighlight">\(\mu_A\)</span> and <span class="math notranslate nohighlight">\(\sigma_A\)</span> are the sample mean and sample standard deviation of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y=A\)</span>.
Notation wise it is fine but you can also view it as <span class="math notranslate nohighlight">\(\mu_{A|X_2}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{A|X_2}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">px2_given_adelie</span> <span class="o">=</span> <span class="n">rv_adelie</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
<span class="n">px2_given_chinstrap</span> <span class="o">=</span> <span class="n">rv_chinstrap</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
<span class="n">px2_given_gentoo</span> <span class="o">=</span> <span class="n">rv_gentoo</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;P(X_2=50|Adelie) = </span><span class="si">{</span><span class="n">px2_given_adelie</span><span class="si">:</span><span class="s1">.7f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;P(X_2=50|Chinstrap) = </span><span class="si">{</span><span class="n">px2_given_chinstrap</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;P(X_2=50|Gentoo) = </span><span class="si">{</span><span class="n">px2_given_gentoo</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">P</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">X_2</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">50</span>|Adelie<span style="font-weight: bold">)</span> = <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000212</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">P</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">X_2</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">50</span>|Chinstrap<span style="font-weight: bold">)</span> = <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.112</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">P</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">X_2</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">50</span>|Gentoo<span style="font-weight: bold">)</span> = <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.09317</span>
</pre>
</div></div>
</div>
<p>As an example, the probability density of <span class="math notranslate nohighlight">\(X_2=50\)</span> given <span class="math notranslate nohighlight">\(Y=A\)</span> is <span class="math notranslate nohighlight">\(0.0000212 \text{ mm}^{-1}\)</span>, and indeed from
the plot above, the area under the curve is definitely the smallest, and the lowest since there is
almost no Adelie with 50 mm bill length.</p>
<p>So the marginal PDF of observing a penguin with a 50 mm bill length is,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{X_2}(50) &amp;= \sum_{y \in \mathcal{Y}} f_{X_2|Y}(50|y) f_{Y}(y) \\
&amp;= \frac{151}{342} \cdot 0.0000212 + \frac{68}{342} \cdot 0.112 + \frac{123}{342} \cdot 0.09317 \\
&amp;= 0.05579
\end{aligned}
\end{split}\]</div>
<p>Once again, this number is not a probability, it is the probability density, it just means for
every 1 mm, there is a 0.05579 mm chance of observing a penguin with a 50 mm bill length
around a small neighborhood <span class="math notranslate nohighlight">\(\delta\)</span> mm of 50 mm.
In laymen, it is how “dense” the probability is at that point.</p>
<p>Then, the posterior conditional PDF of <span class="math notranslate nohighlight">\(Y\)</span> given <span class="math notranslate nohighlight">\(X_2=50\)</span> is,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2}(y=A|x_2=50) &amp;= \frac{f_{X_2|Y}(x_2=50|y=A) f_{Y}(y=A)}{f_{X_2}(x_2=50)} \\
&amp;= \dfrac{(151/342) \cdot 0.0000212}{0.05579} \\
&amp;\approx 0.0002
\end{aligned}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2}(y=C|x_2=50) \approx 0.3992 \\
\end{aligned}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2}(y=G|x_2=50) \approx 0.6006 \\
\end{aligned}
\end{split}\]</div>
<p>Again note that these are not probabilities, they are probability densities. But since they have
the same denominator, it is normalized and so sum up to 1 in this case. This time round,
the final results was pushed over again by the fact that Gentoo is more common in the wild (prior <span class="math notranslate nohighlight">\(P(Y=G)\approx 0.3605\)</span>).</p>
</section>
<section id="two-continuous-predictors">
<h3>Two (Continuous) Predictors<a class="headerlink" href="#two-continuous-predictors" title="Permalink to this heading">#</a></h3>
<p>The reality is that the data is usually multi-dimensional, and we need to use multiple predictors
to make a prediction.</p>
<p>In the previous two examples, we have seen that for the same penguin with the following features,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code>: <span class="math notranslate nohighlight">\(&lt; 4200 \mathrm{~g}\)</span> (<code class="docutils literal notranslate"><span class="pre">overweight</span></code> = 0 if <code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code> <span class="math notranslate nohighlight">\(&lt; 4200 \mathrm{~g}\)</span>, 1 otherwise)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code>: <span class="math notranslate nohighlight">\(50 \mathrm{~mm}\)</span></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code>: <span class="math notranslate nohighlight">\(195 \mathrm{~mm}\)</span></p></li>
</ul>
<p>the predictions for the species is an Adelie if we only use <code class="docutils literal notranslate"><span class="pre">overweight</span></code>, and
a Gentoo if we only use <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code>. This inconsistency suggest that
our model may have room for improvement. Intuitively, we can add
multiple predictors to our model to make a more accurate prediction, though
this is not always the case if the predictors are correlated, or if there are
too many predictors (curse of dimensionality).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">flipper_length_mm</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[[</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="s2">&quot;class_id&quot;</span><span class="p">]]</span>
<span class="n">display</span><span class="p">(</span><span class="n">flipper_length_mm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>flipper_length_mm</th>
      <th>species</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>181.0</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>186.0</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>195.0</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>193.0</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>190.0</td>
      <td>Adelie</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>337</th>
      <td>214.0</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>338</th>
      <td>215.0</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>339</th>
      <td>222.0</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>340</th>
      <td>212.0</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
    <tr>
      <th>341</th>
      <td>213.0</td>
      <td>Gentoo</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>342 rows × 3 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x3_mean</span> <span class="o">=</span> <span class="n">flipper_length_mm</span><span class="p">[</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Mean flipper length across the whole population &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;without conditioning on class: </span><span class="si">{</span><span class="n">x3_mean</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> mm&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Mean flipper length across the whole population without conditioning on class: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">200.92</span> mm
</pre>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plotting both distibutions on the same figure</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span>
    <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">common_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x3_mean</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Density plot of flipper length.&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/a028e8ea0cf5f31bd8a0f33e8943e20c7d498895491ac2a7ecb5e4fb5987fe4a.png" src="../../../_images/a028e8ea0cf5f31bd8a0f33e8943e20c7d498895491ac2a7ecb5e4fb5987fe4a.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x3</span> <span class="o">=</span> <span class="mi">195</span> <span class="c1"># penguin flipper length</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plotting both distibutions on the same figure</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span>
    <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">common_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;195 mm&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Density plot of flipper length&quot;</span><span class="p">)</span>
<span class="c1"># plt.legend()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/a2c9d3dbf4f4d5c6e77d4dd9be45b6bb825051468ad5ac42425296f46e740f07.png" src="../../../_images/a2c9d3dbf4f4d5c6e77d4dd9be45b6bb825051468ad5ac42425296f46e740f07.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plotting both distibutions on the same figure</span>
<span class="n">x2</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span>
    <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">common_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50 mm&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Density plot of bill length&quot;</span><span class="p">)</span>
<span class="c1"># plt.legend()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/f42f28e8f6761a8d45a554432fef5ad2833bb45e9cc4fc8c63bdc36d2e4613a4.png" src="../../../_images/f42f28e8f6761a8d45a554432fef5ad2833bb45e9cc4fc8c63bdc36d2e4613a4.png" />
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> are plotted above as density plots,
just by looking at them alone may be hard to distinguish between the
Chinstrap and Gentoo for the <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> plot because they are
quite close (overlap in density curve) with each other, while if you
only look at the <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> plot, you can see that the Chinstrap and
Adelie are now quite close to each other, but if you combine
both <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> together, you can see that
it is much easier to distinguish between them.</p>
<p>This plot is from <a class="reference external" href="https://seaborn.pydata.org/tutorial/distributions.html#distribution-visualization-in-other-settings">Seaborn guide</a>, one can see with default setting
we have a joint plot of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> with the marginal
histograms on the side. The joint plot is a scatter plot of the two variables.</p>
<p>The plot with <code class="docutils literal notranslate"><span class="pre">kind=hist</span></code> will show the joint distribution as a histogram, and the
rectangular bins are colored by the density of the points in each bin. The darker
the color the more points in that bin. You can understand this as impulses from chan’s book.</p>
<p>Lastly, the plot with <code class="docutils literal notranslate"><span class="pre">kind=kde</span></code> will show the joint distribution as a contour plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;hist&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span>
    <span class="n">cbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span>
    <span class="c1"># cbar=True,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.JointGrid at 0x179548e5880&gt;
</pre></div>
</div>
<img alt="../../../_images/da24e0d4326a5f9806f0e8779293f6d8004c066de2423f10ef21f8675ce3e24c.png" src="../../../_images/da24e0d4326a5f9806f0e8779293f6d8004c066de2423f10ef21f8675ce3e24c.png" />
<img alt="../../../_images/1f96c31ab42fa7c2a33257d7bb162024b2dfe3cf5f74495f0fe86d3b203d0a82.png" src="../../../_images/1f96c31ab42fa7c2a33257d7bb162024b2dfe3cf5f74495f0fe86d3b203d0a82.png" />
<img alt="../../../_images/2728d8e0b62d3b420f82a83932e018cc03d8b8e452786951017e023dc8f58b7e.png" src="../../../_images/2728d8e0b62d3b420f82a83932e018cc03d8b8e452786951017e023dc8f58b7e.png" />
</div>
</div>
<p>The contour plot is a 2d slice of the 3d density plot where <span class="math notranslate nohighlight">\(z = f_{X_1, X_2}(x_1, x_2)\)</span> is constant.</p>
<p>To see the joint distribution conditioned on the class (species) <span class="math notranslate nohighlight">\(Y\)</span>, where <span class="math notranslate nohighlight">\(Y\)</span>
can be treated as a random variable as well <a class="footnote-reference brackets" href="#id3" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>, we can use the <code class="docutils literal notranslate"><span class="pre">hue</span></code> argument.</p>
<p>To emphasise, the way to approach conditional distributions is to zoom in on the
“reduced” sample space, for example if I want to look at the conditional distribution
of <span class="math notranslate nohighlight">\(X_2\)</span> and <span class="math notranslate nohighlight">\(X_3\)</span> conditioned on <span class="math notranslate nohighlight">\(Y=G\)</span>, then you should look at the green colored
hues.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;hist&quot;</span>
<span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.JointGrid at 0x17954a99a90&gt;
</pre></div>
</div>
<img alt="../../../_images/9bec0dc07058490d359f37f126b2b56b900962e1c29dc298745d47c3c0b195f4.png" src="../../../_images/9bec0dc07058490d359f37f126b2b56b900962e1c29dc298745d47c3c0b195f4.png" />
<img alt="../../../_images/19cee528169760e62d57541d88c1cbdb6c1773625c5a4e94ed0dc37bb7bc378a.png" src="../../../_images/19cee528169760e62d57541d88c1cbdb6c1773625c5a4e94ed0dc37bb7bc378a.png" />
<img alt="../../../_images/2b907ce0f30e63b36516d0883f1e664b75b5b460a045e13a17bddca2c5c8b58a.png" src="../../../_images/2b907ce0f30e63b36516d0883f1e664b75b5b460a045e13a17bddca2c5c8b58a.png" />
</div>
</div>
<p>Now we plot two dashed lines for where <span class="math notranslate nohighlight">\(X_2=50\)</span> and <span class="math notranslate nohighlight">\(X_3=195\)</span> respectively, and
see that when combined together, the penguin lies amongst the Chinstrap species,
and it is not even close to the other two speces!!</p>
<p>To internalize this concept, we are again looking at the argmax expression below:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{y} &amp;= \arg\max_{y \in \mathcal{Y}} \mathbb{P}(Y=y|X_2=x_2,X_3=x_3) \\
        &amp;= \arg\max_{y \in \mathcal{Y}} \mathbb{P}(Y=y|X_2=50,X_3=195) \\
\end{aligned}
\end{split}\]</div>
<p>or equivalently,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{y} &amp;= \arg\max_{y \in \mathcal{Y}} f_{Y|X_2,X_3}(y|x_2,x_3) \\
        &amp;= \arg\max_{y \in \mathcal{Y}} f_{Y|X_2,X_3}(y|50,195) \\
\end{aligned}
\end{split}\]</div>
<p>We want to know <strong>given each species <span class="math notranslate nohighlight">\(Y\)</span></strong>, which <span class="math notranslate nohighlight">\(y\)</span> <strong>maximizes</strong>
this conditional probability density function <span class="math notranslate nohighlight">\(f_{Y|X_2,X_3}(y|x_2,x_3)\)</span>.
In other words, given <span class="math notranslate nohighlight">\(X_2=50\)</span> and <span class="math notranslate nohighlight">\(X_3=195\)</span>, which species <span class="math notranslate nohighlight">\(Y\)</span> has the highest
“probability” of being the true species of the penguin. And from the diagram,
we can see that the Chinstrap species has the highest probability of being the true
species of the penguin since geometrically it lies closest to where Chinstrap
will is. We will see later that the geometric interpretation of this
is correct, with the formula.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;195 mm&quot;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;hist&quot;</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;195 mm&quot;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">penguins</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;195 mm&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/8de2d648bb3effab6c23d69267acb8abbdb4ef608fbab34ab52533390b4848ba.png" src="../../../_images/8de2d648bb3effab6c23d69267acb8abbdb4ef608fbab34ab52533390b4848ba.png" />
<img alt="../../../_images/581817d4f2a560009586821551fb427af79baa79ff7bc5cafc3b2d8cc4142428.png" src="../../../_images/581817d4f2a560009586821551fb427af79baa79ff7bc5cafc3b2d8cc4142428.png" />
<img alt="../../../_images/a9064aae5978cf7f753850f111e5636777000686875a2f4f7dbcc42cd8aaf5ad.png" src="../../../_images/a9064aae5978cf7f753850f111e5636777000686875a2f4f7dbcc42cd8aaf5ad.png" />
</div>
</div>
<section id="conditional-independence">
<h4>Conditional Independence<a class="headerlink" href="#conditional-independence" title="Permalink to this heading">#</a></h4>
<p>Let’s use naive Bayes to make a prediction for the same penguin with the following features
<span class="math notranslate nohighlight">\(X_2=x_2\)</span> and <span class="math notranslate nohighlight">\(X_3=x_3\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2,X_3}(y|x_2,x_3) &amp;= \frac{f_{X_2,X_3|Y}(x_2,x_3|y) f_{Y}(y)}{f_{X_2,X_3}(x_2,x_3)} \\
                         &amp;= \frac{f_{X_2,X_3|Y}(x_2,x_3|y) f_{Y}(y)}{\sum_{y \in \mathcal{Y}} f_{X_2,X_3|Y}(x_2,x_3|y) f_{Y}(y)} \\
\end{aligned}
\end{split}\]</div>
<p>Another hurdle is presented in front of us, we need to compute the conditional
joint distribution (PDF) <span class="math notranslate nohighlight">\(f_{X_2,X_3|Y}(x_2,x_3|y)\)</span>, which is not easy to compute.</p>
<p>This is because we were dealing with only one-dimensional
distribution, even though there are two variables just now, but as I mentioned,
when we condition on <span class="math notranslate nohighlight">\(Y\)</span>, we are looking at the reduced sample space of <span class="math notranslate nohighlight">\(X\)</span> in
which <span class="math notranslate nohighlight">\(Y\)</span> is fixed,
and not the joint sample space of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. This is the reason why we can happily
use 1-dimensional Gaussian to get the conditional distribution of <span class="math notranslate nohighlight">\(X_2\)</span>.</p>
<p>To reconcile this, Naive Bayes assumes that the predictors are <strong>conditionally independent</strong><a class="footnote-reference brackets" href="#id4" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>.
It states that given <span class="math notranslate nohighlight">\(D\)</span> continuous predictors <span class="math notranslate nohighlight">\(X_1, \ldots, X_D\)</span>, they are called conditionally
independent given <span class="math notranslate nohighlight">\(Y\)</span> if the joint distribution of <span class="math notranslate nohighlight">\(X_1, \ldots, X_D\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> can be written as</p>
<div class="math notranslate nohighlight">
\[
f_{X_1,\ldots,X_D|Y}(x_1,\ldots,x_D|y) = \prod_{d=1}^n f_{X_d|Y}(x_d|y)
\]</div>
<p>The theorem holds for discrete case as well with the difference being that the
PDF is replaced by the PMF.</p>
<p>This theorem means that <em><strong>within each class (species)</strong></em>, the predictors are independent.
More concretely, if we say that <span class="math notranslate nohighlight">\(X_2\)</span> and <span class="math notranslate nohighlight">\(X_3\)</span> are conditionally independent given <span class="math notranslate nohighlight">\(Y\)</span>,
then we are saying that <em><strong>within each class (species)</strong></em>, the <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> (<span class="math notranslate nohighlight">\(X_2\)</span>)
is independent of the <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> (<span class="math notranslate nohighlight">\(X_3\)</span>). This is a very strong assumption,
but is at the heart of Naive Bayes and many other algorithms. It simplifies the parameters a lot
(see d2l on the parameters reduction). Such a strong assumption is usually not always true,
see the plot below again, within the class <code class="docutils literal notranslate"><span class="pre">Gentoo</span></code>, we can see that the <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code>
and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> exhibit some positive correlation. We will still use this assumption
even though it is not perfect.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">penguins</span><span class="o">.</span><span class="n">corr</span><span class="p">())</span> <span class="c1"># correlation matrix but not conditioned on class</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\runneradmin\AppData\Local\Temp\ipykernel_4676\2213928773.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  display(penguins.corr()) # correlation matrix but not conditioned on class
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>overweight</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>bill_length_mm</th>
      <td>1.000000</td>
      <td>-0.235053</td>
      <td>0.656181</td>
      <td>0.595110</td>
      <td>0.448506</td>
      <td>0.731369</td>
    </tr>
    <tr>
      <th>bill_depth_mm</th>
      <td>-0.235053</td>
      <td>1.000000</td>
      <td>-0.583851</td>
      <td>-0.471916</td>
      <td>-0.533576</td>
      <td>-0.744076</td>
    </tr>
    <tr>
      <th>flipper_length_mm</th>
      <td>0.656181</td>
      <td>-0.583851</td>
      <td>1.000000</td>
      <td>0.871202</td>
      <td>0.762945</td>
      <td>0.854307</td>
    </tr>
    <tr>
      <th>body_mass_g</th>
      <td>0.595110</td>
      <td>-0.471916</td>
      <td>0.871202</td>
      <td>1.000000</td>
      <td>0.851748</td>
      <td>0.750491</td>
    </tr>
    <tr>
      <th>overweight</th>
      <td>0.448506</td>
      <td>-0.533576</td>
      <td>0.762945</td>
      <td>0.851748</td>
      <td>1.000000</td>
      <td>0.689371</td>
    </tr>
    <tr>
      <th>class_id</th>
      <td>0.731369</td>
      <td>-0.744076</td>
      <td>0.854307</td>
      <td>0.750491</td>
      <td>0.689371</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Adelie</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Adelie&quot;</span><span class="p">]</span>
<span class="n">Chinstrap</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Chinstrap&quot;</span><span class="p">]</span>
<span class="n">Gentoo</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Gentoo&quot;</span><span class="p">]</span>

<span class="n">display</span><span class="p">(</span><span class="n">Adelie</span><span class="o">.</span><span class="n">corr</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span><span class="n">Chinstrap</span><span class="o">.</span><span class="n">corr</span><span class="p">())</span>
<span class="n">display</span><span class="p">(</span><span class="n">Gentoo</span><span class="o">.</span><span class="n">corr</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\runneradmin\AppData\Local\Temp\ipykernel_4676\509882408.py:5: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  display(Adelie.corr())
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>overweight</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>bill_length_mm</th>
      <td>1.000000</td>
      <td>0.391492</td>
      <td>0.325785</td>
      <td>0.548866</td>
      <td>0.338386</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>bill_depth_mm</th>
      <td>0.391492</td>
      <td>1.000000</td>
      <td>0.307620</td>
      <td>0.576138</td>
      <td>0.319450</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>flipper_length_mm</th>
      <td>0.325785</td>
      <td>0.307620</td>
      <td>1.000000</td>
      <td>0.468202</td>
      <td>0.336676</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>body_mass_g</th>
      <td>0.548866</td>
      <td>0.576138</td>
      <td>0.468202</td>
      <td>1.000000</td>
      <td>0.715684</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>overweight</th>
      <td>0.338386</td>
      <td>0.319450</td>
      <td>0.336676</td>
      <td>0.715684</td>
      <td>1.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>class_id</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\runneradmin\AppData\Local\Temp\ipykernel_4676\509882408.py:6: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  display(Chinstrap.corr())
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>overweight</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>bill_length_mm</th>
      <td>1.000000</td>
      <td>0.653536</td>
      <td>0.471607</td>
      <td>0.513638</td>
      <td>0.287084</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>bill_depth_mm</th>
      <td>0.653536</td>
      <td>1.000000</td>
      <td>0.580143</td>
      <td>0.604498</td>
      <td>0.375972</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>flipper_length_mm</th>
      <td>0.471607</td>
      <td>0.580143</td>
      <td>1.000000</td>
      <td>0.641559</td>
      <td>0.398093</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>body_mass_g</th>
      <td>0.513638</td>
      <td>0.604498</td>
      <td>0.641559</td>
      <td>1.000000</td>
      <td>0.655613</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>overweight</th>
      <td>0.287084</td>
      <td>0.375972</td>
      <td>0.398093</td>
      <td>0.655613</td>
      <td>1.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>class_id</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\runneradmin\AppData\Local\Temp\ipykernel_4676\509882408.py:7: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  display(Gentoo.corr())
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bill_length_mm</th>
      <th>bill_depth_mm</th>
      <th>flipper_length_mm</th>
      <th>body_mass_g</th>
      <th>overweight</th>
      <th>class_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>bill_length_mm</th>
      <td>1.000000</td>
      <td>0.643384</td>
      <td>0.661162</td>
      <td>0.669166</td>
      <td>0.236458</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>bill_depth_mm</th>
      <td>0.643384</td>
      <td>1.000000</td>
      <td>0.706563</td>
      <td>0.719085</td>
      <td>0.235313</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>flipper_length_mm</th>
      <td>0.661162</td>
      <td>0.706563</td>
      <td>1.000000</td>
      <td>0.702667</td>
      <td>0.240309</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>body_mass_g</th>
      <td>0.669166</td>
      <td>0.719085</td>
      <td>0.702667</td>
      <td>1.000000</td>
      <td>0.425197</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>overweight</th>
      <td>0.236458</td>
      <td>0.235313</td>
      <td>0.240309</td>
      <td>0.425197</td>
      <td>1.000000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>class_id</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It is obvious that the assumption of conditional independence is not true from the empirical data
above. However, we will still use this assumption even though it is not perfect, and in the event
if our Naive Bayes does not perform well, we know where went wrong…</p>
<p>Back to our</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2,X_3}(y|x_2,x_3) &amp;= \frac{f_{X_2,X_3|Y}(x_2,x_3|y) f_{Y}(y)}{f_{X_2,X_3}(x_2,x_3)} \\
                         &amp;= \frac{f_{X_2,X_3|Y}(x_2,x_3|y) f_{Y}(y)}{\sum_{y \in \mathcal{Y}} f_{X_2,X_3|Y}(x_2,x_3|y) f_{Y}(y)} \\
\end{aligned}
\end{split}\]</div>
<p>We now have an answer on how to unpack the joint conditional distribution <span class="math notranslate nohighlight">\(f_{X_2,X_3|Y}(x_2,x_3|y)\)</span>.</p>
<p>We can merely do</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{X_2,X_3|Y}(x_2,x_3|y) &amp;= f_{X_2|Y}(x_2|y) f_{X_3|Y}(x_3|y) \\
\end{aligned}
\end{split}\]</div>
<p>so that our previous expression becomes</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y|X_2,X_3}(y|x_2,x_3) &amp;= \frac{f_{X_2|Y}(x_2|y) f_{X_3|Y}(x_3|y) f_{Y}(y)}{\sum_{y \in \mathcal{Y}} f_{X_2|Y}(x_2|y) f_{X_3|Y}(x_3|y) f_{Y}(y)} \\
\end{aligned}
\end{split}\]</div>
<p>We have already gotten the conditional distribution of <span class="math notranslate nohighlight">\(X_2\)</span> given <span class="math notranslate nohighlight">\(Y\)</span> earlier, <span class="math notranslate nohighlight">\(f_{X_2|Y}(x_2|y)\)</span> is already
found. We can use the same method to find the conditional distribution of <span class="math notranslate nohighlight">\(X_3\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">flipper_length_mean_std</span> <span class="o">=</span> <span class="n">flipper_length_mm</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;species&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">]})</span>
<span class="n">flipper_length_mean_std</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">flipper_length_mm</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
    </tr>
    <tr>
      <th>species</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>189.953642</td>
      <td>6.539457</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>195.823529</td>
      <td>7.131894</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>217.186992</td>
      <td>6.484976</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x2_x3_mean_std</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;species&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">],</span> <span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">]}</span>
<span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">x2_x3_mean_std</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">bill_length_mm</th>
      <th colspan="2" halign="left">flipper_length_mm</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
    </tr>
    <tr>
      <th>species</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>38.791391</td>
      <td>2.663405</td>
      <td>189.953642</td>
      <td>6.539457</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>48.833824</td>
      <td>3.339256</td>
      <td>195.823529</td>
      <td>7.131894</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>47.504878</td>
      <td>3.081857</td>
      <td>217.186992</td>
      <td>6.484976</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rv_adelie</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">190.</span><span class="p">,</span> <span class="mf">6.54</span><span class="p">)</span>
<span class="n">rv_chinstrap</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">196.</span><span class="p">,</span> <span class="mf">7.13</span><span class="p">)</span>
<span class="n">rv_gentoo</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">217.</span><span class="p">,</span> <span class="mf">6.48</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">rv_adelie</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adelie&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">rv_chinstrap</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Chinstrap&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">rv_gentoo</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="mi">100</span><span class="p">)),</span> <span class="s1">&#39;g-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gentoo&#39;</span><span class="p">)</span>
<span class="c1"># plot vertical line</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;195 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x3</span><span class="o">+</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;195.5 mm&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x3</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;194.5 mm&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;flipper_length_mm&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability density&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/1773911f0fa43d2f81fd7ac3b65c76c47441b9fc40424313d9b8875743af9091.png" src="../../../_images/1773911f0fa43d2f81fd7ac3b65c76c47441b9fc40424313d9b8875743af9091.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">px3_given_adelie</span> <span class="o">=</span> <span class="n">rv_adelie</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span>
<span class="n">px3_given_chinstrap</span> <span class="o">=</span> <span class="n">rv_chinstrap</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span>
<span class="n">px3_given_gentoo</span> <span class="o">=</span> <span class="n">rv_gentoo</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;P(X_3=195|Adelie) = </span><span class="si">{</span><span class="n">px3_given_adelie</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;P(X_3=195|Chinstrap) = </span><span class="si">{</span><span class="n">px3_given_chinstrap</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;P(X_3=195|Gentoo) = </span><span class="si">{</span><span class="n">px3_given_gentoo</span><span class="si">:</span><span class="s1">.7f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">P</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">X_3</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">195</span>|Adelie<span style="font-weight: bold">)</span> = <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.04554</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">P</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">X_3</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">195</span>|Chinstrap<span style="font-weight: bold">)</span> = <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.05541</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">P</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">X_3</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">195</span>|Gentoo<span style="font-weight: bold">)</span> = <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0001934</span>
</pre>
</div></div>
</div>
<p>For formality, the code above translates to</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{X_3|Y}(x_3=195|y=A) &amp;= \frac{1}{\sqrt{2\pi}\sigma_{A}} \exp\left(-\frac{(195-\mu_{A})^2}{2\sigma_A^2}\right) \\
&amp;= 0.04554
\end{aligned}
\end{split}\]</div>
<p>Similarly, we can compute the other two conditional distributions to be <span class="math notranslate nohighlight">\(0.05541\)</span> and <span class="math notranslate nohighlight">\(0.0001934\)</span> respectively.</p>
<p>Next, we compute the denominator, which is the joint distribution of observing <span class="math notranslate nohighlight">\(X_2=50\)</span> and <span class="math notranslate nohighlight">\(X_3=195\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\sum_{y \in \mathcal{Y}} f_{X_2|Y}(x_2|y) f_{X_3|Y}(x_3|y) f_{Y}(y) &amp;= \sum_{y \in \mathcal{Y}} f_{X_2|Y}(x_2=50|y) f_{X_3|Y}(x_3=195|y) f_{Y}(y) \\
&amp;= f_{X_2|Y=A}(x_2=50|y=A) f_{X_3|Y=A}(x_3=195|y=A) f_{Y}(y=A) \\
&amp;+ f_{X_2|Y=C}(x_2=50|y=C) f_{X_3|Y=C}(x_3=195|y=C) f_{Y}(y=C) \\
&amp;+ f_{X_2|Y=G}(x_2=50|y=G) f_{X_3|Y=G}(x_3=195|y=G) f_{Y}(y=G) \\
&amp;= 0.0000212 \cdot 0.04554 \cdot \frac{151}{342} \\
&amp;+ 0.112 \cdot 0.05541 \cdot \frac{68}{342} \\
&amp;+ 0.09317 \cdot 0.0001934 \cdot \frac{123}{342} \\
&amp;\approx 0.001241
\end{aligned}
\end{split}\]</div>
<p>We plug into Bayes’ rule to get the posterior probability of <span class="math notranslate nohighlight">\(Y=A\)</span> given <span class="math notranslate nohighlight">\(X_2=50\)</span> and <span class="math notranslate nohighlight">\(X_3=195\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y=A|X_2,X_3}(y=A|x_2=50,x_3=195) &amp;= \frac{f_{X_2|Y=A}(x_2=50|y=A) f_{X_3|Y=A}(x_3=195|y=A) f_{Y}(y=A)}{\sum_{y \in \mathcal{Y}} f_{X_2|Y}(x_2|y) f_{X_3|Y}(x_3|y) f_{Y}(y)} \\
&amp;= \frac{0.0000212 \cdot 0.04554 \cdot \frac{151}{342}}{0.001241} \\
&amp;\approx 0.0003
\end{aligned}
\end{split}\]</div>
<p>Similarly, we can compute the posterior probability of <span class="math notranslate nohighlight">\(Y=C\)</span> and <span class="math notranslate nohighlight">\(Y=G\)</span> given <span class="math notranslate nohighlight">\(X_2=50\)</span> and <span class="math notranslate nohighlight">\(X_3=195\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{Y=C|X_2,X_3}(y=C|x_2=50,x_3=195) &amp;\approx 0.9944 \\
f_{Y=G|X_2,X_3}(y=G|x_2=50,x_3=195) &amp;\approx 0.0052
\end{aligned}
\end{split}\]</div>
<p>We then take the argmax of the posterior probabilities to get the prediction. In this case,
it is <span class="math notranslate nohighlight">\(Y=C\)</span> with a posterior probability of <span class="math notranslate nohighlight">\(0.9944\)</span>.</p>
</section>
</section>
<section id="three-predictors">
<h3>Three Predictors<a class="headerlink" href="#three-predictors" title="Permalink to this heading">#</a></h3>
<p>Even though not mentioned in the book, we can also use 3 predictors to make a prediction.
The three predictors are <code class="docutils literal notranslate"><span class="pre">overweight</span></code>, <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code>, and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code>. The tricky
part is that <code class="docutils literal notranslate"><span class="pre">overweight</span></code> is a categorical variable, and <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code>
are continuous variables. We can still do it though, <a class="reference external" href="https://dafriedman97.github.io/mlbook/content/c4/concept.html#model-structure">dafriedman97</a>
mentioned that we for a random vector <span class="math notranslate nohighlight">\(\mathbf{X} = (X_{1}, X_{2}, \ldots, X_{D})\)</span>, the individual
predictors can take on different distributions. In our case, <code class="docutils literal notranslate"><span class="pre">overweight</span></code> is assumed to be follow a Bernoulli distribution,
<code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> are assumed to be follow a Gaussian distribution. Note again that
this is an assumption, and we can always change it to something else if we want to since Naive Bayes does
not have any assumptions on the distribution of the predictors (potentially confusing part!).</p>
</section>
<section id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h3>
<p>Here we summarize a few key points.</p>
<ul class="simple">
<li><p>If prior is low but likelihood is high, then posterior may not be high if prior &lt;&lt; likelihood.</p></li>
<li><p>The normalizing constant is constant during argmax comparison, and hence is often omitted. You can
always recover the normalizing constant since you have the posterior and the numerator.</p></li>
<li><p>The key here is estimation theory, for example, to estimate the priors, all we need to do is to
find the proportion of each class in the training set. This proportion is an unbiased estimator
of the true prior probability.</p></li>
<li><p>Conditional Independence is key for Naive Bayes to work, but if your model does not do well,
then this assumption may be violated. Note that the conditional independence assumption along
with the <span class="math notranslate nohighlight">\(\iid\)</span> assumpiton are the only assumptions for Naive Bayes. Assuming the conditional
distribution is Gaussian is not an assumption, it is just a way to make the model tractable.
You can come up with your own assumptions for the conditional distribution.</p></li>
</ul>
</section>
</section>
<section id="pytorch">
<h2>PyTorch<a class="headerlink" href="#pytorch" title="Permalink to this heading">#</a></h2>
<p>Subset data to only include <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code>.</p>
<p>Further split the data into training and test sets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[[</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">,</span> <span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s2">&quot;class_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">estimate_prior_parameters</span><span class="p">(</span><span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate the prior distribution of the classes based on the </span>
<span class="sd">    relative frequencies of the classes in the dataset.&quot;&quot;&quot;</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">distribution</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">probs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">distribution</span>
</pre></div>
</div>
</div>
</div>
<p>The prior distribution of the <strong>whole</strong> (not split) is indeed the same as the prior distribution we
got in the previous section <a class="reference internal" href="#naive-bayes-penguin-the-prior"><span class="std std-ref">The Prior</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">estimate_prior_parameters</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prior distribution: </span><span class="si">{</span><span class="n">prior</span><span class="o">.</span><span class="n">probs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Prior distribution: <span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.4415</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.1988</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.3596</span><span style="font-weight: bold">])</span>
</pre>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">estimate_likelihood_parameters</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimate the parameters of X conditional on y where X | y is</span>
<span class="sd">    assumed to be univariate gaussian for each X_d in X.&quot;&quot;&quot;</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># mean vector = loc -&gt; (n_classes, n_features)</span>
    <span class="n">loc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
    <span class="c1"># covariance matrix -&gt; (n_classes, n_features)</span>
    <span class="c1"># diagonal matrix since features are independent</span>
    <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
        <span class="n">X_where_k</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">k</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">):</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">X_where_k</span><span class="p">[:,</span> <span class="n">d</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">X_where_k</span><span class="p">[:,</span> <span class="n">d</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
            <span class="n">loc</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">d</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean</span>
            <span class="n">covariance_matrix</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">]</span> <span class="o">=</span> <span class="n">var</span>

    <span class="n">distribution</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span>
        <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">covariance_matrix</span><span class="o">=</span><span class="n">covariance_matrix</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">distribution</span>
</pre></div>
</div>
</div>
</div>
<p>Sanity check that mean and variance are correct when compared to the results from pandas dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x2_x3_mean_std_var</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;species&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">,</span> <span class="s2">&quot;var&quot;</span><span class="p">],</span> <span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">,</span> <span class="s2">&quot;var&quot;</span><span class="p">]})</span>
<span class="n">display</span><span class="p">(</span><span class="n">x2_x3_mean_std_var</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="3" halign="left">bill_length_mm</th>
      <th colspan="3" halign="left">flipper_length_mm</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>var</th>
      <th>mean</th>
      <th>std</th>
      <th>var</th>
    </tr>
    <tr>
      <th>species</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Adelie</th>
      <td>38.791391</td>
      <td>2.663405</td>
      <td>7.093725</td>
      <td>189.953642</td>
      <td>6.539457</td>
      <td>42.764503</td>
    </tr>
    <tr>
      <th>Chinstrap</th>
      <td>48.833824</td>
      <td>3.339256</td>
      <td>11.150630</td>
      <td>195.823529</td>
      <td>7.131894</td>
      <td>50.863916</td>
    </tr>
    <tr>
      <th>Gentoo</th>
      <td>47.504878</td>
      <td>3.081857</td>
      <td>9.497845</td>
      <td>217.186992</td>
      <td>6.484976</td>
      <td>42.054911</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_conditionals</span> <span class="o">=</span> <span class="n">estimate_likelihood_parameters</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean vector:</span><span class="se">\n</span><span class="si">{</span><span class="n">class_conditionals</span><span class="o">.</span><span class="n">mean</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Covariance matrix:</span><span class="se">\n</span><span class="si">{</span><span class="n">class_conditionals</span><span class="o">.</span><span class="n">covariance_matrix</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Mean vector:
<span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">38.7914</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">189.9536</span><span style="font-weight: bold">]</span>,
        <span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">48.8338</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">195.8235</span><span style="font-weight: bold">]</span>,
        <span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">47.5049</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">217.1870</span><span style="font-weight: bold">]])</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Covariance matrix:
<span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([[[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">7.0937</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000</span><span style="font-weight: bold">]</span>,
         <span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">42.7645</span><span style="font-weight: bold">]]</span>,

        <span style="font-weight: bold">[[</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11.1506</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000</span><span style="font-weight: bold">]</span>,
         <span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">50.8639</span><span style="font-weight: bold">]]</span>,

        <span style="font-weight: bold">[[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">9.4978</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000</span><span style="font-weight: bold">]</span>,
         <span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0000</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">42.0549</span><span style="font-weight: bold">]]])</span>
</pre>
</div></div>
</div>
<p>The mean is a <span class="math notranslate nohighlight">\(3 \times 2\)</span> matrix, and the (co)variance is a <span class="math notranslate nohighlight">\(3 \times 2 \times 2\)</span> matrix and
can be mapped to the <code class="docutils literal notranslate"><span class="pre">x2_x3_mean_std_var</span></code> table.</p>
<p>For the mean matrix, the first row is the mean (<span class="math notranslate nohighlight">\(\boldsymbol{\mu}_{X_1|Y=A}\)</span>) of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> for Adelie,
the second row is the mean (<span class="math notranslate nohighlight">\(\boldsymbol{\mu}_{X_1|Y=C}\)</span>) of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> for Chinstrap, and the third row
is the mean (<span class="math notranslate nohighlight">\(\boldsymbol{\mu}_{X_1|Y=G}\)</span>) of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> for Gentoo.</p>
<p>For instance, the first row is <span class="math notranslate nohighlight">\([38.7914, 189.9536]\)</span> is indeed the mean of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> for Adelie.</p>
<p>For the covariance matrix, the first row is a <span class="math notranslate nohighlight">\(2 \times 2\)</span> matrix,
which corresponds to <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}_{X_1|Y=A}\)</span>, the second row is <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}_{X_1|Y=C}\)</span>, and the third row is <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}_{X_1|Y=G}\)</span>.</p>
<p>For instance, the first row being <span class="math notranslate nohighlight">\([[7.0937, 0], [0, 42.7645]]\)</span> is indeed the covariance matrix of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> for Adelie where <span class="math notranslate nohighlight">\(7.0937\)</span> is the variance of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <span class="math notranslate nohighlight">\(42.7645\)</span> is the variance of <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code>.</p>
<p>Now, this may seem confusing at first, as we have established that each
conditional distribution <span class="math notranslate nohighlight">\(X_d|Y\)</span> is a Gaussian distribution,
and since all <span class="math notranslate nohighlight">\(D\)</span> of them are independent, we estimate the mean and variance of each
univariate Gaussian distribution. However, the way we have done it just now
suggests that we are estimating the mean and variance of a multivariate Gaussian
distribution. What’s the catch here?</p>
<p>The catch is in <a class="reference internal" href="../../../probability_theory/05_joint_distributions/0506_random_vectors/concept.html"><span class="doc std std-doc">Random Vectors</span></a>, finding the mean vector and covariance matrix of <span class="math notranslate nohighlight">\(D\)</span> independent
random variables <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_D\)</span> is equivalent to finding the mean and
variance of each univariate Gaussian distribution. So by construction,
the diagonals of each covariance matrix in <code class="docutils literal notranslate"><span class="pre">class_conditionals.covariance_matrix</span></code> are the
variance of each univariate Gaussian distribution, and the off-diagonals are 0.</p>
<p>This is a compact way to represent the mean and covariance matrix of a multivariate Gaussian distribution where each of its components are independent.</p>
<p>In my <a class="reference external" href="https://github.com/gao-hongnan/gaohn-probability-stats/blob/naive-bayes/src/generative/naive_bayes/naive_bayes.py">code</a>, <code class="docutils literal notranslate"><span class="pre">theta</span></code> is a <span class="math notranslate nohighlight">\(K \times D = 3 \times 2\)</span> matrix, where <span class="math notranslate nohighlight">\(K\)</span> is the number of classes and <span class="math notranslate nohighlight">\(D\)</span> is the number of predictors. But inside each
entry of <code class="docutils literal notranslate"><span class="pre">theta</span></code>, it is a <span class="math notranslate nohighlight">\(1 \times 2\)</span> row vector (a tuple of two numbers). So in the end
it is also a <span class="math notranslate nohighlight">\(3 \times 2 \times 2\)</span> matrix, but means very different things from the above pytorch example.</p>
<p>In our <code class="docutils literal notranslate"><span class="pre">theta</span></code>, the first row is a <span class="math notranslate nohighlight">\(2 \times 2\)</span> matrix encoding <span class="math notranslate nohighlight">\(\mu_{X_1|Y=A}\)</span>, <span class="math notranslate nohighlight">\(\mu_{X_2|Y=A}\)</span>, <span class="math notranslate nohighlight">\(\sigma_{X_1|Y=A}\)</span>, and <span class="math notranslate nohighlight">\(\sigma_{X_2|Y=A}\)</span>, the second row is a <span class="math notranslate nohighlight">\(2 \times 2\)</span> encoding <span class="math notranslate nohighlight">\(\mu_{X_1|Y=C}\)</span>, <span class="math notranslate nohighlight">\(\mu_{X_2|Y=C}\)</span>, <span class="math notranslate nohighlight">\(\sigma_{X_1|Y=C}\)</span>, and <span class="math notranslate nohighlight">\(\sigma_{X_2|Y=C}\)</span>, and the third row is a <span class="math notranslate nohighlight">\(2 \times 2\)</span> encoding <span class="math notranslate nohighlight">\(\mu_{X_1|Y=G}\)</span>, <span class="math notranslate nohighlight">\(\mu_{X_2|Y=G}\)</span>, <span class="math notranslate nohighlight">\(\sigma_{X_1|Y=G}\)</span>, and <span class="math notranslate nohighlight">\(\sigma_{X_2|Y=G}\)</span>.</p>
<p>Below is some functions to plot the contours.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_meshgrid</span><span class="p">(</span><span class="n">x0_range</span><span class="p">,</span> <span class="n">x1_range</span><span class="p">,</span> <span class="n">num_points</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x0_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x0_range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_points</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x1_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x1_range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_points</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">contour_plot</span><span class="p">(</span><span class="n">x0_range</span><span class="p">,</span> <span class="n">x1_range</span><span class="p">,</span> <span class="n">prob_fn</span><span class="p">,</span> <span class="n">batch_shape</span><span class="p">,</span> <span class="n">colours</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_points</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">X0</span><span class="p">,</span> <span class="n">X1</span> <span class="o">=</span> <span class="n">get_meshgrid</span><span class="p">(</span><span class="n">x0_range</span><span class="p">,</span> <span class="n">x1_range</span><span class="p">,</span> <span class="n">num_points</span><span class="o">=</span><span class="n">num_points</span><span class="p">)</span>
    <span class="n">X_input_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">X0</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">X1</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">X_input_space</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_input_space</span><span class="p">)</span>
    
    <span class="n">Z</span> <span class="o">=</span> <span class="n">prob_fn</span><span class="p">(</span><span class="n">X_input_space</span><span class="p">)</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="c1"># convert log pdf to pdf</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="c1"># Z = prob_fn(np.expand_dims(np.array([X0.ravel(), X1.ravel()]).T, 1))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">,</span> <span class="o">*</span><span class="n">X0</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">levels</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">Z</span><span class="p">[</span><span class="n">batch</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">colours</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">levels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">Z</span><span class="p">[</span><span class="n">batch</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="n">colours</span><span class="p">[</span><span class="n">batch</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_data</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">colours</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="n">inx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">inx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">inx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">colours</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training set&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;bill_length_mm&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;flipper_length_mm&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Adelie&quot;</span><span class="p">,</span> <span class="s2">&quot;Chinstrap&quot;</span><span class="p">,</span> <span class="s2">&quot;Gentoo&quot;</span><span class="p">]</span>
<span class="n">class_colours</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We assume the features are conditionally independent given the class label, and follows a Gaussian.</p>
<p>Note we need to use <code class="docutils literal notranslate"><span class="pre">torch.exp</span></code> to exponentiate the log-likelihood back to normal scale, as the log-likelihood is in log-space.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_conditionals</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">195</span><span class="p">])),</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">class_conditionals</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">195</span><span class="p">])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([-13.8483,  -5.0759, -11.0133]),
 tensor([9.6774e-07, 6.2458e-03, 1.6482e-05]))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plot_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">class_names</span><span class="p">,</span> <span class="n">class_colours</span><span class="p">)</span>
<span class="n">x0_min</span><span class="p">,</span> <span class="n">x0_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">contour_plot</span><span class="p">(</span>
    <span class="p">(</span><span class="n">x0_min</span><span class="p">,</span> <span class="n">x0_max</span><span class="p">),</span>
    <span class="p">(</span><span class="n">x1_min</span><span class="p">,</span> <span class="n">x1_max</span><span class="p">),</span>
    <span class="n">class_conditionals</span><span class="o">.</span><span class="n">log_prob</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">,</span>
    <span class="n">class_colours</span><span class="p">,</span>
    <span class="n">num_points</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training set with class-conditional density contours&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/55bd9f23efd77de0f9525a73b10b3727f28565b2809f67ed2d423e3a1a9551f9.png" src="../../../_images/55bd9f23efd77de0f9525a73b10b3727f28565b2809f67ed2d423e3a1a9551f9.png" />
</div>
</div>
<p>So the above contour plot represents each class conditional distribution, for example,
the blue dots are Adelie with <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> on the x-axis and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> on the y-axis and the contour is a 2d visualization of the joint distribution of <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> given Adelie (<span class="math notranslate nohighlight">\(\mathbb{P}(X_1, X_2|Y=A)\)</span>) where the
contour represents a multi-variate Gaussian distribution with mean and covariance matrix,
in particular the covariance matrix is a diagonal matrix since we assume the features are conditionally independent given the class label.</p>
<p>Of course the real data points (blue scatters) are not exactly on the contour, since
there is no reason to believe that Adelie’s <code class="docutils literal notranslate"><span class="pre">bill_length_mm</span></code> and <code class="docutils literal notranslate"><span class="pre">flipper_length_mm</span></code> are exactly Gaussian distributed with such mean and covariance matrix.</p>
</section>
<section id="further-readings">
<h2>Further Readings<a class="headerlink" href="#further-readings" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>JOHNSON, ALICIA A. “Chapter 14. Naive Bayes Classification.” In Bayes Rules!: An Introduction to Applied Bayesian Modeling. S.l.: CHAPMAN &amp; HALL CRC, 2022.</p></li>
<li><p><a class="reference external" href="https://www.python-graph-gallery.com/">Python Graph Gallery</a></p></li>
<li><p><a class="reference external" href="https://seaborn.pydata.org/tutorial/distributions.html">Seaborn Visualizing distributions</a></p>
<ul>
<li><p><a class="reference external" href="https://seaborn.pydata.org/generated/seaborn.jointplot.html">Jointplot for bivariate distributions</a></p></li>
<li><p><a class="reference external" href="https://seaborn.pydata.org/generated/seaborn.histplot.html">Histplot for bivariate distributions</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.kaggle.com/code/parulpandey/penguin-dataset-the-new-iris">https://www.kaggle.com/code/parulpandey/penguin-dataset-the-new-iris</a></p></li>
<li><p><a class="reference external" href="https://goodboychan.github.io/python/coursera/tensorflow_probability/icl/2021/08/18/Naive-bayes-and-logistic-regression.html">https://goodboychan.github.io/python/coursera/tensorflow_probability/icl/2021/08/18/Naive-bayes-and-logistic-regression.html</a></p></li>
</ul>
<hr class="footnotes docutils" />
<aside class="footnote brackets" id="id3" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">2</a><span class="fn-bracket">]</span></span>
<p>In Naive Bayes, both the predictor and the target are random variables, while
it is not the case for logistic regression. Regardless, once you condition on <span class="math notranslate nohighlight">\(Y\)</span>, <span class="math notranslate nohighlight">\(Y\)</span>
is no longer random.</p>
</aside>
<aside class="footnote brackets" id="id4" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">1</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://statproofbook.github.io/D/ind-cond">https://statproofbook.github.io/D/ind-cond</a></p>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./machine_learning\generative\naive_bayes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

            </article>
            

            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="implementation.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Naives Bayes Implementation</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="application_mnist.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Naive Bayes Application (MNIST)</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dependencies">
   Dependencies
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problem-statement">
   Problem Statement
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-prior">
   The Prior
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classifying-one-penguin">
   Classifying one penguin
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-categorical-feature">
     One Categorical Feature
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-quantitative-predictor">
     One Quantitative Predictor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#two-continuous-predictors">
     Two (Continuous) Predictors
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#conditional-independence">
       Conditional Independence
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#three-predictors">
     Three Predictors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pytorch">
   PyTorch
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-readings">
   Further Readings
  </a>
 </li>
</ul>

</nav>
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gao Hongnan
</p>

  </div>
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2023.<br>

</p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
Last updated on None.<br>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </div>
        </footer>
        

      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  </body>
</html>